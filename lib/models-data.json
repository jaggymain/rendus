[
  {
    "id": "fal-ai/flux-pro/kontext",
    "name": "FLUX.1 Kontext [pro]",
    "description": "FLUX.1 Kontext [pro] handles both text and reference images as inputs, seamlessly enabling targeted, local edits and complex transformations of entire scenes.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-2.jpg",
    "tags": [],
    "highlighted": true,
    "pinned": true,
    "input_schema": {
      "title": "FluxKontextInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Put a donut next to the flour."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "3:2",
            "1:1",
            "2:3",
            "3:4",
            "9:16",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/rabbit/rmgBxhwGYb2d3pl3x9sKf_output.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "Image prompt for the omni model."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6"
          ],
          "title": "Safety Tolerance",
          "type": "string",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "default": "2"
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enhance_prompt": {
          "title": "Enhance Prompt",
          "type": "boolean",
          "description": "Whether to enhance the prompt for better results.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "output_format",
        "safety_tolerance",
        "enhance_prompt",
        "aspect_ratio",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "simalabs/sima-upscaler",
    "name": "Sima Upscaler",
    "description": "Upscale your images at blazingly fast speeds with Sima Labs!",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/2H9bdDBfBM3q9Sj3E5blN_fbc5afeb35f74c70b5065872ef81efca.jpg",
    "tags": [
      "upscale",
      "image-to-image"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "scale"
      ],
      "type": "object",
      "properties": {
        "scale": {
          "description": "Upscaling factor (2x or 4x)",
          "type": "integer",
          "minimum": 2,
          "title": "Scale",
          "examples": [
            4
          ],
          "maximum": 4,
          "default": 4
        },
        "image_url": {
          "examples": [
            "https://public-bucket-20251031-222045.s3.us-west-2.amazonaws.com/example_koi.jpg"
          ],
          "description": "URL of the image to upscale",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "UpscaleInput",
      "required": [
        "image_url"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux/dev/image-to-image",
    "name": "FLUX.1 [dev]",
    "description": "FLUX.1 Image-to-Image is a high-performance endpoint for the FLUX.1 [dev] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/panda/jJ3ZxKTV6ulhHV6GKi9nZ_68430b557ef64f68bf6f0fed0e78c6f9.jpg",
    "tags": [
      "style transfer"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "BaseImageToInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cat dressed as a wizard with a background of a mystic forest."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "none"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate an image from."
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "The strength of the initial image. Higher strength values are better for this model.",
          "default": 0.95
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 10,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 40
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 3.5
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "strength",
        "num_inference_steps",
        "prompt",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/aura-sr",
    "name": "AuraSR",
    "description": "Upscale your images with AuraSR.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/koala/rW7Rhmjtkjvb8gnOPUhNN_b14088de7d684d4b8489db59d53ae3f7.jpg",
    "tags": [
      "upscaling",
      "high-res"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "Input",
      "type": "object",
      "properties": {
        "overlapping_tiles": {
          "examples": [
            true,
            false
          ],
          "title": "Overlapping Tiles",
          "type": "boolean",
          "description": "Whether to use overlapping tiles for upscaling. Setting this to true helps remove seams but doubles the inference time.",
          "default": false
        },
        "checkpoint": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Checkpoint",
          "type": "string",
          "description": "Checkpoint to use for upscaling. More coming soon.",
          "examples": [
            "v2",
            "v1"
          ],
          "default": "v1"
        },
        "upscaling_factor": {
          "enum": [
            4
          ],
          "title": "Upscaling Factor (Xs)",
          "type": "integer",
          "description": "Upscaling factor. More coming soon.",
          "examples": [
            4
          ],
          "default": 4
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/rabbit/JlBgYUyQRS3zxiBu_B4fM.png",
            "https://fal.media/files/monkey/e6RtJf_ue0vyWzeiEmTby.png",
            "https://fal.media/files/monkey/A6HGsigx4mmvs-hJVoOZX.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the image to upscale."
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "upscaling_factor",
        "overlapping_tiles",
        "checkpoint"
      ],
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/clarity-upscaler",
    "name": "Clarity Upscaler",
    "description": "Clarity upscaler for upscaling images with high very fidelity.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/controlnet-tile-upscaler.webp",
    "tags": [
      "upscaling"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "upscale_factor",
        "negative_prompt",
        "creativity",
        "resemblance",
        "guidance_scale",
        "num_inference_steps",
        "seed",
        "enable_safety_checker"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "masterpiece, best quality, highres"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
          "default": "masterpiece, best quality, highres"
        },
        "resemblance": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Resemblance",
          "description": "\n            The resemblance of the upscaled image to the original image. The higher the resemblance, the more the model will try to keep the original image.\n            Refers to the strength of the ControlNet.\n        ",
          "default": 0.6
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/gallery/NOCA_Mick-Thompson.resized.resized.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The URL of the image to upscale."
        },
        "creativity": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Creativity",
          "description": "\n            The creativity of the model. The higher the creativity, the more the model will deviate from the prompt.\n            Refers to the denoise strength of the sampling.\n        ",
          "default": 0.35
        },
        "upscale_factor": {
          "minimum": 1,
          "maximum": 4,
          "type": "number",
          "title": "Upscale Factor",
          "description": "The upscale factor",
          "default": 2
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to false, the safety checker will be disabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "(worst quality, low quality, normal quality:2)"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use. Use it to address details that you don't want in the image.",
          "default": "(worst quality, low quality, normal quality:2)"
        },
        "num_inference_steps": {
          "minimum": 4,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 18
        }
      },
      "title": "Input",
      "required": [
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-2-lora-gallery/virtual-tryon",
    "name": "Flux 2 Lora Gallery",
    "description": "Virtual clothing try-on (2 images: person + garment)",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/cvM8xzdznnFvnUi2BzS6u.png",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "VirtualTryonInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A person wearing a stylish jacket, virtual try-on",
            "Virtual try-on of a dress on a model",
            "Fashion virtual try-on with clothing"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate a virtual try-on image."
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "Number of images to generate",
          "default": 1
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the input image will be used."
        },
        "lora_scale": {
          "minimum": 0,
          "title": "Lora Scale",
          "type": "number",
          "maximum": 2,
          "description": "The strength of the virtual try-on effect.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result."
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/koala/YlOtn9SjXGGH274eN1G5R.png",
              "https://v3b.fal.media/files/b/penguin/sji5EHUvmFYOCVZsvvId-.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URLs of the images for virtual try-on. Provide person image and clothing image.",
          "items": {
            "type": "string"
          }
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 40
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 20,
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 2.5
        }
      },
      "x-fal-order-properties": [
        "image_urls",
        "prompt",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "lora_scale"
      ],
      "description": "Input model for Virtual Try-on endpoint - Generate virtual try-on images",
      "required": [
        "image_urls",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/flux-2-lora-gallery/face-to-full-portrait",
    "name": "Flux 2 Lora Gallery",
    "description": "Extends a face into a full body portrait",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/IWwDbQi64nYgQLfCGClXQ.png",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FaceToFullPortraitInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Face to full portrait",
            "Face to full portrait in professional attire",
            "Face to full portrait casual outdoor setting"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt describing the full portrait to generate from the face.",
          "default": "Face to full portrait"
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "Number of images to generate",
          "default": 1
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the input image will be used."
        },
        "lora_scale": {
          "minimum": 0,
          "title": "Lora Scale",
          "type": "number",
          "maximum": 2,
          "description": "The strength of the face to full portrait effect.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result."
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/elephant/XJPJL2v5pAOmx9LemHWAE.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URL of the cropped face image.",
          "items": {
            "type": "string"
          }
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 40
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 20,
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 2.5
        }
      },
      "x-fal-order-properties": [
        "image_urls",
        "prompt",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "lora_scale"
      ],
      "description": "Input model for Face to Full Portrait endpoint - Generate full portrait from face",
      "required": [
        "image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/flux-2-lora-gallery/apartment-staging",
    "name": "Flux 2 Lora Gallery",
    "description": "Virtually furnishes an empty apartment",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/0Tyv49_he8ViUyyChEb3D.png",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ApartmentStagingInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Furnish this room with modern furniture and decor",
            "Furnish this empty apartment with cozy living room furniture",
            "Furnish this room with minimalist Scandinavian design"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate a furnished room. Use 'furnish this room' for best results."
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "Number of images to generate",
          "default": 1
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the input image will be used."
        },
        "lora_scale": {
          "minimum": 0,
          "title": "Lora Scale",
          "type": "number",
          "maximum": 2,
          "description": "The strength of the apartment staging effect.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result."
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/tiger/58rkpMdBl7eqcxuZ8YRus.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URL of the empty room image to furnish.",
          "items": {
            "type": "string"
          }
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 40
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 20,
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 2.5
        }
      },
      "x-fal-order-properties": [
        "image_urls",
        "prompt",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "lora_scale"
      ],
      "description": "Input model for Apartment Staging endpoint - Furnish rooms",
      "required": [
        "image_urls",
        "prompt"
      ]
    }
  },
  {
    "id": "clarityai/crystal-upscaler",
    "name": "Crystal Upscaler",
    "description": "An advanced image enhancement tool designed specifically for facial details and portrait photography, utilizing Clarity AI's upscaling technology.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/rabbit/VjfWoUXISYQgeyKCNi8lU.png",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "scale_factor",
        "creativity"
      ],
      "type": "object",
      "properties": {
        "image_url": {
          "description": "URL to the input image",
          "type": "string",
          "examples": [
            "https://v3b.fal.media/files/b/zebra/eW3waMFDT-2_7Pq8j3r9d_upscaled.png"
          ],
          "title": "Image Url",
          "x-fal": {
            "timeout": 20,
            "max_file_size": 104857600
          },
          "limit_description": "Max file size: 100.0MB, Timeout: 20.0s"
        },
        "scale_factor": {
          "minimum": 1,
          "maximum": 200,
          "type": "number",
          "title": "Scale Factor",
          "description": "Scale factor",
          "default": 2
        },
        "creativity": {
          "minimum": 0,
          "maximum": 10,
          "type": "number",
          "title": "Creativity",
          "description": "Creativity level for upscaling",
          "default": 0
        }
      },
      "title": "CrystalUpscaleInput",
      "required": [
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-2-flex/edit",
    "name": "Flux 2 Flex",
    "description": "Image editing with FLUX.2 [flex] from Black Forest Labs. Supports multi-reference editing with customizable inference steps and enhanced text rendering.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/rWhUhWChzFTCQhbRTUPTq.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "enable_prompt_expansion",
        "seed",
        "safety_tolerance",
        "enable_safety_checker",
        "output_format",
        "sync_mode",
        "image_urls",
        "guidance_scale",
        "num_inference_steps"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Change colors of the vase. In a cozy living room setting, visualize a gradient vase placed on a table, flowing from rich #6a0dad to soft #ff69b4. Add an artistic carving text with a big font on vase says \"FLEX\" in the middle."
          ],
          "description": "The prompt to generate an image from.",
          "type": "string",
          "title": "Prompt"
        },
        "num_inference_steps": {
          "minimum": 2,
          "description": "The number of inference steps to perform.",
          "type": "integer",
          "maximum": 50,
          "title": "Number of Inference Steps",
          "default": 28
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "auto",
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If `auto`, the size will be determined by the model.",
          "title": "Image Size",
          "default": "auto"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "description": "The format of the generated image.",
          "type": "string",
          "title": "Output Format",
          "default": "jpeg"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5"
          ],
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "type": "string",
          "title": "Safety Tolerance",
          "default": "2"
        },
        "enable_safety_checker": {
          "description": "Whether to enable the safety checker.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "seed": {
          "description": "The seed to use for the generation.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/flux2_flex_edit_input.png"
            ]
          ],
          "description": "List of URLs of input images for editing",
          "type": "array",
          "title": "Image URLs",
          "items": {
            "type": "string"
          }
        },
        "enable_prompt_expansion": {
          "description": "Whether to expand the prompt using the model's own knowledge.",
          "type": "boolean",
          "title": "Enable Prompt Expansion",
          "default": true
        },
        "guidance_scale": {
          "minimum": 1.5,
          "description": "The guidance scale to use for the generation.",
          "type": "number",
          "maximum": 10,
          "title": "Guidance Scale",
          "default": 3.5
        }
      },
      "title": "Flux2FlexImageEditInput",
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "pricing_unit": "processed megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-2/edit",
    "name": "Flux 2",
    "description": "Image-to-image editing with FLUX.2 [dev] from Black Forest Labs. Precise modifications using natural language descriptions and hex color control.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/elephant/S9nDfnrxRNWA6tPqM5qtR.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "guidance_scale",
        "seed",
        "num_inference_steps",
        "image_size",
        "num_images",
        "acceleration",
        "enable_prompt_expansion",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "image_urls"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Change his clothes to casual suit and tie"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to edit the image."
        },
        "num_images": {
          "minimum": 1,
          "title": "Number of Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "examples": [
            {
              "height": 1152,
              "width": 2016
            }
          ],
          "title": "Image Size",
          "description": "The size of the image to generate. The width and height must be between 512 and 2048 pixels.",
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ]
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "examples": [
            "regular"
          ],
          "description": "The acceleration level to use for the image generation.",
          "default": "regular"
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 20,
          "description": "Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "default": 2.5
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded for better results.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 4,
          "title": "Number of Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/flux2_dev_edit_input.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URsL of the images for editing. A maximum of 3 images are allowed, if more are provided, only the first 3 will be used.",
          "items": {
            "type": "string"
          }
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      },
      "title": "Flux2EditImageInput",
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "pricing_unit": "processed megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-2-pro/edit",
    "name": "Flux 2 Pro",
    "description": "Text-to-image generation with FLUX.2 [pro] from Black Forest Labs. Optimized for maximum quality, exceptional photorealism and artistic images.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/ER5MxiLqQmWnhIID56vpD.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "seed",
        "safety_tolerance",
        "enable_safety_checker",
        "output_format",
        "sync_mode",
        "image_urls"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Place realistic flames emerging from the top of the coffee cup, dancing above the rim"
          ],
          "description": "The prompt to generate an image from.",
          "type": "string",
          "title": "Prompt"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "auto",
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If `auto`, the size will be determined by the model.",
          "title": "Image Size",
          "default": "auto"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "description": "The format of the generated image.",
          "type": "string",
          "title": "Output Format",
          "default": "jpeg"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5"
          ],
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "type": "string",
          "title": "Safety Tolerance",
          "default": "2"
        },
        "enable_safety_checker": {
          "description": "Whether to enable the safety checker.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "seed": {
          "description": "The seed to use for the generation.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/flux2_pro_edit_input.png"
            ]
          ],
          "description": "List of URLs of input images for editing",
          "type": "array",
          "title": "Image URLs",
          "items": {
            "type": "string"
          }
        }
      },
      "title": "Flux2ProImageEditInput",
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "pricing_unit": "processed megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/chrono-edit-lora",
    "name": "Chrono Edit Lora",
    "description": "LoRA endpoint for the Chrono Edit model.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/saqKmSSvY5wxwc-14EqA9.png",
    "tags": [
      "image-to-image",
      "image-editing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "num_inference_steps",
        "guidance_scale",
        "enable_prompt_expansion",
        "enable_temporal_reasoning",
        "num_temporal_reasoning_steps",
        "resolution",
        "enable_safety_checker",
        "seed",
        "output_format",
        "sync_mode",
        "turbo_mode",
        "loras"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Add a surfer to the wave in the illustration."
          ],
          "description": "The prompt to edit the image.",
          "type": "string",
          "title": "Prompt"
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "Optional additional LoRAs to merge for this request (max 3).",
          "items": {
            "$ref": "#/components/schemas/ChronoLoraWeight"
          },
          "default": []
        },
        "turbo_mode": {
          "title": "Turbo Mode",
          "type": "boolean",
          "description": "Enable turbo mode to use for faster inference.",
          "default": true
        },
        "enable_temporal_reasoning": {
          "title": "Enable Temporal Reasoning",
          "type": "boolean",
          "description": "Whether to enable temporal reasoning.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 10,
          "description": "The guidance scale for the inference.",
          "default": 1
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the output image.",
          "default": "480p"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image.",
          "default": "jpeg"
        },
        "num_temporal_reasoning_steps": {
          "minimum": 2,
          "title": "Number of Temporal Reasoning Steps",
          "type": "integer",
          "maximum": 12,
          "description": "The number of temporal reasoning steps to perform.",
          "default": 8
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "Whether to return the image in sync mode.",
          "default": false
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/zebra/yRvp9rTyDeDGHnbmtcsgK_original-wave.jpg"
          ],
          "description": "The image to edit.",
          "type": "string",
          "title": "Image URL"
        },
        "enable_prompt_expansion": {
          "examples": [
            true
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Number of Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 8
        },
        "seed": {
          "description": "The seed for the inference.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "description": "ChronoEdit input with optional custom LoRAs.",
      "title": "ChronoEditLoRAInput",
      "required": [
        "image_url",
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/chrono-edit-lora-gallery/paintbrush",
    "name": "Chrono Edit Lora Gallery",
    "description": "You can make edits simply by drawing a quick sketch on the input image.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/zebra/AmQzKtO9NXL-mBdxfk2w0.png",
    "tags": [
      "paint",
      "edit",
      "sketch"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input for paintbrush mode",
      "type": "object",
      "properties": {
        "prompt": {
          "title": "Prompt",
          "type": "string",
          "description": "Describe how to transform the sketched regions."
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the output image.",
          "default": "480p"
        },
        "lora_scale": {
          "minimum": 0,
          "maximum": 2,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA adapter.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image.",
          "default": "png"
        },
        "image_url": {
          "title": "Image Url",
          "type": "string",
          "description": "The image to edit."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "Whether to return the image in sync mode.",
          "default": false
        },
        "turbo_mode": {
          "title": "Turbo Mode",
          "type": "boolean",
          "description": "Enable turbo mode to use faster inference.",
          "default": true
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "Optional additional LoRAs to merge (max 3).",
          "items": {
            "$ref": "#/components/schemas/ChronoLoraWeight"
          },
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 10,
          "type": "number",
          "title": "Guidance Scale",
          "description": "Classifier-free guidance scale.",
          "default": 1
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "Number of denoising steps to run.",
          "default": 8
        },
        "mask_url": {
          "title": "Mask Url",
          "type": "string",
          "description": "Optional mask image where black areas indicate regions to sketch/paint."
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the inference."
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        }
      },
      "title": "ChronoEditPaintBrushInput",
      "x-fal-order-properties": [
        "image_url",
        "mask_url",
        "prompt",
        "num_inference_steps",
        "guidance_scale",
        "resolution",
        "enable_safety_checker",
        "lora_scale",
        "seed",
        "output_format",
        "sync_mode",
        "turbo_mode",
        "loras"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/chrono-edit-lora-gallery/upscaler",
    "name": "Chrono Edit Lora Gallery",
    "description": "Upscales and cleans up the image.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/tiger/kdWzzf1E0y6pIybJpp5Go.png",
    "tags": [
      "upscale",
      "details"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input for upscaler mode",
      "type": "object",
      "properties": {
        "lora_scale": {
          "minimum": 0,
          "maximum": 2,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA adapter.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image.",
          "default": "jpeg"
        },
        "image_url": {
          "title": "Image Url",
          "type": "string",
          "description": "The image to upscale."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "Whether to return the image in sync mode.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "Optional additional LoRAs to merge (max 3).",
          "items": {
            "$ref": "#/components/schemas/ChronoLoraWeight"
          },
          "default": []
        },
        "upscale_factor": {
          "minimum": 1,
          "maximum": 4,
          "type": "number",
          "title": "Upscale Factor",
          "description": "Target scale factor for the output resolution.",
          "default": 2
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 10,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The guidance scale for the inference.",
          "default": 1
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "Number of inference steps for the upscaling pass.",
          "default": 30
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the inference."
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        }
      },
      "title": "ChronoEditUpscalerInput",
      "x-fal-order-properties": [
        "image_url",
        "upscale_factor",
        "guidance_scale",
        "enable_safety_checker",
        "num_inference_steps",
        "lora_scale",
        "seed",
        "output_format",
        "sync_mode",
        "loras"
      ],
      "required": [
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/sam-3/image-rle",
    "name": "Sam 3",
    "description": "SAM 3 is a unified foundation model for promptable segmentation in images and videos. It can detect, segment, and track objects using text or visual prompts such as points, boxes, and masks. ",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/koala/R9LH3MHvBZFZVh-7Bqi0F.png",
    "tags": [
      "segmentation",
      "rle",
      "real-time",
      ""
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "text_prompt",
        "prompts",
        "box_prompts",
        "apply_mask",
        "sync_mode",
        "output_format",
        "return_multiple_masks",
        "max_masks",
        "include_scores",
        "include_boxes"
      ],
      "type": "object",
      "properties": {
        "include_boxes": {
          "description": "Whether to include bounding boxes for each mask (when available).",
          "type": "boolean",
          "title": "Include Boxes",
          "default": false
        },
        "include_scores": {
          "description": "Whether to include mask confidence scores.",
          "type": "boolean",
          "title": "Include Scores",
          "default": false
        },
        "box_prompts": {
          "examples": [
            [
              {
                "y_min": 600,
                "x_max": 700,
                "x_min": 425,
                "y_max": 875
              }
            ]
          ],
          "description": "Coordinates for boxes",
          "type": "array",
          "title": "Box Prompts",
          "items": {
            "$ref": "#/components/schemas/BoxPrompt"
          },
          "default": []
        },
        "image_url": {
          "examples": [
            "https://raw.githubusercontent.com/facebookresearch/segment-anything-2/main/notebooks/images/truck.jpg"
          ],
          "description": "URL of the image to be segmented",
          "type": "string",
          "title": "Image Url"
        },
        "sync_mode": {
          "description": "If True, the media will be returned as a data URI.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "description": "The format of the generated image.",
          "type": "string",
          "title": "Output Format",
          "default": "png"
        },
        "prompts": {
          "examples": [
            [
              {
                "y": 375,
                "label": 1,
                "x": 500
              }
            ]
          ],
          "description": "List of point prompts",
          "type": "array",
          "title": "Prompts",
          "items": {
            "$ref": "#/components/schemas/PointPrompt"
          },
          "default": []
        },
        "max_masks": {
          "minimum": 1,
          "maximum": 32,
          "type": "integer",
          "description": "Maximum number of masks to return when `return_multiple_masks` is enabled.",
          "title": "Max Masks",
          "default": 3
        },
        "return_multiple_masks": {
          "description": "If True, upload and return multiple generated masks as defined by `max_masks`.",
          "type": "boolean",
          "title": "Return Multiple Masks",
          "default": false
        },
        "apply_mask": {
          "description": "Apply the mask on the image.",
          "type": "boolean",
          "title": "Apply Mask",
          "default": true
        },
        "text_prompt": {
          "description": "Text prompt for segmentation",
          "type": "string",
          "title": "Text Prompt",
          "default": ""
        }
      },
      "title": "SAM3ImageInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/sam-3/image",
    "name": "Segment Anything Model 3",
    "description": "SAM 3 is a unified foundation model for promptable segmentation in images and videos. It can detect, segment, and track objects using text or visual prompts such as points, boxes, and masks. ",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/c4OomNoO7EBqTsV1Q6fBD_dad01197987c4168a5fef5a12b09cb75.jpg",
    "tags": [
      "segmentation",
      "mask",
      "real-time"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "text_prompt",
        "prompts",
        "box_prompts",
        "apply_mask",
        "sync_mode",
        "output_format",
        "return_multiple_masks",
        "max_masks",
        "include_scores",
        "include_boxes"
      ],
      "type": "object",
      "properties": {
        "include_boxes": {
          "description": "Whether to include bounding boxes for each mask (when available).",
          "type": "boolean",
          "title": "Include Boxes",
          "default": false
        },
        "include_scores": {
          "description": "Whether to include mask confidence scores.",
          "type": "boolean",
          "title": "Include Scores",
          "default": false
        },
        "box_prompts": {
          "examples": [
            [
              {
                "y_min": 600,
                "x_max": 700,
                "x_min": 425,
                "y_max": 875
              }
            ]
          ],
          "description": "Coordinates for boxes",
          "type": "array",
          "title": "Box Prompts",
          "items": {
            "$ref": "#/components/schemas/BoxPrompt"
          },
          "default": []
        },
        "image_url": {
          "examples": [
            "https://raw.githubusercontent.com/facebookresearch/segment-anything-2/main/notebooks/images/truck.jpg"
          ],
          "description": "URL of the image to be segmented",
          "type": "string",
          "title": "Image Url"
        },
        "sync_mode": {
          "description": "If True, the media will be returned as a data URI.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "description": "The format of the generated image.",
          "type": "string",
          "title": "Output Format",
          "default": "png"
        },
        "prompts": {
          "examples": [
            [
              {
                "y": 375,
                "label": 1,
                "x": 500
              }
            ]
          ],
          "description": "List of point prompts",
          "type": "array",
          "title": "Prompts",
          "items": {
            "$ref": "#/components/schemas/PointPrompt"
          },
          "default": []
        },
        "max_masks": {
          "minimum": 1,
          "maximum": 32,
          "type": "integer",
          "description": "Maximum number of masks to return when `return_multiple_masks` is enabled.",
          "title": "Max Masks",
          "default": 3
        },
        "return_multiple_masks": {
          "description": "If True, upload and return multiple generated masks as defined by `max_masks`.",
          "type": "boolean",
          "title": "Return Multiple Masks",
          "default": false
        },
        "apply_mask": {
          "description": "Apply the mask on the image.",
          "type": "boolean",
          "title": "Apply Mask",
          "default": true
        },
        "text_prompt": {
          "description": "Text prompt for segmentation",
          "type": "string",
          "title": "Text Prompt",
          "default": ""
        }
      },
      "title": "SAM3ImageInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/gemini-3-pro-image-preview/edit",
    "name": "Gemini 3 Pro Image to Image",
    "description": "Nano Banana Pro (a.k.a Nano Banana 2) is Google's new state-of-the-art image generation and editing model",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/Vp2KdBwHgd4Qp0ixnsOue_eb81afc63ac24064bc9d3e9ed48f9b74.jpg",
    "tags": [
      "realism",
      "typography"
    ],
    "highlighted": false,
    "pinned": true,
    "input_schema": {
      "title": "NanoBananaImageToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "make a photo of the man driving the car down the california coastline"
          ],
          "maxLength": 50000,
          "minLength": 3,
          "description": "The prompt for image editing.",
          "title": "Prompt",
          "type": "string"
        },
        "num_images": {
          "minimum": 1,
          "description": "The number of images to generate.",
          "type": "integer",
          "title": "Number of Images",
          "maximum": 4,
          "default": 1
        },
        "aspect_ratio": {
          "anyOf": [
            {
              "enum": [
                "auto",
                "21:9",
                "16:9",
                "3:2",
                "4:3",
                "5:4",
                "1:1",
                "4:5",
                "3:4",
                "2:3",
                "9:16"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "description": "The aspect ratio of the generated image.",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "resolution": {
          "enum": [
            "1K",
            "2K",
            "4K"
          ],
          "description": "The resolution of the image to generate.",
          "type": "string",
          "title": "Resolution",
          "default": "1K"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "description": "The format of the generated image.",
          "type": "string",
          "title": "Output Format",
          "default": "png"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input.png",
              "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input-2.png"
            ]
          ],
          "description": "The URLs of the images to use for image-to-image generation or image editing.",
          "type": "array",
          "title": "Image URLs",
          "items": {
            "type": "string"
          }
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode",
        "image_urls",
        "resolution"
      ],
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "credits": 3,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/nano-banana-pro/edit",
    "name": "Nano Banana Pro",
    "description": "Nano Banana Pro (a.k.a Nano Banana 2) is Google's new state-of-the-art image generation and editing model",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/1pQJe8ztzgNn4zFlFx8gv_8bec442530e94e3a9a37e7df968821d6.jpg",
    "tags": [
      "realism",
      "typography"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "NanoBananaImageToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "make a photo of the man driving the car down the california coastline"
          ],
          "maxLength": 50000,
          "type": "string",
          "title": "Prompt",
          "minLength": 3,
          "description": "The prompt for image editing."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Number of Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "21:9",
            "16:9",
            "3:2",
            "4:3",
            "5:4",
            "1:1",
            "4:5",
            "3:4",
            "2:3",
            "9:16"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image.",
          "default": "auto"
        },
        "resolution": {
          "enum": [
            "1K",
            "2K",
            "4K"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the image to generate.",
          "default": "1K"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input.png",
              "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input-2.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URLs of the images to use for image-to-image generation or image editing.",
          "items": {
            "type": "string"
          }
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode",
        "image_urls",
        "resolution"
      ],
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "credits": 3,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora-gallery/multiple-angles",
    "name": "Qwen Image Edit Plus Lora Gallery",
    "description": "Precise camera position and angle control (rotation, zoom, vertical movement)",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/koala/pE_Au_0FmwjWoOgihymjz_6824b39718e04366a2a513de2f0e3954.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input model for Multiple Angles endpoint - Camera control with precise adjustments",
      "type": "object",
      "properties": {
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If not provided, the size of the final input image will be used.",
          "title": "Image Size"
        },
        "wide_angle_lens": {
          "title": "Wide-Angle Lens",
          "type": "boolean",
          "description": "Enable wide-angle lens effect",
          "default": false
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 1
        },
        "image_urls": {
          "examples": [
            [
              "https://v3.fal.media/files/monkey/i3saq4bAPXSIl08nZtq9P_ec535747aefc4e31943136a6d8587075.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URL of the image to adjust camera angle for.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "vertical_angle": {
          "description": "Adjust vertical camera angle (-1=bird's-eye view/looking down, 0=neutral, 1=worm's-eye view/looking up)",
          "type": "number",
          "minimum": -1,
          "maximum": 1,
          "title": "Vertical Angle (Bird \u2b04 Worm)",
          "default": 0
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate",
          "default": 1
        },
        "move_forward": {
          "description": "Move camera forward (0=no movement, 10=close-up)",
          "type": "number",
          "minimum": 0,
          "maximum": 10,
          "title": "Move Forward \u2192 Close-Up",
          "default": 0
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "rotate_right_left": {
          "description": "Rotate camera left (positive) or right (negative) in degrees. Positive values rotate left, negative values rotate right.",
          "type": "number",
          "minimum": -90,
          "maximum": 90,
          "title": "Rotate Right-Left (degrees \u00b0)",
          "default": 0
        },
        "lora_scale": {
          "minimum": 0,
          "maximum": 4,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the camera control effect.",
          "default": 1.25
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "seed": {
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result.",
          "type": "integer",
          "title": "Seed"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 6
        }
      },
      "title": "MultipleAnglesInput",
      "x-fal-order-properties": [
        "image_urls",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "negative_prompt",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "rotate_right_left",
        "move_forward",
        "vertical_angle",
        "wide_angle_lens",
        "lora_scale"
      ],
      "required": [
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora-gallery/shirt-design",
    "name": "Qwen Image Edit Plus Lora Gallery",
    "description": "Apply designs/graphics onto people's shirts",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/elephant/ZXVT6SZVlSVAF6EDlq4Vu_e6f9f57d24f94fa0bd96473666adbc3f.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input model for Shirt Design endpoint - Put designs/graphics on people's shirts",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Put this design on their shirt",
            "Apply this graphic to their t-shirt",
            "Place this logo on their shirt"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Describe what design to put on the shirt. The model will apply the design from your input image onto the person's shirt.",
          "default": "Put this design on their shirt"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If not provided, the size of the final input image will be used.",
          "title": "Image Size"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "lora_scale": {
          "minimum": 0,
          "maximum": 4,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 6
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 1
        },
        "seed": {
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/tiger/1rq65RzrUwKtHLAwpEjq8_4ee388931b5142f1bd1f2e0a3cb2498e.png",
              "https://github.com/fal-ai/fal-assets/blob/main/Logo%20Square.png?raw=true"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URLs of the images: first image is the person wearing a shirt, second image is the design/logo to put on the shirt.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        }
      },
      "title": "ShirtDesignInput",
      "x-fal-order-properties": [
        "image_urls",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "negative_prompt",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "prompt",
        "lora_scale"
      ],
      "required": [
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora-gallery/remove-lighting",
    "name": "Qwen Image Edit Plus Lora Gallery",
    "description": "Remove existing lighting and apply soft, even illumination",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/iouncidmZ2wxAn6Sk9Xra_b9c66b64c8c74ac3812ab70a28ef955c.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input model for Remove Lighting endpoint - Remove existing lighting and apply soft even lighting",
      "type": "object",
      "properties": {
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 6
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If not provided, the size of the final input image will be used.",
          "title": "Image Size"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 1
        },
        "seed": {
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/panda/J0XyFgb0AAgyUzmVFd0nr_5363c66361d94cea89333795d700165d.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URL of the image with lighting/shadows to remove.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        }
      },
      "title": "RemoveLightingInput",
      "x-fal-order-properties": [
        "image_urls",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "negative_prompt",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images"
      ],
      "required": [
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora-gallery/remove-element",
    "name": "Qwen Image Edit Plus Lora Gallery",
    "description": "Remove unwanted elements (objects, people, text) while maintaining image consistency",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/zebra/WrfXd_ifW4WiySNKZQsuc_9abcf5466bc043ab8629f066c3ddfb97.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input model for Remove Element endpoint - Remove/delete elements (objects, people, text) from the image",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Remove the person from the image",
            "Remove the car and the bicycle",
            "Remove the text and logos"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Specify what element(s) to remove from the image (objects, people, text, etc.). The model will cleanly remove the element while maintaining consistency of the rest of the image.",
          "default": "Remove the specified element from the scene"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If not provided, the size of the final input image will be used.",
          "title": "Image Size"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "lora_scale": {
          "minimum": 0,
          "maximum": 4,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 6
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 1
        },
        "seed": {
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/elephant/oWup_Q7zuvbfB4en-hneO_5aaa1cb3d3eb44999005159e82e7c9b7.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URL of the image containing elements to remove.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        }
      },
      "title": "RemoveElementInput",
      "x-fal-order-properties": [
        "image_urls",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "negative_prompt",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "prompt",
        "lora_scale"
      ],
      "required": [
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora-gallery/next-scene",
    "name": "Qwen Image Edit Plus Lora Gallery",
    "description": "Create cinematic transitions and scene progressions (camera movements, framing changes)",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/Bva1pRGx_pdjNTot257xw_4bfa0c1fc15b453bb58f4bf21a2a92f2.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input model for Next Scene endpoint - Create cinematic shot progressions and scene transitions",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Next Scene: The camera pulls back to reveal the entire landscape",
            "Next Scene: The camera tracks forward as sunlight breaks through the clouds",
            "Next Scene: The camera pans right revealing new characters entering the frame"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Describe the camera movement, framing change, or scene transition. Start with 'Next Scene:' for best results. Examples: camera movements (dolly, push-in, pull-back), framing changes (wide to close-up), new elements entering frame.",
          "default": "Next Scene: The camera moves forward revealing more of the scene"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If not provided, the size of the final input image will be used.",
          "title": "Image Size"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "lora_scale": {
          "minimum": 0,
          "maximum": 4,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 6
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 1
        },
        "seed": {
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/penguin/Zj5z8GW7yYlrpOQtuwjKQ_086265e41092415f951a6576fed25e41.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URL of the image to create the next scene from.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        }
      },
      "title": "NextSceneInput",
      "x-fal-order-properties": [
        "image_urls",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "negative_prompt",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "prompt",
        "lora_scale"
      ],
      "required": [
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora-gallery/integrate-product",
    "name": "Qwen Image Edit Plus Lora Gallery",
    "description": "Blend products into backgrounds with automatic perspective and lighting correction",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/kEVLi_bBc9qtMhP8n6qwU_25c875653b4946438eb04430b0ad0ec7.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input model for Integrate Product endpoint - Blend and integrate products/elements into backgrounds",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Blend and integrate the product into the background with correct perspective and lighting",
            "Seamlessly blend the object into the scene with natural shadows",
            "Integrate the product naturally into the environment"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Describe how to blend and integrate the product/element into the background. The model will automatically correct perspective, lighting and shadows for natural integration.",
          "default": "Blend and integrate the product into the background"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If not provided, the size of the final input image will be used.",
          "title": "Image Size"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "lora_scale": {
          "minimum": 0,
          "maximum": 4,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 6
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 1
        },
        "seed": {
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/koala/LFYeCtq2LB4s6IpmoI2iy_2fb7b46d1f3749db9f7bab679bc6c4f3.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URL of the image with product to integrate into background.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        }
      },
      "title": "IntegrateProductInput",
      "x-fal-order-properties": [
        "image_urls",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "negative_prompt",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "prompt",
        "lora_scale"
      ],
      "required": [
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora-gallery/group-photo",
    "name": "Qwen Image Edit Plus Lora Gallery",
    "description": "Create group photos  ",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/Xzyss_iF9ErzEdP9KsS0r_3d7c90af968f4e0c87deff4eb6845dc5.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input model for Group Photo endpoint - Create composite group photos with vintage/retro style",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Two people standing next to each other outside with a landscape background",
            "Group photo outdoors with mountains and nature in the background, vintage style",
            "Two people next to each other in a scenic outdoor setting with retro filter",
            "People standing together outside with beautiful landscape behind them"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Describe the group photo scene, setting, and style. The model will maintain character consistency and add vintage effects like grain, blur, and retro filters.",
          "default": "Two people standing next to each other outside with a landscape background"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If not provided, the size of the final input image will be used.",
          "title": "Image Size"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "lora_scale": {
          "minimum": 0,
          "maximum": 4,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 6
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 1
        },
        "seed": {
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://v3.fal.media/files/monkey/i3saq4bAPXSIl08nZtq9P_ec535747aefc4e31943136a6d8587075.png",
              "https://v3b.fal.media/files/b/kangaroo/OEtbMr7E43t0UPT8JwRT4_091834d85d8346d6960e3fd789d67db8.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URLs of the images to combine into a group photo. Provide 2 or more individual portrait images.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        }
      },
      "title": "GroupPhotoInput",
      "x-fal-order-properties": [
        "image_urls",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "negative_prompt",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "prompt",
        "lora_scale"
      ],
      "required": [
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora-gallery/face-to-full-portrait",
    "name": "Qwen Image Edit Plus Lora Gallery",
    "description": "Generate full portrait from a cropped face photo",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/K0qnknLPw1PbwjJNNJkTS_896641172756488a8f74812d50c0cec4.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input model for Face to Full Portrait endpoint - Generate full portrait from a cropped face image",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Photography. A young woman wearing a yellow dress stands in a flower field",
            "Professional headshot with business suit and office background",
            "Casual portrait outdoors with natural sunlight and bokeh background"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Describe the full portrait you want to generate from the face. Include clothing, setting, pose, and style details.",
          "default": "Photography. A portrait of the person in professional attire with natural lighting"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If not provided, the size of the final input image will be used.",
          "title": "Image Size"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "lora_scale": {
          "minimum": 0,
          "maximum": 4,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 6
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 1
        },
        "seed": {
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/kangaroo/Tl9BsbouyruyrEJtXWYOz_ef4270d3ff4d47f18883c70cfdf07c27.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URL of the cropped face image. Provide a close-up face photo.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        }
      },
      "title": "FaceToFullPortraitInput",
      "x-fal-order-properties": [
        "image_urls",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "negative_prompt",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "prompt",
        "lora_scale"
      ],
      "required": [
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora-gallery/add-background",
    "name": "Qwen Image Edit Plus Lora Gallery",
    "description": "Add a realistic scene behind the object with white background",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/q-_Xgs_OXDhT6oYmH2iWy_ade5b4d5ff1340de8f7ce0e7f4ebfeb9.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input model for Add Background endpoint - Remove white background and add a realistic scene",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Add an outdoor scene with mountains and road behind the car",
            "Add a modern living room background behind the product",
            "Add a natural outdoor setting with grass and trees as background"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Describe the background/scene you want to add behind the object. The model will remove the white background and add the specified environment.",
          "default": "Remove white background and add a realistic scene behind the object"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. If not provided, the size of the final input image will be used.",
          "title": "Image Size"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. 'regular' balances speed and quality.",
          "default": "regular"
        },
        "lora_scale": {
          "minimum": 0,
          "maximum": 4,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image",
          "default": "png"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 6
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and won't be saved in history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale. Controls how closely the model follows the prompt.",
          "default": 1
        },
        "seed": {
          "description": "Random seed for reproducibility. Same seed with same prompt will produce same result.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/rabbit/YN3dXLQBWb2ch6V607Uuc_d808599bb92f4c808502a118697bdc1f.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URLs of the images to edit. Provide an image with a white or clean background.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        }
      },
      "title": "AddBackgroundInput",
      "x-fal-order-properties": [
        "image_urls",
        "image_size",
        "guidance_scale",
        "num_inference_steps",
        "acceleration",
        "negative_prompt",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "num_images",
        "prompt",
        "lora_scale"
      ],
      "required": [
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/reve/fast/remix",
    "name": "Reve",
    "description": "Reve\u2019s fast remix model lets you upload an reference images and then combine/transform them via a text prompt at lightning speed!",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/QBJ4DIme_ALMK-SAeipWr_30f59e7c13274579a8a6a2b3b566b9aa.jpg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_urls",
        "aspect_ratio",
        "num_images",
        "output_format",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "num_images": {
          "description": "Number of images to generate",
          "type": "integer",
          "examples": [
            1
          ],
          "title": "Number of Images",
          "minimum": 1,
          "maximum": 4,
          "default": 1
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "3:2",
            "2:3",
            "4:3",
            "3:4",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "examples": [
            "16:9"
          ],
          "description": "The desired aspect ratio of the generated image. If not provided, will be smartly chosen by the model."
        },
        "prompt": {
          "examples": [
            "Dress the model in the clothes and hat. Add a cat to the scene and change the background to a Victorian era building."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text description of the desired image. May include XML img tags like <img>0</img> to refer to specific images by their index in the image_urls list.",
          "minLength": 1,
          "maxLength": 2560
        },
        "image_urls": {
          "description": "List of URLs of reference images. Must provide between 1 and 6 images (inclusive). Each image must be less than 10 MB. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.",
          "type": "array",
          "items": {
            "type": "string"
          },
          "max_file_size": 10485760,
          "examples": [
            [
              "https://v3b.fal.media/files/b/monkey/lsPBOhBws_FnTzd5G9KZ9_seedream4_edit_input_4.png",
              "https://v3b.fal.media/files/b/monkey/ZrW5ouDj8vjLtvl1Cj9l9_seedream4_edit_input_2.png",
              "https://v3b.fal.media/files/b/elephant/sd0k6YhlQEKfR6d_hAmIH_seedream4_edit_input_3.png"
            ]
          ],
          "title": "Reference Image URLs",
          "min_height": 128,
          "min_width": 128,
          "max_height": 4096,
          "max_width": 4096
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "examples": [
            "png"
          ],
          "description": "Output format for the generated image.",
          "default": "png"
        }
      },
      "title": "ReveRemixInput",
      "description": "Input for Reve image remixing",
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/reve/fast/edit",
    "name": "Reve",
    "description": "Reve\u2019s fast edit model lets you upload an existing image and then transform it via a text prompt at lightning speed!",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/koala/wISCIqUHSbkQYw9wrvYSM_b49480bef5ce45a189f4d23de477524e.jpg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "num_images",
        "output_format",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "num_images": {
          "description": "Number of images to generate",
          "type": "integer",
          "examples": [
            1
          ],
          "title": "Number of Images",
          "minimum": 1,
          "maximum": 4,
          "default": 1
        },
        "prompt": {
          "examples": [
            "Make it nighttime with stars glistening behind the mountain"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text description of how to edit the provided image.",
          "minLength": 1,
          "maxLength": 2560
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "examples": [
            "png"
          ],
          "description": "Output format for the generated image.",
          "default": "png"
        },
        "image_url": {
          "description": "URL of the reference image to edit. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.",
          "type": "string",
          "x-fal": {
            "min_width": 128,
            "timeout": 20,
            "min_height": 128,
            "max_width": 4096,
            "max_height": 4096,
            "max_file_size": 10485760
          },
          "title": "Reference Image URL",
          "examples": [
            "https://v3b.fal.media/files/b/rabbit/Wi1oWbMfigpUMP0w_i5fm_-WnGcaJCtfrT6Q2oms97E.png"
          ],
          "limit_description": "Max file size: 10.0MB, Min width: 128px, Min height: 128px, Max width: 4096px, Max height: 4096px, Timeout: 20.0s"
        }
      },
      "title": "ReveFastEditInput",
      "description": "Input for Reve fast image editing",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/image-apps-v2/outpaint",
    "name": "Image Outpaint",
    "description": "Directional outpainting. Choose edges to expand. left, right, top, or center (uniform all sides). Only expanded areas are generated; an optional zoom-out pulls the frame back by the chosen amount.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/_JfxHHU5PSR2RsM0r9O3S_549a1d78995c4babae440a2d345e621b.jpg",
    "tags": [
      "outpainting"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "expand_left",
        "expand_right",
        "expand_top",
        "expand_bottom",
        "zoom_out_percentage",
        "prompt",
        "num_images",
        "enable_safety_checker",
        "sync_mode",
        "output_format"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "description": "Optional prompt to guide the outpainting. If provided, it will be appended to the base outpaint instruction. Example: 'with a beautiful sunset in the background'",
          "type": "string",
          "maxLength": 500,
          "title": "Prompt",
          "default": ""
        },
        "expand_right": {
          "minimum": 0,
          "maximum": 700,
          "type": "integer",
          "description": "Number of pixels to add as black margin on the right side (0-700).",
          "title": "Expand Right",
          "default": 0
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "description": "Number of images to generate.",
          "title": "Num Images",
          "default": 1
        },
        "zoom_out_percentage": {
          "minimum": 0,
          "maximum": 90,
          "type": "number",
          "description": "Percentage to zoom out the image. If set, the image will be scaled down by this percentage and black margins will be added to maintain original size. Example: 50 means the image will be 50% of original size with black margins filling the rest.",
          "title": "Zoom Out Percentage",
          "default": 20
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "jpg",
            "webp"
          ],
          "description": "The format of the output image.",
          "type": "string",
          "title": "Output Format",
          "default": "png"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/oei_-iPIYFnhdB8SxojND_qwen-edit-res.png"
          ],
          "description": "Image URL to outpaint",
          "type": "string",
          "title": "Image Url"
        },
        "sync_mode": {
          "description": "If True, the function will wait for the image to be generated and uploaded before returning the response. If False, the function will return immediately and the image will be generated asynchronously.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "expand_bottom": {
          "minimum": 0,
          "maximum": 700,
          "type": "integer",
          "description": "Number of pixels to add as black margin on the bottom side (0-700).",
          "title": "Expand Bottom",
          "default": 400
        },
        "expand_left": {
          "minimum": 0,
          "maximum": 700,
          "type": "integer",
          "description": "Number of pixels to add as black margin on the left side (0-700).",
          "title": "Expand Left",
          "default": 0
        },
        "enable_safety_checker": {
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "expand_top": {
          "minimum": 0,
          "maximum": 700,
          "type": "integer",
          "description": "Number of pixels to add as black margin on the top side (0-700).",
          "title": "Expand Top",
          "default": 0
        }
      },
      "title": "OutpaintInput",
      "required": [
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-vision-upscaler",
    "name": "Flux Vision Upscaler",
    "description": "Flux Vision Upscaler for magnify/upscaling images with high fidelity and creativity.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/zebra/7DKYn-EKEd3lthAymIaZ4_54bca98af99240488e7d2fcc2a2dcad8.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Input",
      "type": "object",
      "properties": {
        "guidance": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance",
          "description": "CFG/guidance scale (0-20). Controls how closely the model follows the guidance.",
          "default": 1
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/gallery/NOCA_Mick-Thompson.resized.resized.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The URL of the image to upscale."
        },
        "creativity": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Creativity",
          "description": "The creativity of the model. The higher the creativity, the more the model will deviate from the original. Refers to the denoise strength of the sampling.",
          "default": 0.3
        },
        "steps": {
          "minimum": 4,
          "maximum": 50,
          "type": "integer",
          "title": "Steps",
          "description": "Number of inference steps (4-50).",
          "default": 20
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "The seed to use for the upscale. If not provided, a random seed will be used."
        },
        "upscale_factor": {
          "minimum": 1,
          "maximum": 4,
          "type": "number",
          "title": "Upscale Factor",
          "description": "The upscale factor (1-4x).",
          "default": 2
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "upscale_factor",
        "seed",
        "creativity",
        "guidance",
        "steps",
        "enable_safety_checker"
      ],
      "required": [
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/emu-3.5-image/edit-image",
    "name": "Emu 3.5 Image",
    "description": "Edit images with a text prompt using Emu 3.5 Image",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/qokOwnTLa_gOwi2WfOytn_8aa37ff6627843cf8e1ab8d9b95684ff.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Emu35ImageEditInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Recreate this image in ukiyo-e style"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to edit the image."
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the output image.",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "21:9",
            "16:9",
            "4:3",
            "3:2",
            "1:1",
            "2:3",
            "3:4",
            "9:16",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the output image.",
          "default": "auto"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image.",
          "default": "png"
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/lion/iC4LKAESSVo4ug-XzmR11_e9cafdab-c8b4-4267-804e-230e3d0d0814.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The image to edit."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "Whether to return the image in sync mode.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the inference."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "resolution",
        "aspect_ratio",
        "enable_safety_checker",
        "seed",
        "output_format",
        "sync_mode",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 3,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/chrono-edit",
    "name": "Chrono Edit",
    "description": "NVIDIA's Logically Consistent and Physics-Aware Image Editing Model",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/u92nc8-wxixxeAFpzn6cA_2b49b12b78034f7b9f021ba07b5055e5.jpg",
    "tags": [
      "image-editing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Input model for ChronoEdit standard editing operations",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Add a surfer to the wave in the illustration."
          ],
          "description": "The prompt to edit the image.",
          "type": "string",
          "title": "Prompt"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "description": "The resolution of the output image.",
          "type": "string",
          "title": "Resolution",
          "default": "480p"
        },
        "enable_safety_checker": {
          "description": "Whether to enable the safety checker.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "description": "The format of the output image.",
          "type": "string",
          "title": "Output Format",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/zebra/yRvp9rTyDeDGHnbmtcsgK_original-wave.jpg"
          ],
          "description": "The image to edit.",
          "type": "string",
          "title": "Image URL"
        },
        "turbo_mode": {
          "description": "Enable turbo mode to use for faster inference.",
          "type": "boolean",
          "title": "Turbo Mode",
          "default": true
        },
        "num_temporal_reasoning_steps": {
          "minimum": 2,
          "maximum": 12,
          "type": "integer",
          "title": "Number of Temporal Reasoning Steps",
          "description": "The number of temporal reasoning steps to perform.",
          "default": 8
        },
        "sync_mode": {
          "description": "Whether to return the image in sync mode.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 10,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The guidance scale for the inference.",
          "default": 1
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Number of Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 8
        },
        "enable_temporal_reasoning": {
          "description": "Whether to enable temporal reasoning.",
          "type": "boolean",
          "title": "Enable Temporal Reasoning",
          "default": false
        },
        "enable_prompt_expansion": {
          "examples": [
            true
          ],
          "description": "Whether to enable prompt expansion.",
          "type": "boolean",
          "title": "Enable Prompt Expansion",
          "default": true
        },
        "seed": {
          "description": "The seed for the inference.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "ChronoEditInput",
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "num_inference_steps",
        "guidance_scale",
        "enable_prompt_expansion",
        "enable_temporal_reasoning",
        "num_temporal_reasoning_steps",
        "resolution",
        "enable_safety_checker",
        "seed",
        "output_format",
        "sync_mode",
        "turbo_mode"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/gpt-image-1-mini/edit",
    "name": "GPT Image 1 Mini",
    "description": "GPT Image 1 mini combines OpenAI's advanced language capabilities, powered by GPT-5, with GPT Image 1 Mini for efficient image generation. ",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/cG0uNtODkeDPtNDUXms1H_63d395581f334382bf6806b78849ffb0.jpg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "EditImageRequestMini",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Dress the model in the clothes and hat. Add a cat to the scene and change the background to a Victorian era building."
          ],
          "description": "The prompt for image generation",
          "type": "string",
          "title": "Prompt"
        },
        "num_images": {
          "description": "Number of images to generate",
          "type": "integer",
          "minimum": 1,
          "title": "Number of Images",
          "examples": [
            1
          ],
          "maximum": 4,
          "default": 1
        },
        "image_size": {
          "enum": [
            "auto",
            "1024x1024",
            "1536x1024",
            "1024x1536"
          ],
          "description": "Aspect ratio for the generated image",
          "type": "string",
          "title": "Image Size",
          "default": "auto"
        },
        "background": {
          "enum": [
            "auto",
            "transparent",
            "opaque"
          ],
          "description": "Background for the generated image",
          "type": "string",
          "title": "Background",
          "default": "auto"
        },
        "quality": {
          "enum": [
            "auto",
            "low",
            "medium",
            "high"
          ],
          "description": "Quality for the generated image",
          "type": "string",
          "title": "Quality",
          "default": "auto"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "description": "Output format for the images",
          "type": "string",
          "title": "Output Format",
          "default": "png"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_1.png",
              "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_2.png",
              "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_3.png",
              "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_4.png"
            ]
          ],
          "description": "The URLs of the images to use as a reference for the generation.",
          "type": "array",
          "title": "Image URLs",
          "items": {
            "type": "string"
          }
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_urls",
        "image_size",
        "background",
        "quality",
        "num_images",
        "output_format",
        "sync_mode"
      ],
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/reve/remix",
    "name": "Reve",
    "description": "Reve\u2019s remix model lets you upload an reference images and then combine/transform them via a text prompt",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/dMdAAEUeDONnrgO8mADcY_7cd44920d5e44ebeaa2d125d41bc75bb.jpg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_urls",
        "aspect_ratio",
        "num_images",
        "output_format",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "num_images": {
          "description": "Number of images to generate",
          "type": "integer",
          "examples": [
            1
          ],
          "title": "Number of Images",
          "minimum": 1,
          "maximum": 4,
          "default": 1
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "3:2",
            "2:3",
            "4:3",
            "3:4",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "examples": [
            "16:9"
          ],
          "description": "The desired aspect ratio of the generated image. If not provided, will be smartly chosen by the model."
        },
        "prompt": {
          "examples": [
            "Dress the model in the clothes and hat. Add a cat to the scene and change the background to a Victorian era building."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text description of the desired image. May include XML img tags like <img>0</img> to refer to specific images by their index in the image_urls list.",
          "minLength": 1,
          "maxLength": 2560
        },
        "image_urls": {
          "description": "List of URLs of reference images. Must provide between 1 and 6 images (inclusive). Each image must be less than 10 MB. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.",
          "type": "array",
          "items": {
            "type": "string"
          },
          "max_file_size": 10485760,
          "examples": [
            [
              "https://v3b.fal.media/files/b/monkey/lsPBOhBws_FnTzd5G9KZ9_seedream4_edit_input_4.png",
              "https://v3b.fal.media/files/b/monkey/ZrW5ouDj8vjLtvl1Cj9l9_seedream4_edit_input_2.png",
              "https://v3b.fal.media/files/b/elephant/sd0k6YhlQEKfR6d_hAmIH_seedream4_edit_input_3.png"
            ]
          ],
          "title": "Reference Image URLs",
          "min_height": 128,
          "min_width": 128,
          "max_height": 4096,
          "max_width": 4096
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "examples": [
            "png"
          ],
          "description": "Output format for the generated image.",
          "default": "png"
        }
      },
      "title": "ReveRemixInput",
      "description": "Input for Reve image remixing",
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/reve/edit",
    "name": "Reve",
    "description": "Reve\u2019s edit model lets you upload an existing image and then transform it via a text prompt",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/YAlxwxUbRgskrtV0PhkyL_d163391caef14a548907336e32899ee2.jpg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "num_images",
        "output_format",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "num_images": {
          "description": "Number of images to generate",
          "type": "integer",
          "examples": [
            1
          ],
          "title": "Number of Images",
          "minimum": 1,
          "maximum": 4,
          "default": 1
        },
        "prompt": {
          "examples": [
            "Give him a friend"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text description of how to edit the provided image.",
          "minLength": 1,
          "maxLength": 2560
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "examples": [
            "png"
          ],
          "description": "Output format for the generated image.",
          "default": "png"
        },
        "image_url": {
          "description": "URL of the reference image to edit. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.",
          "type": "string",
          "x-fal": {
            "min_width": 128,
            "timeout": 20,
            "min_height": 128,
            "max_width": 4096,
            "max_height": 4096,
            "max_file_size": 10485760
          },
          "title": "Reference Image URL",
          "examples": [
            "https://v3b.fal.media/files/b/koala/sZE6zNTKjOKc4kcUdVlu__26bac54c-3e94-43e9-aeff-f2efc2631ef0.webp"
          ],
          "limit_description": "Max file size: 10.0MB, Min width: 128px, Min height: 128px, Max width: 4096px, Max height: 4096px, Timeout: 20.0s"
        }
      },
      "title": "ReveEditInput",
      "description": "Input for Reve image editing",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/image2pixel",
    "name": "Image2Pixel",
    "description": "Turn images into pixel-perfect retro art",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/9MSg8Fm_djrKJ76DtwZrx_0ebf4aa3ab1540298b3fcf4593cfd606.jpg",
    "tags": [
      "post-processing",
      "pixel-art"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Image2PixelInput",
      "type": "object",
      "properties": {
        "cleanup_morph": {
          "description": "Apply morphological operations to remove noise.",
          "type": "boolean",
          "title": "Cleanup Morph",
          "default": false
        },
        "auto_color_detect": {
          "description": "Enable automatic detection of optimal number of colors.",
          "type": "boolean",
          "title": "Auto Color Detect",
          "default": false
        },
        "alpha_threshold": {
          "minimum": 0,
          "maximum": 255,
          "type": "integer",
          "description": "Alpha binarization threshold (0-255).",
          "title": "Alpha Threshold",
          "default": 128
        },
        "snap_grid": {
          "description": "Align output to the pixel grid.",
          "type": "boolean",
          "title": "Snap Grid",
          "default": true
        },
        "fixed_palette": {
          "description": "Optional fixed color palette as hex strings (e.g., ['#000000', '#ffffff']).",
          "type": "array",
          "title": "Fixed Palette",
          "items": {
            "type": "string"
          }
        },
        "scale": {
          "minimum": 1,
          "maximum": 64,
          "type": "integer",
          "description": "Force a specific pixel scale. If None, auto-detect.",
          "title": "Scale"
        },
        "background_tolerance": {
          "minimum": 0,
          "maximum": 255,
          "type": "integer",
          "description": "Background tolerance (0-255).",
          "title": "Background Tolerance",
          "default": 0
        },
        "trim_borders": {
          "description": "Trim borders of the image.",
          "type": "boolean",
          "title": "Trim Borders",
          "default": false
        },
        "cleanup_jaggy": {
          "description": "Remove isolated diagonal pixels (jaggy edge cleanup).",
          "type": "boolean",
          "title": "Cleanup Jaggy",
          "default": false
        },
        "detect_method": {
          "enum": [
            "auto",
            "runs",
            "edge"
          ],
          "description": "Scale detection method to use.",
          "type": "string",
          "title": "Detect Method",
          "default": "auto"
        },
        "transparent_background": {
          "description": "Remove background of the image. This will check for contiguous color regions from the edges after correction and make them transparent.",
          "type": "boolean",
          "title": "Transparent Background",
          "default": false
        },
        "downscale_method": {
          "enum": [
            "dominant",
            "median",
            "mode",
            "mean",
            "content-adaptive"
          ],
          "description": "Downscaling method to produce the pixel-art output.",
          "type": "string",
          "title": "Downscale Method",
          "default": "dominant"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/image2pixel-input.jpg"
          ],
          "description": "The image URL to process into improved pixel art",
          "type": "string",
          "title": "Image Url"
        },
        "background_mode": {
          "enum": [
            "edges",
            "corners",
            "midpoints"
          ],
          "description": "Controls where to flood-fill from when removing the background.",
          "type": "string",
          "title": "Background Mode",
          "default": "corners"
        },
        "max_colors": {
          "minimum": 1,
          "maximum": 256,
          "type": "integer",
          "description": "Maximum number of colors in the output palette. Set None to disable limit.",
          "title": "Max Colors",
          "default": 32
        },
        "dominant_color_threshold": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "description": "Dominant color threshold (0.0-1.0).",
          "title": "Dominant Color Threshold",
          "default": 0.05
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "max_colors",
        "auto_color_detect",
        "fixed_palette",
        "detect_method",
        "scale",
        "downscale_method",
        "trim_borders",
        "transparent_background",
        "cleanup_morph",
        "cleanup_jaggy",
        "snap_grid",
        "alpha_threshold",
        "dominant_color_threshold",
        "background_tolerance",
        "background_mode",
        "sync_mode"
      ],
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/dreamomni2/edit",
    "name": "DreamOmni2",
    "description": "DreamOmni2 is a unified multimodal model for text and image guided image editing.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/c4tQDAqMyMQ_6-LNFzCyj_13c4f35481fc4ebaaf4fddf9a5d86ddc.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "DreamOmni2Request",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Replace the first image have the same image style as the second image."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to edit the image."
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/koala/HB33rtG0ue7KzcIdQOTTX_dreamomni_ref_0.jpg",
              "https://v3b.fal.media/files/b/koala/BJMlXeNzOgGzyoO7XyGxr_dreamomni_ref_1.jpg"
            ]
          ],
          "title": "You can use only with to 2 images.",
          "type": "array",
          "description": "List of URLs of input images for editing.",
          "items": {
            "type": "string"
          }
        }
      },
      "x-fal-order-properties": [
        "image_urls",
        "prompt"
      ],
      "required": [
        "image_urls",
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/qwen-image-edit-plus-lora",
    "name": "Qwen Image Edit Plus Lora",
    "description": "LoRA endpoint for the Qwen Image Edit Plus model.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/penguin/X3V08aAYEqPmeSvVdLgN9_6be5ff6349c9459d92e7a5d7db8dadcc.jpg",
    "tags": [
      "image-to-image",
      "image-editing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseQwenEditImagePlusLoRAInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Close shot of a woman standing in next to this car on this highway"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the image with"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. If not provided, the size of the final input image will be used to calculate the size of the output image."
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
          "type": "string",
          "examples": [
            "regular"
          ],
          "title": "Acceleration",
          "default": "regular"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "image_urls": {
          "examples": [
            [
              "https://v3.fal.media/files/monkey/i3saq4bAPXSIl08nZtq9P_ec535747aefc4e31943136a6d8587075.png",
              "https://v3.fal.media/files/penguin/BCOZp6teRhSQFuOXpbBOa_da8ef9b4982347a2a62a516b737d4f21.png",
              "https://v3.fal.media/files/tiger/sCoZhBksx9DvwSR4_U3_C_3d1f581441874005908addeae9c10d0f.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URLs of the images to edit.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "image_urls",
        "negative_prompt",
        "acceleration",
        "loras"
      ],
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/lucidflux",
    "name": "Lucidflux",
    "description": "LucidFlux for upscaling images with very high fidelity",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/koala/IoOnMLFUyTCBXNJfw8p6d_04001a3f68e34de687b6de1a73d7e1de.jpg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LucidFluxRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "restore this image into high-quality, clean, high-resolution result"
          ],
          "description": "The prompt to edit the image.",
          "type": "string",
          "title": "Prompt"
        },
        "guidance": {
          "minimum": 1,
          "description": "The guidance to use for the diffusion process.",
          "type": "number",
          "maximum": 30,
          "title": "Guidance",
          "default": 4
        },
        "target_height": {
          "description": "The height of the output image.",
          "type": "integer",
          "minimum": 512,
          "maximum": 1024,
          "title": "Target Height",
          "default": 1024
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/elephant/6FLKRWYztzOKDKV-v1VfK_3.png"
          ],
          "description": "The URL of the image to edit.",
          "type": "string",
          "title": "Image URL"
        },
        "target_width": {
          "description": "The width of the output image.",
          "type": "integer",
          "minimum": 512,
          "maximum": 1024,
          "title": "Target Width",
          "default": 1024
        },
        "num_inference_steps": {
          "minimum": 2,
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "maximum": 50,
          "title": "Num Inference Steps",
          "default": 50
        },
        "seed": {
          "description": "Seed used for random number generation",
          "type": "integer",
          "title": "Seed",
          "default": 42
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "target_width",
        "target_height",
        "num_inference_steps",
        "guidance",
        "seed"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/qwen-image-edit/image-to-image",
    "name": "Qwen Image Edit",
    "description": "Image to Image Endpoint for Qwen's Image Editing model. Has superior text editing capabilities.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/lion/y1wOAl3dW0LE43drzjWY3_71e9575367b14485b4a5ca83492c0e82.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseQwenEditImg2ImgInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Change bag to apple macbook"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the image with"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
          "type": "string",
          "examples": [
            "regular"
          ],
          "title": "Acceleration",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/oei_-iPIYFnhdB8SxojND_qwen-edit-res.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to edit."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "Strength of the image-to-image transformation. Lower values preserve more of the original image.",
          "default": 0.94
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 30
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            "blurry, ugly"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "image_url",
        "negative_prompt",
        "acceleration",
        "strength"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/wan-25-preview/image-to-image",
    "name": "Wan 2.5 Image to Image",
    "description": "Wan 2.5 image-to-image model.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/panda/E-LG-LvtKaaYeyx_FPqmu_c75bdd0f332b455e80a7cf14a3a44725.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Reimagine the scene under a raging thunderstorm at night: lightning forks across the sky, illuminating the samurai in stark flashes of white light."
          ],
          "title": "Prompt",
          "type": "string",
          "minLength": 1,
          "description": "The text prompt describing how to edit the image. Max 2000 characters."
        },
        "num_images": {
          "description": "Number of images to generate. Values from 1 to 4.",
          "type": "integer",
          "minimum": 1,
          "maximum": 4,
          "examples": [
            1
          ],
          "title": "Num Images",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. Width and height must be between 384 and 1440 pixels.",
          "examples": [
            "square",
            "landscape_16_9",
            "portrait_16_9",
            {
              "height": 1280,
              "width": 1280
            }
          ],
          "default": "square"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "image_urls": {
          "description": "URLs of images to edit. For single-image editing, provide 1 URL. For multi-reference generation, provide up to 2 URLs. If more than 2 URLs are provided, only the first 2 will be used.",
          "type": "array",
          "items": {
            "type": "string"
          },
          "max_file_size": 26214400,
          "examples": [
            [
              "https://v3.fal.media/files/penguin/4VZ7I1ZK5XNv33LV2JBxg.png"
            ]
          ],
          "title": "Image Urls",
          "min_height": 384,
          "min_width": 384,
          "max_height": 5000,
          "max_width": 5000
        },
        "negative_prompt": {
          "examples": [
            "low resolution, error, worst quality, low quality, defects"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt to describe content to avoid. Max 500 characters."
        }
      },
      "description": "Input for image editing",
      "x-fal-order-properties": [
        "prompt",
        "image_urls",
        "negative_prompt",
        "image_size",
        "num_images",
        "seed",
        "enable_safety_checker"
      ],
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "easel-ai/product-photoshoot",
    "name": "Product Photoshoot",
    "description": "Create product advertisements with an example image of the product",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/koala/J7TJvEQBnQjHhNz4q8PDl_8c054226af1d48828c179031f2edf04d.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ProductPhotoShootInput",
      "type": "object",
      "properties": {
        "scene": {
          "examples": [
            "an image with a cheerful young boy sitting at a wooden kitchen table, wearing a bright blue sweatshirt, eating cereal from a white bowl with a spoon."
          ],
          "title": "Scene",
          "type": "string",
          "minLength": 64,
          "description": "Description of the scene in which the product is placed. (Minimum 64 characters.)"
        },
        "product_description": {
          "description": "A brief description of the product.",
          "type": "string",
          "examples": [
            "a box of cereal.",
            "a bottle of milk.",
            "a bag of dog food."
          ],
          "maxLength": 256,
          "title": "Product Description",
          "default": ""
        },
        "product_image": {
          "examples": [
            "https://images.easelai.com/product/special-k.webp",
            "https://images.easelai.com/product/cheerios.jpg"
          ],
          "title": "Product Image",
          "description": "An image of the product to be featured in the photoshoot.",
          "allOf": [
            {
              "$ref": "#/components/schemas/Image"
            }
          ]
        },
        "product_placement": {
          "examples": [
            "on a silver tray on the left side of the image",
            "on a wooden table",
            "on a granite kitchen counter"
          ],
          "maxLength": 128,
          "type": "string",
          "title": "Product Placement",
          "description": "Describe how the product is placed in the scene."
        },
        "output_format": {
          "enum": [
            "1:1 (2k)",
            "4:3",
            "16:9",
            "9:16",
            "1:1 (1k, Turbo)"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The desired output format for the generated image.",
          "default": "4:3"
        },
        "magic_blend_enabled": {
          "title": "Magic Blend Enabled",
          "type": "boolean",
          "description": "Enable Magic Blend to enhance the integration of the product into the scene.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "product_image",
        "product_description",
        "scene",
        "product_placement",
        "magic_blend_enabled",
        "output_format"
      ],
      "required": [
        "product_image",
        "scene",
        "product_placement"
      ]
    }
  },
  {
    "id": "fal-ai/qwen-image-edit-plus",
    "name": "Qwen Image Edit Plus",
    "description": "Endpoint for Qwen's Image Editing Plus model also known as Qwen-Image-Edit-2509. Has superior text editing capabilities and multi-image support.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/elephant/pGXxmNi6TrKTe864jBKW8_1bb43c6eab2349ab9c8cefbb24f3fd1b.jpg",
    "tags": [
      "image-editing",
      "image-to-image",
      "high-quality-text"
    ],
    "highlighted": false,
    "pinned": true,
    "input_schema": {
      "title": "BaseQwenEditImagePlusInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Close shot of a woman standing in next to this car on this highway"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the image with"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
          "type": "string",
          "examples": [
            "regular"
          ],
          "title": "Acceleration",
          "default": "regular"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 100,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 50
        },
        "image_urls": {
          "examples": [
            [
              "https://v3.fal.media/files/monkey/i3saq4bAPXSIl08nZtq9P_ec535747aefc4e31943136a6d8587075.png",
              "https://v3.fal.media/files/penguin/BCOZp6teRhSQFuOXpbBOa_da8ef9b4982347a2a62a516b737d4f21.png",
              "https://v3.fal.media/files/tiger/sCoZhBksx9DvwSR4_U3_C_3d1f581441874005908addeae9c10d0f.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URLs of the images to edit.",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "examples": [
            " "
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "image_urls",
        "negative_prompt",
        "acceleration"
      ],
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/seedvr/upscale/image",
    "name": "SeedVR2",
    "description": "Use SeedVR2 to upscale your images",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/panda/_-1rRy0_I6w-fbt3q0RDL_2f47fece6e2b433994dda482e8d20bb9.jpg",
    "tags": [
      "upscale",
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SeedVRImageInput",
      "type": "object",
      "properties": {
        "upscale_mode": {
          "enum": [
            "target",
            "factor"
          ],
          "title": "Upscale Mode",
          "type": "string",
          "description": "The mode to use for the upscale. If 'target', the upscale factor will be calculated based on the target resolution. If 'factor', the upscale factor will be used directly.",
          "default": "factor"
        },
        "noise_scale": {
          "description": "The noise scale to use for the generation process.",
          "type": "number",
          "minimum": 0,
          "title": "Noise Scale",
          "maximum": 1,
          "multipleOf": 0.001,
          "default": 0.1
        },
        "target_resolution": {
          "enum": [
            "720p",
            "1080p",
            "1440p",
            "2160p"
          ],
          "title": "Target Resolution",
          "type": "string",
          "description": "The target resolution to upscale to when `upscale_mode` is `target`.",
          "default": "1080p"
        },
        "output_format": {
          "enum": [
            "png",
            "jpg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image.",
          "default": "jpg"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/seedvr2/image_in.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The input image to be processed"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "upscale_factor": {
          "minimum": 1,
          "title": "Upscale Factor",
          "type": "number",
          "description": "Upscaling factor to be used. Will multiply the dimensions with this factor when `upscale_mode` is `factor`.",
          "maximum": 10,
          "default": 2
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The random seed used for the generation process."
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "upscale_mode",
        "upscale_factor",
        "target_resolution",
        "seed",
        "noise_scale",
        "output_format",
        "sync_mode"
      ],
      "required": [
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/image-apps-v2/product-holding",
    "name": "Product Holding",
    "description": "Place products naturally in a person\u2019s hands for realistic marketing visuals.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/zebra/7dJ2m31gOP0J0m8WZJ46I_1625d9610207407292eac394cc4a3026.jpg",
    "tags": [
      "product",
      "marketing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "person_image_url",
        "product_image_url",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "product_image_url": {
          "examples": [
            "https://v3.fal.media/files/tiger/WqtPStHkOu6W0lZcIlXD8_156e3c91cb3a4d12b7380cc43b5e4c67.png"
          ],
          "description": "Image URL of the product to be held by the person",
          "type": "string",
          "title": "Product Image Url"
        },
        "person_image_url": {
          "examples": [
            "https://v3.fal.media/files/panda/oMob58qZJRtbDs5l45QKT_e3a1512c455d425fab2d62e07a51c506.png"
          ],
          "description": "Image URL of the person who will hold the product",
          "type": "string",
          "title": "Person Image Url"
        }
      },
      "title": "ProductHoldingInput",
      "required": [
        "person_image_url",
        "product_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/product-photography",
    "name": "Product Photography",
    "description": "Generate professional product photography with realistic lighting and backgrounds.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/penguin/g36T9svKmdie3DHtxJz5x_67cde98934654713bf484b258e2384f3.jpg",
    "tags": [
      "product",
      "marketing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "product_image_url",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "product_image_url": {
          "examples": [
            "https://v3.fal.media/files/tiger/WqtPStHkOu6W0lZcIlXD8_156e3c91cb3a4d12b7380cc43b5e4c67.png"
          ],
          "description": "Image URL of the product to create professional studio photography",
          "type": "string",
          "title": "Product Image Url"
        }
      },
      "title": "ProductPhotographyInput",
      "required": [
        "product_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/virtual-try-on",
    "name": "Virtual Try-on",
    "description": "Try on clothes virtually by combining person and clothing images.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/tiger/dd5748sfMpq2uZzoUA_Y3_6377b3f9ee8e49afa174da674a80b9a6.jpg",
    "tags": [
      "fashion",
      "try-on",
      "virtual-try-on"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "person_image_url",
        "clothing_image_url",
        "preserve_pose",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "preserve_pose": {
          "title": "Preserve Pose",
          "type": "boolean",
          "default": true
        },
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output (default: 3:4 for fashion)",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "clothing_image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/monkey/5ZWXSKUuk9EilI1apFCeu_1ecd050187f24b9aa1d2defb88d8d8ae.png"
          ],
          "description": "Clothing photo URL",
          "type": "string",
          "title": "Clothing Image Url"
        },
        "person_image_url": {
          "examples": [
            "https://v3.fal.media/files/tiger/4vxSHizex4UWR5fdnPs1A.jpeg"
          ],
          "description": "Person photo URL",
          "type": "string",
          "title": "Person Image Url"
        }
      },
      "title": "VirtualTryOnInput",
      "required": [
        "person_image_url",
        "clothing_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/texture-transform",
    "name": "Texture Transform",
    "description": "Transform objects with different surface textures like marble, wood, or fabric.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/kangaroo/gzXctbp7SzO3xaVpDEqtN_97343b9e7b404a3e8f042b1d7d57a12f.jpg",
    "tags": [
      "texture-transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "target_texture",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "target_texture": {
          "enum": [
            "cotton",
            "denim",
            "wool",
            "felt",
            "wood",
            "leather",
            "velvet",
            "stone",
            "marble",
            "ceramic",
            "concrete",
            "brick",
            "clay",
            "foam",
            "glass",
            "metal",
            "silk",
            "fabric",
            "crystal",
            "rubber",
            "plastic",
            "lace"
          ],
          "title": "Target Texture",
          "type": "string",
          "default": "marble"
        },
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/tiger/WqtPStHkOu6W0lZcIlXD8_156e3c91cb3a4d12b7380cc43b5e4c67.png"
          ],
          "description": "Image URL for texture transformation",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "TextureTransformInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/relighting",
    "name": "Relighting",
    "description": "Adjust and enhance images with different lighting styles.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/koala/W0d6z5pWtVwakzxtKd4K4_94f6ab5b5820440db672dce73d447bff.jpg",
    "tags": [
      "relighting"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "lighting_style",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "lighting_style": {
          "enum": [
            "natural",
            "studio",
            "golden_hour",
            "blue_hour",
            "dramatic",
            "soft",
            "hard",
            "backlight",
            "side_light",
            "front_light",
            "rim_light",
            "sunset",
            "sunrise",
            "neon",
            "candlelight",
            "moonlight",
            "spotlight",
            "ambient"
          ],
          "title": "Lighting Style",
          "type": "string",
          "default": "natural"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/monkey/tugG2Q-XqMgf_ZoBr8KFO.jpeg"
          ],
          "description": "Image URL for relighting",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "RelightingInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/style-transfer",
    "name": "Style Transfer",
    "description": "Apply artistic styles like impressionism, cubism, or surrealism to your images.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/kangaroo/uZNy5XjPfUQJOs0Kuw7C4_367de9bbd3034716b9432d637c3b369d.jpg",
    "tags": [
      "style-transfer"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "style_reference_image_url",
        "target_style",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "target_style": {
          "enum": [
            "anime_character",
            "cartoon_3d",
            "hand_drawn_animation",
            "cyberpunk_future",
            "anime_game_style",
            "comic_book_animation",
            "animated_series",
            "cartoon_animation",
            "lofi_aesthetic",
            "cottagecore",
            "dark_academia",
            "y2k",
            "vaporwave",
            "liminal_space",
            "weirdcore",
            "dreamcore",
            "synthwave",
            "outrun",
            "photorealistic",
            "hyperrealistic",
            "digital_art",
            "concept_art",
            "impressionist",
            "anime",
            "pixel_art",
            "claymation"
          ],
          "title": "Target Style",
          "type": "string",
          "default": "impressionist"
        },
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "style_reference_image_url": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "description": "Optional reference image URL. When provided, the style will be inferred from this image instead of the selected preset style.",
          "title": "Style Reference Image Url"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/tiger/vAohCtb_N8Q_cAs9Z03GS.jpeg"
          ],
          "description": "Image URL for style transfer",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "StyleTransferInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/photo-restoration",
    "name": "Photo Restoration",
    "description": "Restore old or damaged photos by fixing colors, scratches, and resolution.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/kangaroo/oP9mu0F1Obx0ufyEEVAgn_3f7a878f3cf54a078fa8e0d53524020a.jpg",
    "tags": [
      "photo-restoration",
      "image-enhance"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "enhance_resolution",
        "fix_colors",
        "remove_scratches",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "enhance_resolution": {
          "title": "Enhance Resolution",
          "type": "boolean",
          "default": true
        },
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output (default: 4:3 for classic photos)",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "remove_scratches": {
          "title": "Remove Scratches",
          "type": "boolean",
          "default": true
        },
        "fix_colors": {
          "title": "Fix Colors",
          "type": "boolean",
          "default": true
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/panda/BcOIyOJ5Z1-GOjDi_GmsX_50e353c588c74435882f8f68989b4af5.png"
          ],
          "description": "Old or damaged photo URL to restore",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "PhotoRestorationInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/portrait-enhance",
    "name": "Portrait Enhance",
    "description": "Enhance and refine portrait photos with improved clarity and detail.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/monkey/9kZMXV4GvRettHUuudKER_3f04e4f8fd0e4f28ad957c2a3bf9f3e5.jpg",
    "tags": [
      "image-edit",
      "enhancement"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/monkey/VszUszGx2uzReqFvQzF26.jpg"
          ],
          "description": "Portrait image URL to enhance",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "PortraitInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/photography-effects",
    "name": "Photography Effects",
    "description": "Apply diverse photography styles and effects to transform your images.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/rabbit/QHdnOcB8IwyNRSkQOeVWE_aad27ab63cee47e8b6c15254f6813ac2.jpg",
    "tags": [
      "style-transfer",
      "photography"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "effect_type",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "effect_type": {
          "enum": [
            "film",
            "vintage_film",
            "portrait_photography",
            "fashion_photography",
            "street_photography",
            "sepia_tone",
            "film_grain",
            "light_leaks",
            "vignette_effect",
            "instant_camera",
            "golden_hour",
            "dramatic_lighting",
            "soft_focus",
            "bokeh_effect",
            "high_contrast",
            "double_exposure"
          ],
          "title": "Effect Type",
          "type": "string",
          "default": "film"
        },
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/monkey/tugG2Q-XqMgf_ZoBr8KFO.jpeg"
          ],
          "description": "Image URL for photography effects",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "PhotographyEffectsInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/perspective",
    "name": "Perspective Change",
    "description": "Easily adjust the perspective of any image to different angles.",
    "category": "image-to-image",
    "thumbnail_url": "https://v3.fal.media/files/rabbit/PjquFEk5HynXyIj8Z1Xke_4ef010a6c99b4fa2a1f6639c233f8b93.jpg",
    "tags": [
      "change-angle",
      "perspective"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "target_perspective",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "target_perspective": {
          "enum": [
            "front",
            "left_side",
            "right_side",
            "back",
            "top_down",
            "bottom_up",
            "birds_eye",
            "three_quarter_left",
            "three_quarter_right"
          ],
          "title": "Target Perspective",
          "type": "string",
          "default": "front"
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/lion/aqEiZ8Ui6rxWUB-Ujfu79_52c238c6d75d45538eaa71c50d329ba0.png"
          ],
          "description": "Image URL for perspective change",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "PerspectiveInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/object-removal",
    "name": "Object Removal",
    "description": "Remove unwanted objects seamlessly from any image.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/rabbit/m-e8Cm424GRXU0JdKie8l_915251cbaa4b4130a55547fde0f5bd36.jpg",
    "tags": [
      "remove",
      "object-removal"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "object_to_remove",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "object_to_remove": {
          "description": "Object to remove",
          "type": "string",
          "title": "Object To Remove"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/L_YMy6H5r_HYMacZX1qne_74a8fb6130164a18930af55370a1c9b2.png"
          ],
          "description": "Image URL containing object to remove",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "ObjectRemovalInput",
      "required": [
        "image_url",
        "object_to_remove"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/headshot-photo",
    "name": "Headshot Generator",
    "description": "Generate professional headshot photos with customizable backgrounds.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/koala/F4h1jbZoExQGajA6HDsTi_60aacfe738274239a2eb930f8c885bfa.jpg",
    "tags": [
      "headshot",
      "profile-photo"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "background_style",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "background_style": {
          "enum": [
            "professional",
            "corporate",
            "clean",
            "gradient"
          ],
          "title": "Background Style",
          "type": "string",
          "default": "professional"
        },
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/panda/oMob58qZJRtbDs5l45QKT_e3a1512c455d425fab2d62e07a51c506.png"
          ],
          "description": "Portrait image URL to convert to professional headshot",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "HeadshotInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/hair-change",
    "name": "Hair Change",
    "description": "Change hairstyles and hair colors in photos realistically.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/zebra/bfNDAz9O7I1IzLIMnQON0_5faa305ab343464989f49415737cc39d.jpg",
    "tags": [
      "hair-edit",
      "style-change"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "target_hairstyle",
        "hair_color",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "target_hairstyle": {
          "enum": [
            "short_hair",
            "medium_long_hair",
            "long_hair",
            "curly_hair",
            "wavy_hair",
            "high_ponytail",
            "bun",
            "bob_cut",
            "pixie_cut",
            "braids",
            "straight_hair",
            "afro",
            "dreadlocks",
            "buzz_cut",
            "mohawk",
            "bangs",
            "side_part",
            "middle_part"
          ],
          "title": "Target Hairstyle",
          "type": "string",
          "default": "long_hair"
        },
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "hair_color": {
          "enum": [
            "black",
            "dark_brown",
            "light_brown",
            "blonde",
            "platinum_blonde",
            "red",
            "auburn",
            "gray",
            "silver",
            "blue",
            "green",
            "purple",
            "pink",
            "rainbow",
            "natural",
            "highlights",
            "ombre",
            "balayage"
          ],
          "title": "Hair Color",
          "type": "string",
          "default": "natural"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/1ois7lqES78dLualcytmS_1e088ef24f474972824cffcfdd7ff291.png"
          ],
          "description": "Portrait image URL for hair change",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "HairChangeInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/expression-change",
    "name": "Expression Change",
    "description": "Change facial expressions in photos with realistic results.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/panda/2ZF-wegMjX4YdYMzLlauc_6176038c50b8492694be5872b350aa5d.jpg",
    "tags": [
      "face-edit",
      "expression-change"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "target_expression",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "target_expression": {
          "enum": [
            "smile",
            "surprise",
            "glare",
            "panic",
            "shyness",
            "laugh",
            "cry",
            "angry",
            "sad",
            "happy",
            "excited",
            "shocked",
            "confused",
            "focused",
            "dreamy",
            "serious",
            "playful",
            "mysterious",
            "confident",
            "thoughtful"
          ],
          "title": "Target Expression",
          "type": "string",
          "default": "smile"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/kangaroo/Gk5_0En-p1CNYnGOCDkl1_8332b944f8334ba9b3118b49e3e641cf.png"
          ],
          "description": "Portrait image URL for expression change",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "ExpressionChangeInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/city-teleport",
    "name": "City Teleport",
    "description": "Place a person\u2019s photo into iconic cities worldwide.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/elephant/dorvx78TXh0JIi4CASrhw_967925f37afb4f3489b89712b0639311.jpg",
    "tags": [
      "city-teleport",
      "backgroundswap"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "person_image_url",
        "city_image_url",
        "city_name",
        "photo_shot",
        "camera_angle",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "city_image_url": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "description": "Optional city background image URL. When provided, the person will be blended into this custom scene.",
          "title": "City Image Url"
        },
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "city_name": {
          "examples": [
            "Paris"
          ],
          "description": "City name (used when city_image_url is not provided)",
          "type": "string",
          "title": "City Name"
        },
        "photo_shot": {
          "enum": [
            "extreme_close_up",
            "close_up",
            "medium_close_up",
            "medium_shot",
            "medium_long_shot",
            "long_shot",
            "extreme_long_shot",
            "full_body"
          ],
          "description": "Type of photo shot",
          "type": "string",
          "title": "Photo Shot",
          "default": "medium_shot"
        },
        "camera_angle": {
          "enum": [
            "eye_level",
            "low_angle",
            "high_angle",
            "dutch_angle",
            "birds_eye_view",
            "worms_eye_view",
            "overhead",
            "side_angle"
          ],
          "description": "Camera angle for the shot",
          "type": "string",
          "title": "Camera Angle",
          "default": "eye_level"
        },
        "person_image_url": {
          "examples": [
            "https://v3.fal.media/files/kangaroo/qsFWu-bO3FwcTQSym9HeL_e52f70668f2940a3b4ea2cab54fcb65b.png"
          ],
          "description": "Person photo URL",
          "type": "string",
          "title": "Person Image Url"
        }
      },
      "title": "CityTeleportInput",
      "required": [
        "person_image_url",
        "city_name"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/age-modify",
    "name": "Age Modify",
    "description": "Modify a face to look younger or older while keeping identity realistic.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/panda/HOgA2l7XskHnD0rcabkPc_43ce3b12df8043d4aa6c9b98497ea32b.jpg",
    "tags": [
      "age-transformation",
      "face-editing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "target_age",
        "preserve_identity",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "target_age": {
          "minimum": 6,
          "maximum": 100,
          "type": "integer",
          "title": "Target Age",
          "default": 30
        },
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "preserve_identity": {
          "title": "Preserve Identity",
          "type": "boolean",
          "default": true
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/lion/s2GShUC7AB9i-ypYV0DbI_1b5ca4fe5d7e477fb4501acf9a1c43bc.png"
          ],
          "description": "Portrait image URL for age modification",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "AgeModifyInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/image-apps-v2/makeup-application",
    "name": "Makeup Changer",
    "description": "Apply realistic makeup styles with adjustable intensity.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/penguin/v3-_Ppam38Pq8cZ70oZPM_03aaba849a774a1f8e3a4bf4fbf6777f.jpg",
    "tags": [
      "makeup",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "makeup_style",
        "intensity",
        "aspect_ratio"
      ],
      "type": "object",
      "properties": {
        "aspect_ratio": {
          "description": "Aspect ratio for 4K output (default: 3:4 for portraits)",
          "$ref": "#/components/schemas/AspectRatio"
        },
        "makeup_style": {
          "enum": [
            "natural",
            "glamorous",
            "smoky_eyes",
            "bold_lips",
            "no_makeup",
            "remove_makeup",
            "dramatic",
            "bridal",
            "professional",
            "korean_style",
            "artistic"
          ],
          "title": "Makeup Style",
          "type": "string",
          "default": "natural"
        },
        "intensity": {
          "enum": [
            "light",
            "medium",
            "heavy",
            "dramatic"
          ],
          "title": "Intensity",
          "type": "string",
          "default": "medium"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/elephant/jpdD30YLw3OfPdVDxq1-D_1ec2e27f3e7d400fbf5f7aa2b80e89f0.png"
          ],
          "description": "Portrait image URL for makeup application",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "MakeupApplicationInput",
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/qwen-image-edit/inpaint",
    "name": "Qwen Image Edit",
    "description": "Inpainting Endpoint for the Qwen Edit Image editing model.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/penguin/h_viUqwLJqnKY98Is1-HS_5c63021b7458464296a4fa264837f480.jpg",
    "tags": [
      "image-to-image",
      "inpainting",
      "qwen-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseQwenEditInpaintImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Change the ball to a black and white football"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the image with"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
          "type": "string",
          "examples": [
            "regular"
          ],
          "title": "Acceleration",
          "default": "regular"
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "blurry, ugly"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/image_kontext_inpaint.jpeg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to edit."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "Strength of noising process for inpainting",
          "default": 0.93
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "mask_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/mask_kontext_inpaint.png"
          ],
          "title": "Mask URL",
          "type": "string",
          "description": "The URL of the mask for inpainting"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 30
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "image_url",
        "negative_prompt",
        "acceleration",
        "mask_url",
        "strength"
      ],
      "required": [
        "prompt",
        "image_url",
        "mask_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux/srpo/image-to-image",
    "name": "FLUX.1 SRPO [dev]",
    "description": "FLUX.1 SRPO [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.\n",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/lion/h6ZndwWNcRsiobOzKCSmL_4ab6291336a74f78b4c90d9b42e97ab0.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseSRPOImageToInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cat dressed as a wizard with a background of a mystic forest."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "none"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate an image from."
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "The strength of the initial image. Higher strength values are better for this model.",
          "default": 0.95
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 10,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 40
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 4.5
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "strength",
        "num_inference_steps",
        "prompt",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-1/srpo/image-to-image",
    "name": "FLUX.1 SRPO [dev]",
    "description": "FLUX.1 SRPO [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.\n",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/panda/Lw4P1PGZPkZkAPI3u_Mxt_709597e8d0024e10ab25dfdf31963d0a.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseSRPOFlux1ImageToInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cat dressed as a wizard with a background of a mystic forest."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate an image from."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "The strength of the initial image. Higher strength values are better for this model.",
          "default": 0.95
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        },
        "num_inference_steps": {
          "minimum": 10,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 40
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 4.5
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "strength",
        "num_inference_steps",
        "prompt",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/qwen-image-edit-lora",
    "name": "Qwen Image Edit Lora",
    "description": "LoRA inference endpoint for the Qwen Image Editing model.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/koala/TLOrc_UR0t-P9eEqdlnKO_7873734a28ad4a5085fdb207645a902f.jpg",
    "tags": [
      "image-to-image",
      "image-editing",
      "lora"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseQwenEditImageLoRAInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Change bag to apple macbook"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the image with"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
          "type": "string",
          "examples": [
            "regular"
          ],
          "title": "Acceleration",
          "default": "none"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/oei_-iPIYFnhdB8SxojND_qwen-edit-res.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to edit."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 30
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            "blurry, ugly"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "image_url",
        "negative_prompt",
        "acceleration",
        "loras"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/vidu/reference-to-image",
    "name": "Vidu",
    "description": "Vidu Reference-to-Image creates images by using a reference images and combining them with a prompt.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/vidu/vidu.webp",
    "tags": [
      "images-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ReferenceToImageRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The little devil is looking at the apple on the beach and walking around it."
          ],
          "maxLength": 1500,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 1500 characters"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the output video",
          "default": "16:9"
        },
        "reference_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference1.png",
              "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference2.png",
              "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference3.png"
            ]
          ],
          "title": "Reference Image Urls",
          "type": "array",
          "description": "URLs of the reference images to use for consistent subject appearance",
          "items": {
            "type": "string"
          }
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "reference_image_urls",
        "aspect_ratio",
        "seed"
      ],
      "required": [
        "prompt",
        "reference_image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/bytedance/seedream/v4/edit",
    "name": "Bytedance Seedream v4 Edit",
    "description": "A new-generation image creation model ByteDance, Seedream 4.0 integrates image generation and image editing capabilities into a single, unified architecture.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/panda/6sPEukO8Ky0J7Y3dgv-OV_33a012d1372c4951942465b87a3d83ce.jpg",
    "tags": [
      "stylized",
      "transform",
      "editing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_images",
        "max_images",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "enhance_prompt_mode",
        "image_urls"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Dress the model in the clothes and hat. Add a cat to the scene and change the background to a Victorian era building."
          ],
          "description": "The text prompt used to edit the image",
          "type": "string",
          "title": "Prompt"
        },
        "num_images": {
          "minimum": 1,
          "description": "Number of separate model generations to be run with the prompt.",
          "type": "integer",
          "title": "Num Images",
          "maximum": 6,
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9",
                "auto",
                "auto_2K",
                "auto_4K"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. The minimum total image area is 921600 pixels. Failing this, the image size will be adjusted to by scaling it up, while maintaining the aspect ratio.",
          "title": "Image Size",
          "examples": [
            {
              "height": 2160,
              "width": 3840
            }
          ],
          "default": {
            "height": 2048,
            "width": 2048
          }
        },
        "enhance_prompt_mode": {
          "enum": [
            "standard",
            "fast"
          ],
          "description": "The mode to use for enhancing prompt enhancement. Standard mode provides higher quality results but takes longer to generate. Fast mode provides average quality results but takes less time to generate.",
          "type": "string",
          "title": "Enhance Prompt Mode",
          "default": "standard"
        },
        "max_images": {
          "minimum": 1,
          "description": "If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`. The total number of images (image inputs + image outputs) must not exceed 15",
          "type": "integer",
          "title": "Max Images",
          "maximum": 6,
          "default": 1
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "seed": {
          "description": "Random seed to control the stochasticity of image generation.",
          "type": "integer",
          "title": "Seed"
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_1.png",
              "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_2.png",
              "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_3.png",
              "https://storage.googleapis.com/falserverless/example_inputs/seedream4_edit_input_4.png"
            ]
          ],
          "description": "List of URLs of input images for editing. Presently, up to 10 image inputs are allowed. If over 10 images are sent, only the last 10 will be used.",
          "type": "array",
          "title": "Image URLs",
          "items": {
            "type": "string"
          }
        }
      },
      "title": "SeedDream4EditInput",
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/image-to-image",
    "name": "Wan",
    "description": "Wan 2.2's 14B model edit high-resolution, photorealistic images with powerful prompt understanding and fine-grained visual detail",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanI2IRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cinematic shot of an ancient city at sunset, intricate stone buildings, warm golden light"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide image generation."
        },
        "shift": {
          "minimum": 1,
          "maximum": 10,
          "type": "number",
          "title": "Shift",
          "default": 2
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "examples": [
            "regular"
          ],
          "default": "regular"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size"
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 10,
          "type": "number",
          "title": "Guidance Scale",
          "description": "Classifier-free guidance scale.",
          "default": 3.5
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "image_format": {
          "enum": [
            "png",
            "jpeg"
          ],
          "title": "Image Format",
          "type": "string",
          "description": "The format of the output image.",
          "examples": [
            "jpeg"
          ],
          "default": "jpeg"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated image. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/wan-image-to-image-input.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the input image."
        },
        "strength": {
          "description": "Denoising strength. 1.0 = fully remake; 0.0 = preserve original.",
          "type": "number",
          "minimum": 0,
          "maximum": 1,
          "title": "Strength",
          "default": 0.5
        },
        "guidance_scale_2": {
          "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            4
          ],
          "title": "Guidance Scale (2nd Stage)",
          "default": 4
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 40,
          "examples": [
            27
          ],
          "title": "Number of Inference Steps",
          "default": 27
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "strength",
        "negative_prompt",
        "seed",
        "aspect_ratio",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "guidance_scale",
        "guidance_scale_2",
        "shift",
        "image_size",
        "image_format"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/uso",
    "name": "Uso",
    "description": "Use USO to perform subject driven generations using reference image.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/kangaroo/5WCxaQjQ18eFu6qeVTJ2w_700fa4cd63ee445ca3d8d6cd94a356d5.jpg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "USOInputImage",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A handsome man."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt for generation. Can be empty for pure style transfer.",
          "default": ""
        },
        "num_images": {
          "minimum": 1,
          "title": "Number of Images",
          "type": "integer",
          "maximum": 4,
          "description": "Number of images to generate in parallel.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. ",
          "default": "square_hd"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "Output image format. PNG preserves transparency, JPEG is smaller.",
          "default": "png"
        },
        "keep_size": {
          "title": "Keep Input Size",
          "type": "boolean",
          "description": "Preserve the layout and dimensions of the input content image. Useful for style transfer.",
          "default": false
        },
        "input_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/USO/style3.webp",
              "https://storage.googleapis.com/falserverless/USO/style4.webp"
            ]
          ],
          "title": "Reference Images",
          "type": "array",
          "description": "List of image URLs in order: [content_image, style_image, extra_style_image].",
          "items": {
            "type": "string"
          }
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If true, wait for generation and upload before returning. Increases latency but provides immediate access to images.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale (CFG)",
          "type": "number",
          "maximum": 10,
          "description": "How closely to follow the prompt. Higher values stick closer to the prompt.",
          "default": 4
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "Number of denoising steps. More steps can improve quality but increase generation time.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducible generation. Use same seed for consistent results."
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, distorted, ugly, bad anatomy",
            "cartoon, anime, illustration",
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "What you don't want in the image. Use it to exclude unwanted elements, styles, or artifacts.",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Safety Checker",
          "type": "boolean",
          "description": "Enable NSFW content detection and filtering.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "input_image_urls",
        "image_size",
        "negative_prompt",
        "num_inference_steps",
        "guidance_scale",
        "keep_size",
        "num_images",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "input_image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/gemini-25-flash-image/edit",
    "name": "Gemini 2.5 Flash Image",
    "description": "Gemini 2.5 Flash Image is Google's state-of-the-art image generation and editing model\n",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/tiger/w7rvVqvAQiYg2cDSZTn2i_b6895b8a0f864c42a33bfd040dc1228c.jpg",
    "tags": [
      "image-editing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "NanoBananaImageToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "make a photo of the man driving the car down the california coastline"
          ],
          "maxLength": 5000,
          "minLength": 3,
          "description": "The prompt for image editing.",
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "anyOf": [
            {
              "enum": [
                "auto",
                "21:9",
                "16:9",
                "3:2",
                "4:3",
                "5:4",
                "1:1",
                "4:5",
                "3:4",
                "2:3",
                "9:16"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "description": "The aspect ratio of the generated image.",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Number of Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "description": "The format of the generated image.",
          "type": "string",
          "title": "Output Format",
          "default": "png"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input.png",
              "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input-2.png"
            ]
          ],
          "description": "The URLs of the images to use for image-to-image generation or image editing.",
          "type": "array",
          "title": "Image URLs",
          "items": {
            "type": "string"
          }
        },
        "limit_generations": {
          "description": "Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.",
          "type": "boolean",
          "title": "Limit Generations",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode",
        "image_urls",
        "limit_generations"
      ],
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/qwen-image/image-to-image",
    "name": "Qwen Image",
    "description": "Qwen-Image (Image-to-Image) transforms and edits input images with high fidelity, enabling precise style transfer, enhancement, and creative modification.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/koala/6JAMNCSti-vm-zJeZi6hA_626cdc11d4d04560ac9523fbd61f2eac.jpg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "QwenImageI2IInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Mount Fuji with purple japanese wisteria in the foreground, clear sky, peaceful spring day, soft natural light, landscape, painted with oil brush on a wood panel with abstract mixed colors"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the image with"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. Options: 'none', 'regular', 'high'. Higher acceleration increases speed. 'regular' balances speed and quality. 'high' is recommended for images without text.",
          "examples": [
            "none"
          ],
          "default": "none"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. By default, we will use the provided image for determining the image_size."
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale",
          "type": "number",
          "maximum": 20,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 2.5
        },
        "use_turbo": {
          "examples": [
            true
          ],
          "title": "Use Turbo",
          "type": "boolean",
          "description": "Enable turbo mode for faster generation with high quality. When enabled, uses optimized settings (10 steps, CFG=1.2).",
          "default": false
        },
        "negative_prompt": {
          "examples": [
            "blurry, ugly"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/rabbit/KoIbq6nhDBDPxDQrivW-m.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The reference image to guide the generation."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "strength": {
          "description": "Denoising strength. 1.0 = fully remake; 0.0 = preserve original.",
          "type": "number",
          "examples": [
            0.8
          ],
          "maximum": 1,
          "title": "Strength",
          "minimum": 0,
          "default": 0.6
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 250,
          "description": "The number of inference steps to perform.",
          "default": 30
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "negative_prompt",
        "acceleration",
        "loras",
        "use_turbo",
        "image_url",
        "strength"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "bria/reimagine/3.2",
    "name": "Reimagine",
    "description": "Reimagine uses a structure reference for generating new images while preserving the structure of an input image, guided by text prompts.\nPerfect for transforming sketches, illustrations, or photos into new illustrations. Trained exclusively on licensed data",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/koala/jkGFvEL6cLvJsAPkL48qP_f74234f867b84e23aaf691d48124fb85.jpg",
    "tags": [
      "bria"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "InputModel",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Delicate, watercolor-style letters infused with shades of blue and green, accompanied by artistic, blooming flowers that blend harmoniously into a light background, giving a serene and artistic touch."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Prompt for image generation."
        },
        "depth_preprocess": {
          "title": "Depth Preprocess",
          "type": "boolean",
          "description": "Depth image preprocess.",
          "default": true
        },
        "canny_preprocess": {
          "title": "Canny Preprocess",
          "type": "boolean",
          "description": "Canny image preprocess.",
          "default": true
        },
        "depth_image_url": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Depth Image Url",
          "description": "Depth control image (file or URL).",
          "examples": [
            "https://bria-image-repository.s3.us-east-1.amazonaws.com/BRIA+(1).png"
          ],
          "default": ""
        },
        "guidance_scale": {
          "description": "Guidance scale for text.",
          "type": "number",
          "minimum": 1,
          "title": "Guidance Scale",
          "maximum": 10,
          "default": 5
        },
        "canny_image_url": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Canny Image Url",
          "description": "Canny edge control image (file or URL).",
          "examples": [
            "https://bria-image-repository.s3.us-east-1.amazonaws.com/BRIA+(1).png"
          ],
          "default": ""
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for image generation.",
          "default": "Logo,Watermark,Ugly,Morbid,Extra fingers,Poorly drawn hands,Mutation,Blurry,Extra limbs,Gross proportions,Missing arms,Mutated hands,Long neck,Duplicate,Mutilated,Mutilated hands,Poorly drawn face,Deformed,Bad anatomy,Cloned face,Malformed limbs,Missing legs,Too many fingers"
        },
        "depth_scale": {
          "description": "Depth control strength (0.0 to 1.0).",
          "type": "number",
          "minimum": 0,
          "title": "Depth Scale",
          "maximum": 1,
          "default": 0.5
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "2:3",
            "3:2",
            "3:4",
            "4:3",
            "4:5",
            "5:4",
            "9:16",
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9",
          "default": "1:1"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If true, returns the image directly in the response (increases latency).",
          "default": false
        },
        "prompt_enhancer": {
          "title": "Prompt Enhancer",
          "type": "boolean",
          "description": "Whether to improve the prompt.",
          "default": true
        },
        "truncate_prompt": {
          "title": "Truncate Prompt",
          "type": "boolean",
          "description": "Whether to truncate the prompt.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility.",
          "default": 5555
        },
        "canny_scale": {
          "description": "Canny edge control strength (0.0 to 1.0).",
          "type": "number",
          "minimum": 0,
          "title": "Canny Scale",
          "maximum": 1,
          "default": 0.5
        },
        "num_inference_steps": {
          "description": "Number of inference steps.",
          "type": "integer",
          "minimum": 20,
          "title": "Num Inference Steps",
          "maximum": 50,
          "default": 30
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_inference_steps",
        "seed",
        "aspect_ratio",
        "negative_prompt",
        "guidance_scale",
        "truncate_prompt",
        "prompt_enhancer",
        "sync_mode",
        "depth_image_url",
        "depth_scale",
        "depth_preprocess",
        "canny_image_url",
        "canny_preprocess",
        "canny_scale"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/nano-banana/edit",
    "name": "Nano Banana",
    "description": "Google's state-of-the-art image generation and editing model",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/koala/1iXUmtPWBg9oNTpkAv48W_ce1da4146f99452f8c1dfe58dd2b150e.jpg",
    "tags": [
      "image-editing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "NanoBananaImageToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "make a photo of the man driving the car down the california coastline"
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 5000,
          "minLength": 3,
          "description": "The prompt for image editing."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Number of Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "aspect_ratio": {
          "anyOf": [
            {
              "enum": [
                "auto",
                "21:9",
                "16:9",
                "3:2",
                "4:3",
                "5:4",
                "1:1",
                "4:5",
                "3:4",
                "2:3",
                "9:16"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image.",
          "default": "auto"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "limit_generations": {
          "title": "Limit Generations",
          "type": "boolean",
          "description": "Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.",
          "default": false
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input.png",
              "https://storage.googleapis.com/falserverless/example_inputs/nano-banana-edit-input-2.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URLs of the images to use for image-to-image generation or image editing.",
          "items": {
            "type": "string"
          }
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode",
        "image_urls",
        "limit_generations"
      ],
      "required": [
        "prompt",
        "image_urls"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/nextstep-1",
    "name": "Nextstep 1",
    "description": "Endpoint for NextStep-1 Autoregressive Image Editing model.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/zebra/mA2AtvaSMWo6PQZ7NBKaC_4e2f5a654dec43ea904364e9a4a16d49.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "NextStepEditRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Add a pirate hat to the dog's head. Change the background to a stormy sea with dark clouds. Include the text 'Captain Paws' in bold white letters at the top portion of the image."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to edit the image."
        },
        "negative_prompt": {
          "examples": [
            "Copy original image."
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n        "
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/tiger/JitXwwpMuF9iIhv0Pq6Dh_dog.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to edit."
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "negative_prompt"
      ],
      "required": [
        "image_url",
        "prompt",
        "negative_prompt"
      ]
    }
  },
  {
    "id": "fal-ai/qwen-image-edit",
    "name": "Qwen Image Edit",
    "description": "Endpoint for Qwen's Image Editing model. Has superior text editing capabilities.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/kangaroo/NR_iO1JmZVV3QZbjufcGu_367391df7b0242c9bf8a23368c0c4acf.jpg",
    "tags": [
      "image-editing",
      "image-to-image",
      "high-quality-text"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseQwenEditImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Change bag to apple macbook"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the image with"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "description": "Acceleration level for image generation. Options: 'none', 'regular'. Higher acceleration increases speed. 'regular' balances speed and quality.",
          "type": "string",
          "examples": [
            "regular"
          ],
          "title": "Acceleration",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/oei_-iPIYFnhdB8SxojND_qwen-edit-res.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to edit."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 30
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            "blurry, ugly"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "image_url",
        "negative_prompt",
        "acceleration"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/ideogram/character/edit",
    "name": "Ideogram V3 Character Edit",
    "description": "Modify consistent characters while preserving their core identity. Edit poses, expressions, or clothing without losing recognizable character features",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/penguin/sa3_-HW2nveeEYE8OzSn0_738419fcb18148cc8c8e0728196cd142.jpg",
    "tags": [
      "character-consistency"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "CharacterEditInputV3",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "woman holding bag"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to fill the masked part of the image."
        },
        "style": {
          "enum": [
            "AUTO",
            "REALISTIC",
            "FICTION"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style type to generate with. Cannot be used with style_codes.",
          "default": "AUTO"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Determine if MagicPrompt should be used in generating the request or not.",
          "default": true
        },
        "rendering_speed": {
          "enum": [
            "TURBO",
            "BALANCED",
            "QUALITY"
          ],
          "title": "Rendering Speed",
          "type": "string",
          "description": "The rendering speed to use.",
          "default": "BALANCED"
        },
        "reference_mask_urls": {
          "title": "Reference Mask Urls",
          "type": "array",
          "description": "A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format",
          "items": {
            "type": "string"
          }
        },
        "reference_image_urls": {
          "examples": [
            [
              "https://v3.fal.media/files/kangaroo/0rinwnj_Kn9Fsu2dK-aKm_image.png"
            ]
          ],
          "title": "Reference Image Urls",
          "type": "array",
          "description": "A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format",
          "items": {
            "type": "string"
          }
        },
        "image_urls": {
          "anyOf": [
            {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            {
              "type": "null"
            }
          ],
          "title": "Image Urls",
          "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate.",
          "default": 1
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/panda/-LC_gNNV3wUHaGMQT3klE_output.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The image URL to generate an image from. MUST have the exact same dimensions (width and height) as the mask image."
        },
        "style_codes": {
          "anyOf": [
            {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            {
              "type": "null"
            }
          ],
          "title": "Style Codes",
          "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style"
        },
        "color_palette": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ColorPalette"
            },
            {
              "type": "null"
            }
          ],
          "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for the random number generator"
        },
        "mask_url": {
          "examples": [
            "https://v3.fal.media/files/panda/jVDAgSkpsZFDP080ceSZJ_woman_face_mask.png"
          ],
          "title": "Mask URL",
          "type": "string",
          "description": "The mask URL to inpaint the image. MUST have the exact same dimensions (width and height) as the input image."
        }
      },
      "x-fal-order-properties": [
        "image_urls",
        "rendering_speed",
        "color_palette",
        "style_codes",
        "style",
        "expand_prompt",
        "num_images",
        "seed",
        "sync_mode",
        "prompt",
        "image_url",
        "mask_url",
        "reference_image_urls",
        "reference_mask_urls"
      ],
      "required": [
        "prompt",
        "image_url",
        "mask_url",
        "reference_image_urls"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/ideogram/character",
    "name": "Ideogram V3 Character",
    "description": "Generate consistent character appearances across multiple images. Maintain facial features, proportions, and distinctive traits for cohesive storytelling and branding",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/koala/spkoglxAAeU3iFhwZyWSW_b17f175d3e314853bc4c9bae2809cabd.jpg",
    "tags": [
      "character-consistency",
      ""
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseCharacterInputV3",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Place the woman leisurely enjoying a cup of espresso while relaxing at a sunlit caf\u00e9 table in Siena, Italy. The caf\u00e9 setting showcases vintage wooden furniture with peeling white paint, aged brick flooring, and sun-bleached stone walls decorated with trailing ivy and vibrant potted geraniums that capture Siena's medieval character. Golden late-morning light streams through overhead, creating soft shadows that highlight the weathered architectural details. The composition appears slightly off-center, conveying the unguarded tranquility and personal intimacy of a peaceful moment savoring the Tuscan morning ambiance."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to fill the masked part of the image."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Image Size",
          "description": "The resolution of the generated image",
          "default": "square_hd"
        },
        "style": {
          "enum": [
            "AUTO",
            "REALISTIC",
            "FICTION"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style type to generate with. Cannot be used with style_codes.",
          "default": "AUTO"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Determine if MagicPrompt should be used in generating the request or not.",
          "default": true
        },
        "rendering_speed": {
          "enum": [
            "TURBO",
            "BALANCED",
            "QUALITY"
          ],
          "title": "Rendering Speed",
          "type": "string",
          "description": "The rendering speed to use.",
          "default": "BALANCED"
        },
        "reference_mask_urls": {
          "title": "Reference Mask Urls",
          "type": "array",
          "description": "A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format",
          "items": {
            "type": "string"
          }
        },
        "reference_image_urls": {
          "examples": [
            [
              "https://v3.fal.media/files/kangaroo/0rinwnj_Kn9Fsu2dK-aKm_image.png"
            ]
          ],
          "title": "Reference Image Urls",
          "type": "array",
          "description": "A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format",
          "items": {
            "type": "string"
          }
        },
        "image_urls": {
          "anyOf": [
            {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            {
              "type": "null"
            }
          ],
          "title": "Image Urls",
          "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.",
          "default": ""
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate.",
          "default": 1
        },
        "style_codes": {
          "anyOf": [
            {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            {
              "type": "null"
            }
          ],
          "title": "Style Codes",
          "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style"
        },
        "color_palette": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ColorPalette"
            },
            {
              "type": "null"
            }
          ],
          "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for the random number generator"
        }
      },
      "x-fal-order-properties": [
        "image_urls",
        "rendering_speed",
        "color_palette",
        "style_codes",
        "style",
        "expand_prompt",
        "num_images",
        "seed",
        "sync_mode",
        "prompt",
        "image_size",
        "negative_prompt",
        "reference_image_urls",
        "reference_mask_urls"
      ],
      "required": [
        "prompt",
        "reference_image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/ideogram/character/remix",
    "name": "Ideogram V3 Character Remix",
    "description": "Transform your consistent character into different art styles, settings, or scenarios while maintaining their distinctive appearance and identity",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/zebra/AIDfIY6DcuzLpcKmklBq__73fde9aa027d4f079e59b53bf55b9c58.jpg",
    "tags": [
      "character-consistency"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "CharacterRemixInputV3",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A glamorous portrait photograph of a woman in an elegant ballroom setting. The subject wears a champagne-colored ball gown with a fitted bodice, long sleeves, and a full skirt adorned with delicate lace appliques. The dress features a crystal-embellished hair accessory and pearl drop earrings. The grand staircase has ornate gold railings and leads to an elaborate crystal chandelier hanging from an arched ceiling. The walls are decorated with classical paintings featuring floral motifs. The lighting is warm and dramatic, creating a soft glow throughout the space. The composition is shot in a formal portrait style with the subject positioned on the lower landing of the staircase, looking over her shoulder at the camera."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to remix the image with"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Image Size",
          "description": "The resolution of the generated image",
          "default": "square_hd"
        },
        "style": {
          "enum": [
            "AUTO",
            "REALISTIC",
            "FICTION"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style type to generate with. Cannot be used with style_codes.",
          "default": "AUTO"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Determine if MagicPrompt should be used in generating the request or not.",
          "default": true
        },
        "rendering_speed": {
          "enum": [
            "TURBO",
            "BALANCED",
            "QUALITY"
          ],
          "title": "Rendering Speed",
          "type": "string",
          "description": "The rendering speed to use.",
          "default": "BALANCED"
        },
        "reference_mask_urls": {
          "title": "Reference Mask Urls",
          "type": "array",
          "description": "A set of masks to apply to the character references. Currently only 1 mask is supported, rest will be ignored. (maximum total size 10MB across all character references). The masks should be in JPEG, PNG or WebP format",
          "items": {
            "type": "string"
          }
        },
        "reference_image_urls": {
          "examples": [
            [
              "https://v3.fal.media/files/kangaroo/0rinwnj_Kn9Fsu2dK-aKm_image.png"
            ]
          ],
          "title": "Reference Image Urls",
          "type": "array",
          "description": "A set of images to use as character references. Currently only 1 image is supported, rest will be ignored. (maximum total size 10MB across all character references). The images should be in JPEG, PNG or WebP format",
          "items": {
            "type": "string"
          }
        },
        "image_urls": {
          "anyOf": [
            {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            {
              "type": "null"
            }
          ],
          "title": "Image Urls",
          "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.",
          "default": ""
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate.",
          "default": 1
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/panda/mcxydS-_4ZjfBWFtgoo2z_XHLsl7khq6dC6Qp3cIdJl08rG0I.avif"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The image URL to remix"
        },
        "style_codes": {
          "anyOf": [
            {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            {
              "type": "null"
            }
          ],
          "title": "Style Codes",
          "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style"
        },
        "color_palette": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ColorPalette"
            },
            {
              "type": "null"
            }
          ],
          "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "Strength of the input image in the remix",
          "default": 0.8
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for the random number generator"
        }
      },
      "x-fal-order-properties": [
        "image_urls",
        "rendering_speed",
        "color_palette",
        "style_codes",
        "style",
        "expand_prompt",
        "num_images",
        "seed",
        "sync_mode",
        "prompt",
        "image_url",
        "strength",
        "image_size",
        "negative_prompt",
        "reference_image_urls",
        "reference_mask_urls"
      ],
      "required": [
        "prompt",
        "image_url",
        "reference_image_urls"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/flux-krea-lora/inpainting",
    "name": "FLUX.1 Krea [dev] Inpainting with LoRAs",
    "description": "Super fast endpoint for the FLUX.1 [dev] inpainting model with LoRA support, enabling rapid and high-quality image inpaingting using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "tags": [
      "lora",
      "personalization"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "InpaintInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A photo of a lion sitting on a stone bench"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate. This is always set to 1 for streaming output.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/dog.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of image to use for inpainting. or img2img"
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
          "default": 0.85
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 35,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "mask_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/dog_mask.png"
          ],
          "title": "Mask Url",
          "type": "string",
          "description": "\n            The mask to area to Inpaint in.\n        "
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "image_url",
        "strength",
        "mask_url"
      ],
      "required": [
        "prompt",
        "image_url",
        "mask_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-krea-lora/image-to-image",
    "name": "FLUX.1 Krea [dev] with LoRAs",
    "description": "FLUX LoRA Image-to-Image is a high-performance endpoint that transforms existing images using FLUX models, leveraging LoRA adaptations to enable rapid and precise image style transfer, modifications, and artistic variations.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "tags": [
      "lora",
      "style transfer"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A photo of a lion sitting on a stone bench"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate. This is always set to 1 for streaming output.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/dog.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of image to use for inpainting. or img2img"
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
          "default": 0.85
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 35,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "image_url",
        "strength"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "easel-ai/fashion-tryon",
    "name": "Fashion Try On",
    "description": "Instant fashion try on with a full-body pic and an outfit",
    "category": "image-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/koala/CsvNzqTdxWgyeMaY3ByNM_c8c44e108a8c427398a6cde17ff5ccd0.jpg",
    "tags": [
      "try-on",
      "fashion",
      "clothing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "full_body_image",
        "clothing_image",
        "gender"
      ],
      "type": "object",
      "properties": {
        "clothing_image": {
          "examples": [
            "https://images.easelai.com/tryon/outfit6.webp",
            "https://images.easelai.com/tryon/outfit4.webp",
            "https://images.easelai.com/tryon/woman_outfit7.webp",
            "https://images.easelai.com/tryon/men_outfit7.webp",
            "https://images.easelai.com/tryon/outfit3.webp"
          ],
          "description": "The clothing item to try on the person",
          "title": "Clothing Image",
          "allOf": [
            {
              "$ref": "#/components/schemas/Image"
            }
          ]
        },
        "gender": {
          "enum": [
            "male",
            "female"
          ],
          "description": "The model's gender for the try-on.",
          "type": "string",
          "title": "Model Gender",
          "default": "female"
        },
        "full_body_image": {
          "examples": [
            "https://images.easelai.com/tryon/woman.webp",
            "https://images.easelai.com/tryon/man.webp"
          ],
          "description": "The reference person full body image to try clothes on",
          "title": "Full Body Image",
          "allOf": [
            {
              "$ref": "#/components/schemas/Image"
            }
          ]
        }
      },
      "title": "TryOnInput",
      "required": [
        "full_body_image",
        "clothing_image"
      ]
    }
  },
  {
    "id": "fal-ai/flux/krea/image-to-image",
    "name": "FLUX.1 Krea [dev]",
    "description": "FLUX.1 Krea [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.\n",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-4.jpeg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseKreaImageToInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cat dressed as a wizard with a background of a mystic forest."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "none"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate an image from."
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "The strength of the initial image. Higher strength values are better for this model.",
          "default": 0.95
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 10,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 40
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 4.5
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "strength",
        "num_inference_steps",
        "prompt",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux/krea/redux",
    "name": "FLUX.1 Krea [dev] Redux",
    "description": "FLUX.1 Krea [dev] Redux is a high-performance endpoint for the FLUX.1 Krea [dev] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseKreaReduxInput",
      "type": "object",
      "properties": {
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "none"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/flux_krea_redux_output_1.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate an image from."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 4.5
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/flux-1/krea/image-to-image",
    "name": "FLUX.1 Krea [dev]",
    "description": "FLUX.1 Krea [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.\n",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-5.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseKreaFlux1ImageToInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cat dressed as a wizard with a background of a mystic forest."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/koala/Chls9L2ZnvuipUTEwlnJC.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate an image from."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "The strength of the initial image. Higher strength values are better for this model.",
          "default": 0.95
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        },
        "num_inference_steps": {
          "minimum": 10,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 40
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 4.5
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "strength",
        "num_inference_steps",
        "prompt",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-1/krea/redux",
    "name": "FLUX.1 Krea [dev] Redux",
    "description": "FLUX.1 Krea [dev] Redux is a high-performance endpoint for the FLUX.1 Krea [dev] model that enables rapid transformation of existing images, delivering high-quality style transfers and image modifications with the core FLUX capabilities.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseKreaFlux1ReduxInput",
      "type": "object",
      "properties": {
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/flux_krea_redux_output_1.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate an image from."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 4.5
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/flux-kontext-lora/inpaint",
    "name": "Flux Kontext Lora",
    "description": "Fast inpainting endpoint for the FLUX.1 Kontext [dev] model with LoRA support, enabling rapid and high-quality image inpainting with reference images, while using pre-trained LoRA adaptations for specific styles, brand identities, and product-specific outputs.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "tags": [
      "image-editing",
      "image-inpainting",
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseKontextInpaintInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A football lying on a field."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt for the image to image task."
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "none"
        },
        "reference_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/reference_kontext_inpaint.jpeg"
          ],
          "title": "Reference Image URL",
          "type": "string",
          "description": "The URL of the reference image for inpainting."
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 2.5
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/image_kontext_inpaint.jpeg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to be inpainted."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "The strength of the initial image. Higher strength values are better for this model.",
          "default": 0.88
        },
        "num_inference_steps": {
          "minimum": 10,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 30
        },
        "mask_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/mask_kontext_inpaint.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the mask for inpainting."
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "loras",
        "acceleration",
        "reference_image_url",
        "mask_url",
        "strength"
      ],
      "required": [
        "prompt",
        "image_url",
        "reference_image_url",
        "mask_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/hunyuan_world",
    "name": "Hunyuan World",
    "description": "Hunyuan World 1.0 turns a single image into a panorama or a 3D world. It creates realistic scenes from the image, allowing you to explore and view it from different angles.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/rabbit/K4wH2Zlj5N6woxkqlpGya_f9ae0f21d42a4c67afe183ab1eea225e.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToPanoramaRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A skyland of wonders"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for the panorama generation."
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/penguin/_4oXlxt85dr0WY2o0I894_output.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The URL of the image to convert to a panorama."
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/image-editing/retouch",
    "name": "Image Editing",
    "description": "Retouch photos of faces. Remove blemishes and improve the skin.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-4.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "RetouchInput",
      "type": "object",
      "properties": {
        "lora_scale": {
          "minimum": 0,
          "maximum": 4,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
          "default": 1
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/gallery/tulsi.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the image to retouch."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "Number of inference steps for sampling.",
          "default": 30
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        }
      },
      "description": "Input model for retouch endpoint.",
      "x-fal-order-properties": [
        "image_url",
        "guidance_scale",
        "num_inference_steps",
        "enable_safety_checker",
        "lora_scale",
        "seed",
        "sync_mode"
      ],
      "required": [
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/hidream-e1-1",
    "name": "Hidream E1 1",
    "description": "Edit images with natural language",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Convert the image into a 3D animated style."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Number of Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_guidance_scale": {
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your initial image when looking for a related image to show you.\n        ",
          "type": "number",
          "minimum": 0,
          "maximum": 20,
          "examples": [
            2
          ],
          "title": "Image Guidance Scale (CFG)",
          "default": 2
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/hidream/woman.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of an input image to edit."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "target_image_description": {
          "title": "Target Image Description",
          "type": "string",
          "description": "The description of the target image after your edits have been made. Leave this blank to allow the model to use its own imagination."
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Number of Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 50
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            "low resolution, blur"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": "low resolution, blur"
        },
        "guidance_scale": {
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "type": "number",
          "minimum": 0,
          "maximum": 20,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale (CFG)",
          "default": 3.5
        }
      },
      "x-fal-order-properties": [
        "target_image_description",
        "prompt",
        "negative_prompt",
        "image_url",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "image_guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/rife",
    "name": "RIFE",
    "description": "Interpolate images with RIFE - Real-Time Intermediate Flow Estimation",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/penguin/HLrNymdnzx1neVc9Pj0c1_debdeb10494e45888dd68d1a2df2dcac.jpg",
    "tags": [
      "interpolation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "start_image_url",
        "end_image_url",
        "output_type",
        "output_format",
        "num_frames",
        "include_start",
        "include_end",
        "fps",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "output_format": {
          "enum": [
            "png",
            "jpeg"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output images. Only applicable if output_type is 'images'.",
          "default": "jpeg"
        },
        "include_start": {
          "title": "Include Start",
          "type": "boolean",
          "description": "Whether to include the start image in the output.",
          "default": false
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If True, the function will wait for images to be generated and uploaded before returning. This will increase the response time but ensures that the images are ready for use immediately without going through the CDN. Does not apply if output_type is 'video'.",
          "default": false
        },
        "include_end": {
          "title": "Include End",
          "type": "boolean",
          "description": "Whether to include the end image in the output.",
          "default": false
        },
        "fps": {
          "minimum": 1,
          "maximum": 60,
          "type": "integer",
          "title": "Frames Per Second",
          "description": "Frames per second for the output video. Only applicable if output_type is 'video'.",
          "default": 8
        },
        "start_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/interpolate-start-frame.png"
          ],
          "title": "Start Image URL",
          "type": "string",
          "description": "The URL of the first image to use as the starting point for interpolation."
        },
        "end_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/interpolate-end-frame.png"
          ],
          "title": "End Image URL",
          "type": "string",
          "description": "The URL of the second image to use as the ending point for interpolation."
        },
        "output_type": {
          "enum": [
            "images",
            "video"
          ],
          "title": "Output Type",
          "type": "string",
          "description": "The type of output to generate; either individual images or a video.",
          "default": "images"
        },
        "num_frames": {
          "description": "The number of frames to generate between the input images.",
          "type": "integer",
          "minimum": 1,
          "maximum": 64,
          "title": "Number of Frames",
          "default": 1
        }
      },
      "title": "RIFEImageInput",
      "required": [
        "start_image_url",
        "end_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/film",
    "name": "FILM",
    "description": "Interpolate images with FILM - Frame Interpolation for Large Motion",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos.jpg",
    "tags": [
      "interpolation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FILMImageInput",
      "type": "object",
      "properties": {
        "video_write_mode": {
          "examples": [
            "balanced"
          ],
          "description": "The write mode of the output video. Only applicable if output_type is 'video'.",
          "type": "string",
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "default": "balanced"
        },
        "output_type": {
          "enum": [
            "images",
            "video"
          ],
          "description": "The type of output to generate; either individual images or a video.",
          "type": "string",
          "title": "Output Type",
          "default": "images"
        },
        "fps": {
          "minimum": 1,
          "description": "Frames per second for the output video. Only applicable if output_type is 'video'.",
          "type": "integer",
          "maximum": 60,
          "title": "Frames Per Second",
          "default": 8
        },
        "sync_mode": {
          "description": "If True, the function will wait for images to be generated and uploaded before returning. This will increase the response time but ensures that the images are ready for use immediately without going through the CDN.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "include_end": {
          "description": "Whether to include the end image in the output.",
          "type": "boolean",
          "title": "Include End",
          "default": false
        },
        "video_quality": {
          "examples": [
            "high"
          ],
          "description": "The quality of the output video. Only applicable if output_type is 'video'.",
          "type": "string",
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "default": "high"
        },
        "include_start": {
          "description": "Whether to include the start image in the output.",
          "type": "boolean",
          "title": "Include Start",
          "default": false
        },
        "start_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/interpolate-start-frame.png"
          ],
          "description": "The URL of the first image to use as the starting point for interpolation.",
          "type": "string",
          "title": "Start Image URL"
        },
        "end_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/interpolate-end-frame.png"
          ],
          "description": "The URL of the second image to use as the ending point for interpolation.",
          "type": "string",
          "title": "End Image URL"
        },
        "image_format": {
          "enum": [
            "png",
            "jpeg"
          ],
          "description": "The format of the output images. Only applicable if output_type is 'images'.",
          "type": "string",
          "title": "Image Format",
          "default": "jpeg"
        },
        "num_frames": {
          "description": "The number of frames to generate between the input images.",
          "type": "integer",
          "minimum": 1,
          "maximum": 64,
          "title": "Number of Frames",
          "default": 1
        }
      },
      "x-fal-order-properties": [
        "start_image_url",
        "end_image_url",
        "output_type",
        "image_format",
        "video_quality",
        "video_write_mode",
        "num_frames",
        "include_start",
        "include_end",
        "fps",
        "sync_mode"
      ],
      "required": [
        "start_image_url",
        "end_image_url"
      ]
    }
  },
  {
    "id": "easel-ai/fashion-photoshoot",
    "name": "Fashion Photoshoot",
    "description": "Instant fashion photoshoot with a selfie and an outfit",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-3.jpeg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FashionShootInput",
      "type": "object",
      "properties": {
        "mode": {
          "enum": [
            "stylistic",
            "realistic"
          ],
          "title": "Mode",
          "type": "string",
          "description": "Choose generation mode: stylistic (classic look) or realistic (photorealistic).",
          "default": "stylistic"
        },
        "gender": {
          "enum": [
            "male",
            "female"
          ],
          "title": "Model Gender",
          "type": "string",
          "description": "The model's gender for the fashion shoot."
        },
        "body_size": {
          "enum": [
            "XS",
            "S",
            "M",
            "L",
            "XL"
          ],
          "description": "The body size for the fashion shoot.",
          "type": "string",
          "examples": [
            "XS",
            "S",
            "M",
            "L",
            "XL"
          ],
          "title": "Body Size",
          "default": "S"
        },
        "location": {
          "enum": [
            "park",
            "city",
            "runway"
          ],
          "title": "Location",
          "type": "string",
          "description": "Sets the location / background for the fashion shoot.",
          "default": "park"
        },
        "garment_image": {
          "examples": [
            "https://images.easelai.com/fashionshoot/acoldwall_sweater.webp",
            "https://images.easelai.com/fashionshoot/boss_dress.webp",
            "https://images.easelai.com/fashionshoot/boss_suiit.webp",
            "https://images.easelai.com/fashionshoot/gucci_jacket_women.jpg"
          ],
          "title": "Garment Image",
          "description": "The garment image to be used for the fashion shoot.",
          "allOf": [
            {
              "$ref": "#/components/schemas/Image"
            }
          ]
        },
        "face_image": {
          "examples": [
            "https://images.easelai.com/mirror_fal/faces/male.png",
            "https://images.easelai.com/mirror_fal/faces/female.png"
          ],
          "title": "Face Image",
          "description": "The user's face image used for the fashion shoot.",
          "allOf": [
            {
              "$ref": "#/components/schemas/Image"
            }
          ]
        }
      },
      "x-fal-order-properties": [
        "garment_image",
        "face_image",
        "gender",
        "body_size",
        "location",
        "mode"
      ],
      "required": [
        "garment_image",
        "face_image",
        "gender"
      ]
    }
  },
  {
    "id": "fal-ai/calligrapher",
    "name": "Calligrapher",
    "description": "Use the text and font retaining capabilities of calligrapher to modify texts on your books, clothes and many more.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "tags": [
      "image-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Input",
      "type": "object",
      "properties": {
        "use_context": {
          "title": "Use Context",
          "type": "boolean",
          "description": "Whether to prepend context reference to the input",
          "default": true
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "How many images to generate",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "Target image size for generation",
          "default": {
            "height": 1024,
            "width": 1024
          }
        },
        "auto_mask_generation": {
          "title": "Auto Mask Generation",
          "type": "boolean",
          "description": "Whether to automatically generate mask from detected text",
          "default": false
        },
        "reference_image_url": {
          "title": "Reference Image Url",
          "type": "string",
          "description": "Optional base64 reference image for style"
        },
        "source_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/calligrapher/test17_source.png"
          ],
          "title": "Source Image Url",
          "type": "string",
          "description": "Base64-encoded source image with drawn mask layers"
        },
        "prompt": {
          "examples": [
            "The text is 'Rise'"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to inpaint or customize"
        },
        "mask_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/calligrapher/test17_mask.png"
          ],
          "title": "Mask Image Url",
          "type": "string",
          "description": "Base64-encoded mask image (optional if using auto_mask_generation)"
        },
        "source_text": {
          "title": "Source Text",
          "type": "string",
          "description": "Source text to replace (if empty, masks all detected text)",
          "default": ""
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "Number of inference steps (1-100)",
          "default": 50
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility"
        },
        "cfg_scale": {
          "minimum": 0,
          "title": "Cfg Scale",
          "type": "number",
          "maximum": 5,
          "description": "Guidance or strength scale for the model",
          "default": 1
        }
      },
      "x-fal-order-properties": [
        "source_image_url",
        "mask_image_url",
        "reference_image_url",
        "prompt",
        "num_images",
        "image_size",
        "cfg_scale",
        "num_inference_steps",
        "seed",
        "use_context",
        "auto_mask_generation",
        "source_text"
      ],
      "required": [
        "source_image_url",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/bria/reimagine",
    "name": "Bria",
    "description": "Structure Reference allows generating new images while preserving the structure of an input image, guided by text prompts. Perfect for transforming sketches, illustrations, or photos into new illustrations. Trained exclusively on licensed data for safe and risk-free commercial use.",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/rabbit/wXG4NtIA2sZUz7-CiooUJ_bb5f4b6f122149849d744baaad6896f8.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ReimagineInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A 2d illustration of a dog in a vibrant park"
          ],
          "description": "The prompt you would like to use to generate images.",
          "type": "string",
          "title": "Prompt"
        },
        "num_results": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Results",
          "description": "How many images you would like to generate. When using any Guidance Method, Value is set to 1.",
          "default": 1
        },
        "structure_ref_influence": {
          "examples": [
            0.15
          ],
          "description": "The influence of the structure reference on the generated image.",
          "type": "number",
          "title": "Structure Ref Influence",
          "default": 0.75
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "fast": {
          "description": "Whether to use the fast model",
          "type": "boolean",
          "title": "Fast",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 20,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of iterations the model goes through to refine the generated image. This parameter is optional.",
          "default": 30
        },
        "seed": {
          "minimum": 0,
          "maximum": 2147483647,
          "type": "integer",
          "title": "Seed",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "structure_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/bria/bria_reimagine_input.png"
          ],
          "description": "The URL of the structure reference image. Use \"\" to leave empty. Accepted formats are jpeg, jpg, png, webp.",
          "type": "string",
          "title": "Structure Image Url",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "structure_image_url",
        "structure_ref_influence",
        "num_results",
        "seed",
        "fast",
        "num_inference_steps",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/image-editing/realism",
    "name": "Image Editing",
    "description": "Add details to faces, enhance face features, remove blur.",
    "category": "image-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "tags": [
      "stylized",
      "transform",
      "realism"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "RealismInput",
      "type": "object",
      "properties": {
        "lora_scale": {
          "minimum": 0,
          "maximum": 2,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale factor for the LoRA model. Controls the strength of the LoRA effect.",
          "default": 0.6
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/penguin/QpRcoPb4dDyDJJSpFm4CZ_img_55_start.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the image to enhance with realism details."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If set to true, the function will wait for the image to be generated and uploaded before returning the response. This will increase the latency of the function but it allows you to get the image directly in the response without going through the CDN.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The same seed and the same prompt given to the same version of the model will output the same image every time."
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "Number of inference steps for sampling.",
          "default": 30
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker for the generated image.",
          "default": true
        }
      },
      "description": "Input model for realism enhancement endpoint.",
      "x-fal-order-properties": [
        "image_url",
        "guidance_scale",
        "num_inference_steps",
        "enable_safety_checker",
        "lora_scale",
        "seed",
        "sync_mode"
      ],
      "required": [
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/post-processing/vignette",
    "name": "Post Processing",
    "description": "Add a darkening vignette effect around the edges of the image with adjustable strength",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/kangaroo/8KT3LjgSQtyW87hvxYr9n_8c31d2880fac4b9c877518c8162c2c8a.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "VignetteInput",
      "type": "object",
      "properties": {
        "vignette_strength": {
          "minimum": 0,
          "maximum": 10,
          "type": "number",
          "title": "Vignette Strength",
          "description": "Vignette strength",
          "default": 0.5
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of image to process"
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "vignette_strength"
      ],
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/post-processing/solarize",
    "name": "Post Processing",
    "description": "Apply solarization effect by inverting pixel values above a threshold",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/zebra/eR5hrHpGP3yIomYpon_z2_707e890433164c9494d964f9660833ec.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SolarizeInput",
      "type": "object",
      "properties": {
        "solarize_threshold": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Solarize Threshold",
          "description": "Solarize threshold",
          "default": 0.5
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of image to process"
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "solarize_threshold"
      ],
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/post-processing/sharpen",
    "name": "Post Processing",
    "description": "Apply sharpening effects with three modes: basic unsharp mask, smart sharpening with edge preservation, and Contrast Adaptive Sharpening (CAS).",
    "category": "image-to-image",
    "thumbnail_url": "https://fal.media/files/elephant/koBXGLN1Y5Qzu7ZKUogdf_7ceac7fe825841b5813a724990cd4f5b.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SharpenInput",
      "type": "object",
      "properties": {
        "sharpen_mode": {
          "enum": [
            "basic",
            "smart",
            "cas"
          ],
          "title": "Sharpen Mode",
          "type": "string",
          "description": "Type of sharpening to apply",
          "default": "basic"
        },
        "sharpen_alpha": {
          "minimum": 0.1,
          "maximum": 5,
          "type": "number",
          "title": "Sharpen Alpha",
          "description": "Sharpen strength (for basic mode)",
          "default": 1
        },
        "noise_radius": {
          "minimum": 1,
          "maximum": 25,
          "type": "integer",
          "title": "Noise Radius",
          "description": "Noise radius for smart sharpen",
          "default": 7
        },
        "sharpen_radius": {
          "minimum": 1,
          "maximum": 15,
          "type": "integer",
          "title": "Sharpen Radius",
          "description": "Sharpen radius (for basic mode)",
          "default": 1
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/post-process/postpro-input.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of image to process"
        },
        "smart_sharpen_strength": {
          "minimum": 0,
          "maximum": 25,
          "type": "number",
          "title": "Smart Sharpen Strength",
          "description": "Smart sharpen strength",
          "default": 5
        },
        "cas_amount": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Cas Amount",
          "description": "CAS sharpening amount",
          "default": 0.8
        },
        "preserve_edges": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Preserve Edges",
          "description": "Edge preservation factor",
          "default": 0.75
        },
        "smart_sharpen_ratio": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Smart Sharpen Ratio",
          "description": "Smart sharpen blend ratio",
          "default": 0.5
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "sharpen_mode",
        "sharpen_radius",
        "sharpen_alpha",
        "noise_radius",
        "preserve_edges",
        "smart_sharpen_strength",
        "smart_sharpen_ratio",
        "cas_amount"
      ],
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/wan-effects",
    "name": "Wan Effects",
    "description": "Wan Effects generates high-quality videos with popular effects from images",
    "category": "image-to-video",
    "thumbnail_url": "/video-thumbnails/wan-effects-thumb.mp4",
    "tags": [
      "motion",
      "effects"
    ],
    "highlighted": true,
    "pinned": true,
    "input_schema": {
      "x-fal-order-properties": [
        "subject",
        "image_url",
        "effect_type",
        "num_frames",
        "frames_per_second",
        "seed",
        "aspect_ratio",
        "num_inference_steps",
        "lora_scale",
        "turbo_mode"
      ],
      "type": "object",
      "properties": {
        "effect_type": {
          "enum": [
            "squish",
            "muscle",
            "inflate",
            "crush",
            "rotate",
            "gun-shooting",
            "deflate",
            "cakeify",
            "hulk",
            "baby",
            "bride",
            "classy",
            "puppy",
            "snow-white",
            "disney-princess",
            "mona-lisa",
            "painting",
            "pirate-captain",
            "princess",
            "jungle",
            "samurai",
            "vip",
            "warrior",
            "zen",
            "assassin",
            "timelapse",
            "tsunami",
            "fire",
            "zoom-call",
            "doom-fps",
            "fus-ro-dah",
            "hug-jesus",
            "robot-face-reveal",
            "super-saiyan",
            "jumpscare",
            "laughing",
            "cartoon-jaw-drop",
            "crying",
            "kissing",
            "angry-face",
            "selfie-younger-self",
            "animeify",
            "blast"
          ],
          "description": "The type of effect to apply to the video.",
          "type": "string",
          "title": "Effect Type",
          "default": "cakeify"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the output video.",
          "default": "16:9"
        },
        "subject": {
          "examples": [
            "a cute kitten",
            "Donald Trump",
            "a tank",
            "a ceramic vase"
          ],
          "description": "The subject to insert into the predefined prompt template for the selected effect.",
          "type": "string",
          "title": "Subject"
        },
        "lora_scale": {
          "minimum": 0.1,
          "maximum": 2,
          "type": "number",
          "title": "Lora Scale",
          "description": "The scale of the LoRA weight. Used to adjust effect intensity.",
          "default": 1
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/wan-effects/cat.jpg",
            "https://storage.googleapis.com/falserverless/web-examples/wan-effects/man_1.png",
            "https://storage.googleapis.com/falserverless/web-examples/wan-effects/woman_2.png"
          ],
          "description": "URL of the input image.",
          "type": "string",
          "title": "Image URL"
        },
        "turbo_mode": {
          "description": "Whether to use turbo mode. If True, the video will be generated faster but with lower quality.",
          "type": "boolean",
          "title": "Turbo Mode",
          "default": false
        },
        "frames_per_second": {
          "minimum": 5,
          "description": "Frames per second of the generated video.",
          "type": "integer",
          "maximum": 24,
          "title": "Frames Per Second",
          "default": 16
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 40,
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "default": 30
        },
        "seed": {
          "description": "Random seed for reproducibility. If None, a random seed is chosen.",
          "type": "integer",
          "title": "Seed"
        },
        "num_frames": {
          "minimum": 81,
          "title": "Num Frames",
          "type": "integer",
          "maximum": 100,
          "description": "Number of frames to generate.",
          "default": 81
        }
      },
      "title": "BaseInput",
      "required": [
        "subject",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/wan-pro/image-to-video",
    "name": "Wan-2.1 Pro Image-to-Video",
    "description": "Wan-2.1 Pro is a premium image-to-video model that generates high-quality 1080p videos at 30fps with up to 6 seconds duration, delivering exceptional visual quality and motion diversity from images",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/wan-pro-image-to-video.webp",
    "tags": [
      "image to video",
      "motion"
    ],
    "highlighted": true,
    "pinned": true,
    "input_schema": {
      "title": "WanProI2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The URL of the image to generate the video from"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "enable_safety_checker",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 16,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/veo2/image-to-video",
    "name": "Veo 2 (Image to Video)",
    "description": "Veo 2 creates videos from images with realistic motion and very high quality output.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/veo2-image-to-video.webp",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": true,
    "pinned": true,
    "input_schema": {
      "title": "ImageToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A lego chef cooking eggs"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt describing how the image should be animated"
        },
        "duration": {
          "enum": [
            "5s",
            "6s",
            "7s",
            "8s"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5s"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "auto_prefer_portrait",
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "auto"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/elephant/6fq8JDSjb1osE_c3J_F2H.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the input image to animate. Should be 720p or higher resolution."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "aspect_ratio",
        "duration"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 50,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/kling-video/v1.6/pro/image-to-video",
    "name": "Kling 1.6",
    "description": "Generate video clips from your images using Kling 1.6 (pro)",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/kling-1-6-image-to-video.webp",
    "tags": [],
    "highlighted": true,
    "pinned": true,
    "input_schema": {
      "title": "ProImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Snowflakes fall as a car moves along the road."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/kling/kling_input.jpeg"
          ],
          "title": "Image Url",
          "type": "string"
        },
        "tail_image_url": {
          "description": "URL of the image to be used for the end of the video",
          "type": "string",
          "title": "Tail Image Url"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "aspect_ratio",
        "tail_image_url",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/minimax/video-01/image-to-video",
    "name": "MiniMax (Hailuo AI) Video 01",
    "description": "Generate video clips from your images using MiniMax Video model",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/minimax-video-01-image-to-video.webp",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "prompt_optimizer"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 10,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3/pro/image-to-video",
    "name": "MiniMax Hailuo 2.3 [Pro] (Image to Video)",
    "description": "MiniMax Hailuo-2.3 Image To Video API (Pro, 1080p): Advanced image-to-video generation model with 1080p resolution",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/0iV7vFj9ujGqHUqKkBesN_a65fac7d7c994f39aeedabe31db6fb2d.jpg",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ProImageToVideoHailuo23Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "The camera follows the mountain biker as they navigate a technical forest trail at high speed, wheels bouncing over roots and rocks. The rider approaches a jump, launching into the air with the bike, both rider and machine perfectly synchronized. They land smoothly and continue through tight turns, splashing through a stream crossing. Mud and water spray as the bike powers through challenging terrain. The atmosphere is wild and adventurous. Audio: Tires gripping dirt, gears shifting, heavy breathing, branches whipping past, and water splashing."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000,
          "description": "Text prompt for video generation",
          "minLength": 1
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/hailuo23/pro_i2v_in.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "prompt_optimizer",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 10,
    "pricing_unit": "units"
  },
  {
    "id": "fal-ai/wan-25-preview/image-to-video",
    "name": "Wan 2.5 Image to Video",
    "description": "Wan 2.5 image-to-video model.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/rabbit/jryVrAZdQNdLdN_4rTlN7_9bebc94cb69a482fb4d948bdd06d6a5e.jpg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
          ],
          "title": "Prompt",
          "type": "string",
          "minLength": 1,
          "description": "The text prompt describing the desired video motion. Max 800 characters."
        },
        "resolution": {
          "enum": [
            "480p",
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Video resolution. Valid values: 480p, 720p, 1080p",
          "default": "1080p"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "Duration of the generated video in seconds. Choose between 5 or 10 seconds.",
          "examples": [
            "5",
            "10"
          ],
          "default": "5"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/wan/dragon-warrior.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the image to use as the first frame. Must be publicly accessible or base64 data URI.\n\nMax file size: 25.0MB, Min width: 360px, Min height: 360px, Max width: 2000px, Max height: 2000px, Timeout: 20.0s",
          "x-fal": {
            "min_width": 360,
            "min_height": 360,
            "timeout": 20,
            "max_width": 2000,
            "max_height": 2000,
            "max_file_size": 26214400
          }
        },
        "audio_url": {
          "title": "Audio Url",
          "type": "string",
          "description": "\nURL of the audio to use as the background music. Must be publicly accessible.\nLimit handling: If the audio duration exceeds the duration value (5 or 10 seconds),\nthe audio is truncated to the first 5 or 10 seconds, and the rest is discarded. If\nthe audio is shorter than the video, the remaining part of the video will be silent.\nFor example, if the audio is 3 seconds long and the video duration is 5 seconds, the\nfirst 3 seconds of the output video will have sound, and the last 2 seconds will be silent.\n- Format: WAV, MP3.\n- Duration: 3 to 30 s.\n- File size: Up to 15 MB.\n"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt rewriting using LLM.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "low resolution, error, worst quality, low quality, defects"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt to describe content to avoid. Max 500 characters."
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "description": "Input for image-to-video generation",
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "audio_url",
        "resolution",
        "duration",
        "negative_prompt",
        "enable_prompt_expansion",
        "seed",
        "enable_safety_checker"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 5,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/kling-video/v2.6/pro/image-to-video",
    "name": "Kling 2.6 Pro (I2V)",
    "description": "Kling 2.6 Pro: Latest image-to-video generation with enhanced motion fluidity, cinematic visuals, native audio generation, and exceptional prompt precision.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/rabbit/2KNBk1qkmEBXK0FLgfHCl_ee4bb1ada254433bbab296893a8636e3.jpg",
    "thumbnail_animated_url": "/video-thumbnails/kling2.6-thumb.mp4",
    "tags": [
      "cinematic",
      "premium",
      "audio"
    ],
    "highlighted": true,
    "pinned": true,
    "input_schema": {
      "title": "ImageToVideoV26ProRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A king walks slowly and says \"My people, here I am! I am here to save you all\""
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": ["5", "10"],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "generate_audio": {
          "type": "boolean",
          "title": "Generate Audio",
          "description": "Whether to generate native audio for the video",
          "default": true
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/0a84ab29/BSJXz9Ht-jgRgMf4IGxLU_upscaled.png"
          ],
          "description": "URL of the image to be used for the video",
          "type": "string",
          "title": "Image Url"
        },
        "aspect_ratio": {
          "enum": ["16:9", "9:16", "1:1"],
          "title": "Aspect Ratio",
          "type": "string",
          "default": "16:9"
        }
      },
      "required": ["prompt", "image_url"]
    },
    "credits_per_5sec": 7,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/kling-video/v2.5-turbo/pro/image-to-video",
    "name": "Kling Video",
    "description": "Kling 2.5 Turbo Pro: Top-tier image-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/rabbit/2KNBk1qkmEBXK0FLgfHCl_ee4bb1ada254433bbab296893a8636e3.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoV25ProRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stark starting line divides two powerful cars, engines revving for the challenge ahead. They surge forward in the heat of competition, a blur of speed and chrome. The finish line looms as they vie for victory."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "tail_image_url": {
          "description": "URL of the image to be used for the end of the video",
          "type": "string",
          "title": "Tail Image Url"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/panda/HnY2yf-BbzlrVQxR-qP6m_9912d0932988453aadf3912fc1901f52.jpg"
          ],
          "description": "URL of the image to be used for the video",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "negative_prompt",
        "cfg_scale",
        "tail_image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 7,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/minimax/hailuo-02/standard/image-to-video",
    "name": "MiniMax Hailuo 02 [Standard] (Image to Video)",
    "description": "MiniMax Hailuo-02 Image To Video API (Standard, 768p, 512p): Advanced image-to-video generation model with 768p and 512p resolutions",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "StandardImageToVideoHailuo02Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "duration": {
          "enum": [
            "6",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.",
          "default": "6"
        },
        "prompt": {
          "examples": [
            "Man walked into winter cave with polar bear"
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000
        },
        "resolution": {
          "enum": [
            "512P",
            "768P"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated video.",
          "default": "768P"
        },
        "end_image_url": {
          "title": "End Image Url",
          "type": "string",
          "description": "Optional URL of the image to use as the last frame of the video"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/minimax/1749891352437225630-389852416840474630_1749891352.png"
          ],
          "title": "Image Url",
          "type": "string"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "prompt_optimizer",
        "resolution",
        "end_image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 5,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/pro/image-to-video",
    "name": "Seedance 1.0 Pro",
    "description": "Seedance 1.0 Pro, a high quality video generation model developed by Bytedance.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-3.jpg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "camera_fixed",
        "seed",
        "enable_safety_checker",
        "image_url",
        "end_image_url"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A skier glides over fresh snow, joyously smiling while kicking up large clouds of snow as he turns. Accelerating gradually down the slope, the camera moves smoothly alongside."
          ],
          "description": "The text prompt used to generate the video",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16",
            "auto"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p",
            "1080p"
          ],
          "description": "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
          "type": "string",
          "title": "Resolution",
          "default": "1080p"
        },
        "duration": {
          "enum": [
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
          ],
          "description": "Duration of the video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/seedance_pro_i2v_img.jpg"
          ],
          "description": "The URL of the image used to generate video",
          "type": "string",
          "title": "Image Url"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "camera_fixed": {
          "description": "Whether to fix the camera position",
          "type": "boolean",
          "title": "Camera Fixed",
          "default": false
        },
        "end_image_url": {
          "description": "The URL of the image the video ends with. Defaults to None.",
          "type": "string",
          "title": "End Image Url"
        },
        "seed": {
          "description": "Random seed to control video generation. Use -1 for random.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "SeedanceProImageToVideoInput",
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v2.1/master/image-to-video",
    "name": "Kling 2.1 Master",
    "description": "Kling 2.1 Master: The premium endpoint for Kling 2.1, designed for top-tier image-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.\n\n",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-5.jpeg",
    "tags": [
      "_marquee-video-model"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoV21MasterRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Sunlight dapples through budding branches, illuminating a vibrant tapestry of greens and browns as a pair of robins meticulously weave twigs and mud into a cradle of life, their tiny forms a whirlwind of activity against a backdrop of blossoming spring.  The scene unfolds with a gentle, observational pace, allowing the viewer to fully appreciate the intricate details of nest construction, the soft textures of downy feathers contrasted against the rough bark of the branches, the delicate balance of strength and fragility in their creation."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/9Nrm22YyLojSTPJbZYNhh_image.webp"
          ],
          "description": "URL of the image to be used for the video",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 28,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/kling-video/v2.1/standard/image-to-video",
    "name": "Kling 2.1 (standard)",
    "description": "Kling 2.1 Standard is a cost-efficient endpoint for the Kling 2.1 model, delivering high-quality image-to-video generation \n\n",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/elephant/5Yt8D9tl-IaGQ-6czSXL1_HHQ_VCby6xP_DFLkQQLpV_3c8622214c4c4ac29b4b64e157746507.jpg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoV21StandardRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "As the sun dips below the horizon, painting the sky in fiery hues of orange and purple, powerful waves relentlessly crash against jagged, dark rocks, their white foam a stark contrast to the deepening twilight; the textured surface of the rocks, wet and glistening, reflects the vibrant colors, creating a mesmerizing spectacle of nature's raw power and breathtaking beauty"
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/kling/kling-image-to-video.jpg"
          ],
          "description": "URL of the image to be used for the video",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 5,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/kling-video/v2/master/image-to-video",
    "name": "Kling 2.0 Master",
    "description": "Generate video clips from your images using Kling 2.0 Master",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos.jpg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoV2MasterRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "slow-motion sequence captures the catastrophic implosion of a skyscraper, dust and debris billowing outwards in a chaotic ballet of destruction, while a haunting, orchestral score underscores the sheer power and finality of the event."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/elephant/rkH-9qoXtXu3rAYTsx9V5_image.webp"
          ],
          "description": "URL of the image to be used for the video",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 28,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/wan-i2v",
    "name": "Wan-2.1 Image-to-Video",
    "description": "Wan-2.1 is a image-to-video model that generates high-quality videos with high visual quality and motion diversity from images",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video-image-to-video.webp",
    "tags": [
      "image to video",
      "motion"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "WanI2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Cars racing in slow motion"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "shift": {
          "minimum": 1,
          "maximum": 10,
          "type": "number",
          "description": "Shift parameter for video generation.",
          "title": "Shift",
          "default": 5
        },
        "acceleration": {
          "examples": [
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "enum": [
            "none",
            "regular"
          ],
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "default": "regular"
        },
        "frames_per_second": {
          "minimum": 5,
          "maximum": 24,
          "type": "integer",
          "title": "Frames Per Second",
          "description": "Frames per second of the generated video. Must be between 5 to 24.",
          "default": 16
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": false
        },
        "num_frames": {
          "minimum": 81,
          "title": "Num Frames",
          "type": "integer",
          "description": "Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
          "maximum": 100,
          "default": 81
        },
        "negative_prompt": {
          "examples": [
            "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/gallery/car_720p.png"
          ],
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
          "type": "string",
          "title": "Image Url"
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 40,
          "type": "integer",
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "title": "Num Inference Steps",
          "default": 30
        },
        "guide_scale": {
          "minimum": 1,
          "maximum": 10,
          "type": "number",
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "title": "Guide Scale",
          "default": 5
        },
        "seed": {
          "description": "Random seed for reproducibility. If None, a random seed is chosen.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_url",
        "num_frames",
        "frames_per_second",
        "seed",
        "resolution",
        "num_inference_steps",
        "guide_scale",
        "shift",
        "enable_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "aspect_ratio"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 8,
    "pricing_unit": "videos"
  },
  {
    "id": "bytedance/lynx",
    "name": "Lynx",
    "description": "Generate subject consistent videos using Lynx from ByteDance!",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/lion/49-4PP-6iG8KcIfhWAduK_ac8d9da273624a95bf696ff6e439debd.jpg",
    "tags": [
      "image-to-video",
      "subject"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LynxInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A person carves a pumpkin on a porch in the evening. The camera captures their upper body as they draw a face with a marker, carefully cut along the lines, then lift the lid with both hands. Their face lights up with excitement as they peek inside"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide video generation"
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p, 580p, or 720p)",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9, 9:16, or 1:1)",
          "default": "16:9"
        },
        "num_frames": {
          "minimum": 9,
          "title": "Num Frames",
          "type": "integer",
          "description": "Number of frames in the generated video. Must be between 9 to 100.",
          "maximum": 81,
          "default": 81
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/lynx/example_in.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The URL of the subject image to be used for video generation"
        },
        "strength": {
          "minimum": 0,
          "title": "Strength",
          "type": "number",
          "description": "Reference image scale. Controls the influence of the reference image on the generated video.",
          "maximum": 2,
          "default": 1
        },
        "frames_per_second": {
          "minimum": 5,
          "title": "Frames Per Second",
          "type": "integer",
          "description": "Frames per second of the generated video. Must be between 5 to 30.",
          "maximum": 30,
          "default": 16
        },
        "guidance_scale_2": {
          "minimum": 0,
          "title": "Guidance Scale 2",
          "type": "number",
          "description": "Image guidance scale. Controls how closely the generated video follows the reference image. Higher values increase adherence to the reference image but may decrease quality.",
          "maximum": 10,
          "default": 2
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale",
          "type": "number",
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "maximum": 20,
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "maximum": 75,
          "default": 50
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt to guide what should not appear in the generated video",
          "default": "Bright tones, overexposed, blurred background, static, subtitles, style, works, paintings, images, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
        },
        "ip_scale": {
          "minimum": 0,
          "title": "Ip Scale",
          "type": "number",
          "description": "Identity preservation scale. Controls how closely the generated video preserves the subject's identity from the reference image.",
          "maximum": 2,
          "default": 1
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "negative_prompt",
        "num_inference_steps",
        "seed",
        "resolution",
        "aspect_ratio",
        "ip_scale",
        "strength",
        "frames_per_second",
        "guidance_scale",
        "guidance_scale_2",
        "num_frames"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/pixverse/swap",
    "name": "Pixverse",
    "description": "Generate high quality video clips by swapping person, objects and background using Pixverse Swap.",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/panda/eTq_2p2OlIBu7MyDFdtWz_6290f4acd92c4382b04ed302b2aa5a3a.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SwapRequest",
      "type": "object",
      "properties": {
        "original_sound_switch": {
          "description": "Whether to keep the original audio",
          "type": "boolean",
          "title": "Original Sound Switch",
          "default": true
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p"
          ],
          "description": "The output resolution (1080p not supported)",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "keyframe_id": {
          "minimum": 1,
          "description": "The keyframe ID (from 1 to the last frame position)",
          "type": "integer",
          "title": "Keyframe Id",
          "default": 1
        },
        "mode": {
          "enum": [
            "person",
            "object",
            "background"
          ],
          "description": "The swap mode to use",
          "type": "string",
          "title": "Mode",
          "default": "person"
        },
        "video_url": {
          "examples": [
            "https://v3b.fal.media/files/b/lion/k_RpEIZ4YZtwZklzXz7Gb_output.mp4"
          ],
          "description": "URL of the external video to swap",
          "type": "string",
          "title": "Video Url"
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/elephant/Lu7lo2dpxVPD-NrNZzx42_56dc797a1f764c98a4f075a8c0332bf0.jpg"
          ],
          "description": "URL of the target image for swapping",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "video_url",
        "mode",
        "keyframe_id",
        "image_url",
        "resolution",
        "original_sound_switch"
      ],
      "required": [
        "video_url",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/longcat-video/image-to-video/720p",
    "name": "Longcat Video 720p",
    "description": "Generate long videos in 720p/30fps from images using LongCat Video",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/g4nDPc8_i-pYRxSK69VVs_b05afd7a74cc45699355fc55ccb85cdf.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": true,
    "input_schema": {
      "title": "LongCat720PCFGImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k"
          ],
          "description": "The prompt to guide the video generation.",
          "type": "string",
          "title": "Prompt",
          "default": "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k"
        },
        "acceleration": {
          "examples": [
            "regular"
          ],
          "description": "The acceleration level to use for the video generation.",
          "type": "string",
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "default": "regular"
        },
        "fps": {
          "minimum": 1,
          "title": "FPS",
          "type": "integer",
          "description": "The frame rate of the generated video.",
          "maximum": 60,
          "default": 30
        },
        "num_refine_inference_steps": {
          "minimum": 8,
          "title": "Number of Refinement Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use for refinement.",
          "maximum": 50,
          "default": 40
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable safety checker.",
          "default": true
        },
        "num_frames": {
          "description": "The number of frames to generate.",
          "type": "integer",
          "minimum": 17,
          "title": "Number of Frames",
          "maximum": 961,
          "default": 162
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale",
          "type": "number",
          "description": "The guidance scale to use for the video generation.",
          "maximum": 10,
          "default": 4
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use for the video generation.",
          "default": "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the generated video.",
          "default": "balanced"
        },
        "video_output_type": {
          "enum": [
            "X264 (.mp4)",
            "VP9 (.webm)",
            "PRORES4444 (.mov)",
            "GIF (.gif)"
          ],
          "title": "Video Output Type",
          "type": "string",
          "description": "The output type of the generated video.",
          "default": "X264 (.mp4)"
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/zebra/trXRsbjJwy4Z3OEgbnB9a.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate a video from."
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the generated video.",
          "default": "high"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 8,
          "title": "Number of Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use for the video generation.",
          "maximum": 50,
          "default": 40
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator."
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "negative_prompt",
        "num_frames",
        "num_inference_steps",
        "num_refine_inference_steps",
        "guidance_scale",
        "fps",
        "seed",
        "enable_prompt_expansion",
        "enable_safety_checker",
        "video_output_type",
        "video_quality",
        "video_write_mode",
        "sync_mode",
        "acceleration"
      ],
      "required": [
        "image_url"
      ]
    },
    "credits_per_5sec": 4,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/longcat-video/image-to-video/480p",
    "name": "LongCat Video",
    "description": "Generate long videos from images using LongCat Video",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/5ViX_LNixCVmYCYuCEgiY_45feeda8832a4eb18f832a70f8af564d.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LongCatCFGImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k"
          ],
          "description": "The prompt to guide the video generation.",
          "type": "string",
          "title": "Prompt",
          "default": "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k"
        },
        "acceleration": {
          "examples": [
            "regular"
          ],
          "description": "The acceleration level to use for the video generation.",
          "type": "string",
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "default": "regular"
        },
        "fps": {
          "minimum": 1,
          "title": "FPS",
          "type": "integer",
          "description": "The frame rate of the generated video.",
          "maximum": 60,
          "default": 15
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable safety checker.",
          "default": true
        },
        "num_frames": {
          "description": "The number of frames to generate.",
          "type": "integer",
          "minimum": 17,
          "title": "Number of Frames",
          "maximum": 961,
          "default": 162
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale",
          "type": "number",
          "description": "The guidance scale to use for the video generation.",
          "maximum": 10,
          "default": 4
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use for the video generation.",
          "default": "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the generated video.",
          "default": "balanced"
        },
        "video_output_type": {
          "enum": [
            "X264 (.mp4)",
            "VP9 (.webm)",
            "PRORES4444 (.mov)",
            "GIF (.gif)"
          ],
          "title": "Video Output Type",
          "type": "string",
          "description": "The output type of the generated video.",
          "default": "X264 (.mp4)"
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/zebra/trXRsbjJwy4Z3OEgbnB9a.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate a video from."
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the generated video.",
          "default": "high"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 8,
          "title": "Number of Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use for the video generation.",
          "maximum": 50,
          "default": 40
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator."
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "negative_prompt",
        "num_frames",
        "num_inference_steps",
        "guidance_scale",
        "fps",
        "seed",
        "enable_prompt_expansion",
        "enable_safety_checker",
        "video_output_type",
        "video_quality",
        "video_write_mode",
        "sync_mode",
        "acceleration"
      ],
      "required": [
        "image_url"
      ]
    },
    "credits_per_5sec": 3,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/longcat-video/distilled/image-to-video/720p",
    "name": "LongCat Video Distilled",
    "description": "Generate long videos in 720p/30fps from images using LongCat Video Distilled",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/gS8j6NAcRDw4yUVAt9aAz_cb5675eaa23149ae9be06d1684f2ee3f.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LongCat720PImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k"
          ],
          "description": "The prompt to guide the video generation.",
          "type": "string",
          "title": "Prompt",
          "default": "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k"
        },
        "video_output_type": {
          "enum": [
            "X264 (.mp4)",
            "VP9 (.webm)",
            "PRORES4444 (.mov)",
            "GIF (.gif)"
          ],
          "title": "Video Output Type",
          "type": "string",
          "description": "The output type of the generated video.",
          "default": "X264 (.mp4)"
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the generated video.",
          "default": "balanced"
        },
        "fps": {
          "minimum": 1,
          "title": "FPS",
          "type": "integer",
          "description": "The frame rate of the generated video.",
          "maximum": 60,
          "default": 30
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/zebra/trXRsbjJwy4Z3OEgbnB9a.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate a video from."
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the generated video.",
          "default": "high"
        },
        "num_refine_inference_steps": {
          "minimum": 2,
          "title": "Number of Refinement Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use for refinement.",
          "maximum": 16,
          "default": 12
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "num_frames": {
          "description": "The number of frames to generate.",
          "type": "integer",
          "minimum": 17,
          "title": "Number of Frames",
          "maximum": 961,
          "default": 162
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable safety checker.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Number of Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use.",
          "maximum": 16,
          "default": 12
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator."
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "num_frames",
        "num_inference_steps",
        "num_refine_inference_steps",
        "fps",
        "seed",
        "enable_prompt_expansion",
        "enable_safety_checker",
        "video_output_type",
        "video_quality",
        "video_write_mode",
        "sync_mode"
      ],
      "required": [
        "image_url"
      ]
    },
    "credits_per_5sec": 1,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/longcat-video/distilled/image-to-video/480p",
    "name": "LongCat Video Distilled",
    "description": "Generate long videos from images using LongCat Video Distilled",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/3d4yOBDSZ0g2z6pPOr3qP_bbe50a030bbb497d9417bfc0e5129536.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LongCatImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k"
          ],
          "description": "The prompt to guide the video generation.",
          "type": "string",
          "title": "Prompt",
          "default": "First-person view from the cockpit of a Formula 1 car. The driver's gloved hands firmly grip the intricate, carbon-fiber steering wheel adorned with numerous colorful buttons and a vibrant digital display showing race data. Beyond the windshield, a sun-drenched racetrack stretches ahead, lined with cheering spectators in the grandstands. Several rival cars are visible in the distance, creating a dynamic sense of competition. The sky above is a clear, brilliant blue, reflecting the exhilarating atmosphere of a high-speed race. high resolution 4k"
        },
        "video_output_type": {
          "enum": [
            "X264 (.mp4)",
            "VP9 (.webm)",
            "PRORES4444 (.mov)",
            "GIF (.gif)"
          ],
          "title": "Video Output Type",
          "type": "string",
          "description": "The output type of the generated video.",
          "default": "X264 (.mp4)"
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the generated video.",
          "default": "balanced"
        },
        "image_url": {
          "examples": [
            "https://v3b.fal.media/files/b/zebra/trXRsbjJwy4Z3OEgbnB9a.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate a video from."
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the generated video.",
          "default": "high"
        },
        "fps": {
          "minimum": 1,
          "title": "FPS",
          "type": "integer",
          "description": "The frame rate of the generated video.",
          "maximum": 60,
          "default": 15
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "num_frames": {
          "description": "The number of frames to generate.",
          "type": "integer",
          "minimum": 17,
          "title": "Number of Frames",
          "maximum": 961,
          "default": 162
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable safety checker.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Number of Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use.",
          "maximum": 16,
          "default": 12
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator."
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "num_frames",
        "num_inference_steps",
        "fps",
        "seed",
        "enable_prompt_expansion",
        "enable_safety_checker",
        "video_output_type",
        "video_quality",
        "video_write_mode",
        "sync_mode"
      ],
      "required": [
        "image_url"
      ]
    },
    "credits_per_5sec": 1,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3-fast/standard/image-to-video",
    "name": "MiniMax Hailuo 2.3 Fast [Standard] (Image to Video)",
    "description": "MiniMax Hailuo-2.3-Fast Image To Video API (Standard, 768p): Advanced fast image-to-video generation model with 768p resolution",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/elephant/Qa714sjGzfM3X59sy7I9y_12d9a8d139204572b25ee2e9ec6c92d1.jpg",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "StandardFastImageToVideoHailuo23Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "duration": {
          "enum": [
            "6",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the video in seconds.",
          "default": "6"
        },
        "prompt": {
          "examples": [
            "Athlete running powerfully on beach, dynamic camera movement tracking the runner, waves and sunset in motion, Hollywood movie cinematography, professional sports filming, inspiring atmosphere"
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000,
          "description": "Text prompt for video generation",
          "minLength": 1
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/hailuo23/fast_standard_i2v_in.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "prompt_optimizer",
        "image_url",
        "duration"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 4,
    "pricing_unit": "units"
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3/standard/image-to-video",
    "name": "MiniMax Hailuo 2.3 [Standard] (Image to Video)",
    "description": "MiniMax Hailuo-2.3 Image To Video API (Standard, 768p): Advanced image-to-video generation model with 768p resolution",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/zebra/7kDvX2hsHnnUu9mSt-I_C_3a18467c2b234f6590e01edd53840f2d.jpg",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "StandardImageToVideoHailuo23Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "duration": {
          "enum": [
            "6",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the video in seconds.",
          "default": "6"
        },
        "prompt": {
          "examples": [
            "The space station slowly rotates in orbit, its solar panels tracking the sun. Earth rotates majestically in the background with weather patterns and landmasses drifting by. The station's communication arrays adjust position. A small spacecraft approaches one of the docking ports. The scene captures the silent majesty of space and human engineering."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000,
          "description": "Text prompt for video generation",
          "minLength": 1
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/hailuo23/standard_i2v_in.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "prompt_optimizer",
        "duration",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 6,
    "pricing_unit": "units"
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3-fast/pro/image-to-video",
    "name": "MiniMax Hailuo 2.3 Fast [Pro] (Image to Video)",
    "description": "MiniMax Hailuo-2.3-Fast Image To Video API (Pro, 1080p): Advanced fast image-to-video generation model with 1080p resolution",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/37ZHJodysdkE5NcfUc3fu_5731672b9b3c4e47b4b851a5145e5d3c.jpg",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ProFastImageToVideoHailuo23Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "Subject-tracking orbit: camera glides parallel to astronaut, Earth rotates beneath, sun crest reveals lens flare, astronaut tethers and spins slowly, 8K 60 fps slow-motion, ends with spacecraft blackout on sun disk"
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000,
          "description": "Text prompt for video generation",
          "minLength": 1
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/hailuo23/fast_pro_i2v_in.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "prompt_optimizer",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 7,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/pro/fast/image-to-video",
    "name": "Bytedance",
    "description": "Image to Video endpoint for Seedance 1.0 Pro Fast, a next-generation video model designed to deliver maximum performance at minimal cost",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/OHnRF5artsmMtvv5DikBL_0d31376b45fc47c28ad70e15245ca449.jpg",
    "tags": [
      "bytedance",
      "seedance",
      "pro",
      "fast"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "camera_fixed",
        "seed",
        "enable_safety_checker",
        "image_url"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Bathed in a stark spotlight, a lone ballet dancer takes center stage. Her movements, precise and graceful, tell a story of passion and dedication against the velvet darkness. The scene evokes a sense of intimacy, highlighting the raw emotion and artistry of her performance."
          ],
          "description": "The text prompt used to generate the video",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16",
            "auto"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "duration": {
          "enum": [
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
          ],
          "description": "Duration of the video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p",
            "1080p"
          ],
          "description": "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
          "type": "string",
          "title": "Resolution",
          "default": "1080p"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/seedance_fast_i2v_input.png"
          ],
          "description": "The URL of the image used to generate video",
          "type": "string",
          "title": "Image Url"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "camera_fixed": {
          "description": "Whether to fix the camera position",
          "type": "boolean",
          "title": "Camera Fixed",
          "default": false
        },
        "seed": {
          "description": "Random seed to control video generation. Use -1 for random.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "SeedanceProFastImageToVideoInput",
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/vidu/q2/image-to-video/turbo",
    "name": "Vidu",
    "description": "Use the latest Vidu Q2 models which much more better quality and control on your videos.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/pV-tsWf3pDIWfSzE8Y8QD_405c6376ad454bdd9aec52cfcc23a97e.jpg",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Q2ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman walking through a vibrant city street at night, neon lights reflecting off wet pavement."
          ],
          "maxLength": 3000,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 3000 characters"
        },
        "duration": {
          "enum": [
            2,
            3,
            4,
            5,
            6,
            7,
            8
          ],
          "title": "Duration",
          "type": "integer",
          "description": "Duration of the video in seconds",
          "default": 4
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Output video resolution",
          "default": "720p"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the starting frame"
        },
        "bgm": {
          "title": "Bgm",
          "type": "boolean",
          "description": "Whether to add background music to the video (only for 4-second videos)",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "seed",
        "duration",
        "resolution",
        "movement_amplitude",
        "bgm"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/vidu/q2/image-to-video/pro",
    "name": "Vidu",
    "description": "Use the latest Vidu Q2 models which much more better quality and control on your videos.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/rabbit/9ZFHimyaNGh_0WHvVLfOn_67d61fe778bd4257a402b467aaff6f66.jpg",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Q2ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman walking through a vibrant city street at night, neon lights reflecting off wet pavement."
          ],
          "maxLength": 3000,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 3000 characters"
        },
        "duration": {
          "enum": [
            2,
            3,
            4,
            5,
            6,
            7,
            8
          ],
          "title": "Duration",
          "type": "integer",
          "description": "Duration of the video in seconds",
          "default": 4
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Output video resolution",
          "default": "720p"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the starting frame"
        },
        "bgm": {
          "title": "Bgm",
          "type": "boolean",
          "description": "Whether to add background music to the video (only for 4-second videos)",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "seed",
        "duration",
        "resolution",
        "movement_amplitude",
        "bgm"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/ltxv-2/image-to-video/fast",
    "name": "LTX Video 2.0 Fast",
    "description": "Create high-fidelity video with audio from images with LTX-2 Fast",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/OdQJdqqToEMWzSaiNh68b_cc8c521793624020b4a86056a3b498d0.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "duration",
        "resolution",
        "aspect_ratio",
        "fps",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman stands still amid a busy neon-lit street at night. The camera slowly dollies in toward her face as people blur past, their motion emphasizing her calm presence. City lights flicker and reflections shift across her denim jacket."
          ],
          "maxLength": 5000,
          "minLength": 1,
          "title": "Prompt",
          "description": "The prompt to generate the video from",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            6,
            8,
            10,
            12,
            14,
            16,
            18,
            20
          ],
          "description": "The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.",
          "type": "integer",
          "title": "Duration",
          "default": 6
        },
        "generate_audio": {
          "description": "Whether to generate audio for the generated video",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "resolution": {
          "enum": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "1080p"
        },
        "fps": {
          "enum": [
            25,
            50
          ],
          "description": "The frames per second of the generated video",
          "type": "integer",
          "title": "Frames per Second",
          "default": 25
        },
        "image_url": {
          "description": "URL of the image to generate the video from. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.",
          "type": "string",
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/ltxv-2-i2v-input.jpg"
          ],
          "title": "Image URL",
          "x-fal": {
            "timeout": 20,
            "max_file_size": 7340032
          },
          "limit_description": "Max file size: 7.0MB, Timeout: 20.0s"
        }
      },
      "title": "LTXVImageToVideoFastRequest",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 4,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/ltxv-2/image-to-video",
    "name": "LTX Video 2.0 Pro",
    "description": "Create high-fidelity video with audio from images with LTX-2 Pro",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/jFuLJyFYw6CnRfSpmA8BG_82dec35b7bd143ee9abd2615f8052957.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "duration",
        "resolution",
        "aspect_ratio",
        "fps",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman stands still amid a busy neon-lit street at night. The camera slowly dollies in toward her face as people blur past, their motion emphasizing her calm presence. City lights flicker and reflections shift across her denim jacket."
          ],
          "maxLength": 5000,
          "minLength": 1,
          "title": "Prompt",
          "description": "The prompt to generate the video from",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            6,
            8,
            10
          ],
          "description": "The duration of the generated video in seconds",
          "type": "integer",
          "title": "Duration",
          "default": 6
        },
        "generate_audio": {
          "description": "Whether to generate audio for the generated video",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "resolution": {
          "enum": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "1080p"
        },
        "fps": {
          "enum": [
            25,
            50
          ],
          "description": "The frames per second of the generated video",
          "type": "integer",
          "title": "Frames per Second",
          "default": 25
        },
        "image_url": {
          "description": "URL of the image to generate the video from. Must be publicly accessible or base64 data URI. Supports PNG, JPEG, WebP, AVIF, and HEIF formats.",
          "type": "string",
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/ltxv-2-i2v-input.jpg"
          ],
          "title": "Image URL",
          "x-fal": {
            "timeout": 20,
            "max_file_size": 7340032
          },
          "limit_description": "Max file size: 7.0MB, Timeout: 20.0s"
        }
      },
      "title": "LTXVImageToVideoRequest",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 6,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/vidu/q2/reference-to-video",
    "name": "Vidu",
    "description": "Use the latest Vidu Q2 models which much more better quality and control on your videos.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/rabbit/9ZFHimyaNGh_0WHvVLfOn_67d61fe778bd4257a402b467aaff6f66.jpg",
    "tags": [
      "reference-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Q2ReferenceToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A character walking through a beach catching an apple."
          ],
          "maxLength": 3000,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 3000 characters"
        },
        "duration": {
          "enum": [
            1,
            2,
            3,
            4,
            5,
            6,
            7,
            8
          ],
          "title": "Duration",
          "type": "integer",
          "description": "Duration of the video in seconds",
          "default": 4
        },
        "resolution": {
          "enum": [
            "360p",
            "520p",
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Output video resolution",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the output video",
          "default": "16:9"
        },
        "bgm": {
          "title": "Bgm",
          "type": "boolean",
          "description": "Whether to add background music to the video (only for 4-second videos)",
          "default": false
        },
        "reference_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference1.png",
              "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference2.png",
              "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference3.png"
            ]
          ],
          "title": "Reference Image Urls",
          "type": "array",
          "description": "URLs of the reference images to use for consistent subject appearance (up to 7 images)",
          "items": {
            "type": "string"
          }
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "reference_image_urls",
        "seed",
        "duration",
        "resolution",
        "aspect_ratio",
        "movement_amplitude",
        "bgm"
      ],
      "required": [
        "prompt",
        "reference_image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v2.5-turbo/standard/image-to-video",
    "name": "Kling Video",
    "description": "Kling 2.5 Turbo Standard: Top-tier image-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/elephant/BJ1ZIdeClgqnUTW9XgEUS_d00e816ad20849ae9f92b735358d610d.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoV25StandardRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "In a dimly lit room, a playful cat's eyes light up, fixated on a dancing red dot. With boundless energy, it pounces and leaps, chasing the elusive beam across the floor and up the walls. The simple joy of the hunt unfolds in clear, uncomplicated visuals."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/kling_v25_std_i2v_input.png"
          ],
          "description": "URL of the image to be used for the video",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 4,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/veo3.1/fast/first-last-frame-to-video",
    "name": "Veo 3.1 Fast",
    "description": "Generate videos from a first/last frame using Google's Veo 3.1 Fast",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/rabbit/8tRJcj1P_EtIcpbdkP3m7_f9984366e4054165a8919d0671acbcb3.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "first_frame_url",
        "last_frame_url",
        "prompt",
        "duration",
        "aspect_ratio",
        "resolution",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman looks into the camera, breathes in, then exclaims energetically, \"have you guys checked out Veo3.1 First-Last-Frame-to-Video on Fal? It's incredible!\""
          ],
          "description": "The text prompt describing the video you want to generate",
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "4s",
            "6s",
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "9:16",
            "16:9",
            "1:1"
          ],
          "description": "Aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 33% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "Resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "first_frame_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/veo31-flf2v-input-1.jpeg"
          ],
          "title": "First Frame URL",
          "type": "string",
          "description": "URL of the first frame of the video"
        },
        "last_frame_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/veo31-flf2v-input-2.jpeg"
          ],
          "title": "Last Frame URL",
          "type": "string",
          "description": "URL of the last frame of the video"
        }
      },
      "title": "FirstLastFrameToVideoFastInput",
      "required": [
        "first_frame_url",
        "last_frame_url",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/veo3.1/first-last-frame-to-video",
    "name": "Veo 3.1 First-Last Frame",
    "description": "Generate videos from a first and last framed using Google's Veo 3.1",
    "category": "image-to-video",
    "thumbnail_url": "/video-thumbnails/veo31-thumb.mp4",
    "tags": [],
    "highlighted": true,
    "pinned": true,
    "input_schema": {
      "x-fal-order-properties": [
        "first_frame_url",
        "last_frame_url",
        "prompt",
        "duration",
        "aspect_ratio",
        "resolution",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman looks into the camera, breathes in, then exclaims energetically, \"have you guys checked out Veo3.1 First-Last-Frame-to-Video on Fal? It's incredible!\""
          ],
          "description": "The text prompt describing the video you want to generate",
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "4s",
            "6s",
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "9:16",
            "16:9",
            "1:1"
          ],
          "description": "Aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 50% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "Resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "first_frame_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/veo31-flf2v-input-1.jpeg"
          ],
          "title": "First Frame URL",
          "type": "string",
          "description": "URL of the first frame of the video"
        },
        "last_frame_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/veo31-flf2v-input-2.jpeg"
          ],
          "title": "Last Frame URL",
          "type": "string",
          "description": "URL of the last frame of the video"
        }
      },
      "title": "FirstLastFrameToVideoInput",
      "required": [
        "first_frame_url",
        "last_frame_url",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/veo3.1/reference-to-video",
    "name": "Veo 3.1",
    "description": "Generate Videos from images using Google's Veo 3.1",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/tiger/IwzOGSbzp6e8N00QuLtFF_129417bb24f248298e95c3fa2b1b82fb.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_urls",
        "prompt",
        "duration",
        "resolution",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A graceful ballerina dancing outside a circus tent on green grass, with colorful wildflowers swaying around her as she twirls and poses in the meadow."
          ],
          "description": "The text prompt describing the video you want to generate",
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "Resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 50% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/veo31-r2v-input-1.png",
              "https://storage.googleapis.com/falserverless/example_inputs/veo31-r2v-input-2.png",
              "https://storage.googleapis.com/falserverless/example_inputs/veo31-r2v-input-3.png"
            ]
          ],
          "description": "URLs of the reference images to use for consistent subject appearance",
          "type": "array",
          "title": "Image Urls",
          "items": {
            "type": "string"
          }
        }
      },
      "title": "ReferenceToVideoInput",
      "required": [
        "image_urls",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/veo3.1/fast/image-to-video",
    "name": "Veo 3.1 Fast",
    "description": "Generate videos from your image prompts using Veo 3.1 fast.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/tiger/CcVVXXOo5stpgsAJV_6UO_74aa2dbdc79447e7ae69b533a7863038.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "aspect_ratio",
        "duration",
        "generate_audio",
        "resolution"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman looks into the camera, breathes in, then exclaims energetically, \"have you guys checked out Veo3 Image-to-Video on Fal? It's incredible!\""
          ],
          "description": "The text prompt describing how the image should be animated",
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "4s",
            "6s",
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "9:16",
            "16:9",
            "1:1"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 33% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "Resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/veo3-i2v-input.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit."
        }
      },
      "title": "ImageToVideoPreviewFastInput",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 15,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/veo3.1/image-to-video",
    "name": "Veo 3.1",
    "description": "Veo 3.1 is the latest state-of-the art video generation model from Google DeepMind",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/zebra/G680VZS5VpMMQO1pSt2uj_dfbae33f738344aa98a62cf2022c427c.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "aspect_ratio",
        "duration",
        "generate_audio",
        "resolution"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A monkey and polar bear host a casual podcast about AI inference, bringing their unique perspectives from different environments (tropical vs. arctic) to discuss how AI systems make decisions and process information.\nSample Dialogue:\nMonkey (Banana): \"Welcome back to Bananas & Ice! I am Banana\"\nPolar Bear (Ice): \"And I'm Ice!\""
          ],
          "description": "The text prompt describing the video you want to generate",
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "4s",
            "6s",
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "description": "The aspect ratio of the generated video. Only 16:9 and 9:16 are supported.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 50% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "Resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/veo31_i2v_input.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit."
        }
      },
      "title": "ImageToVideo31Input",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 40,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/sora-2/image-to-video/pro",
    "name": "Sora 2",
    "description": "Image-to-video endpoint for Sora 2 Pro, OpenAI's state-of-the-art video model capable of creating richly detailed, dynamic clips with audio from natural language or images.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/koala/19D6ouLhOE6EKGbUTnfzf_b958de62e48c4356a1c58abef534060b.jpg",
    "tags": [
      "image-to-video",
      "audio",
      "sora-2-pro"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "resolution",
        "aspect_ratio",
        "duration",
        "delete_video",
        "image_url"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Front-facing 'invisible' action-cam on a skydiver in freefall above bright clouds; camera locked on his face. He speaks over the wind with clear lipsync: 'This is insanely fun! You've got to try it\u2014book a tandem and go!' Natural wind roar, voice close-mic'd and slightly compressed so it's intelligible. Midday sun, goggles and jumpsuit flutter, altimeter visible, parachute rig on shoulders. Energetic but stable framing with subtle shake; brief horizon roll. End on first tug of canopy and wind noise dropping."
          ],
          "maxLength": 5000,
          "minLength": 1,
          "title": "Prompt",
          "description": "The text prompt describing the video you want to generate",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "9:16",
            "16:9"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "resolution": {
          "enum": [
            "auto",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "auto"
        },
        "duration": {
          "enum": [
            4,
            8,
            12
          ],
          "description": "Duration of the generated video in seconds",
          "type": "integer",
          "title": "Duration",
          "default": 4
        },
        "delete_video": {
          "description": "Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.",
          "type": "boolean",
          "title": "Delete Video",
          "default": true
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/sora-2-i2v-input.png"
          ],
          "description": "The URL of the image to use as the first frame",
          "type": "string",
          "title": "Image URL"
        }
      },
      "title": "ProImageToVideoInput",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/sora-2/image-to-video",
    "name": "Sora 2",
    "description": "Image-to-video endpoint for Sora 2, OpenAI's state-of-the-art video model capable of creating richly detailed, dynamic clips with audio from natural language or images.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/kangaroo/8n-yLTQvW5q0BEvW0H2J3_8233c7e127124290b6dfa965f44ebc79.jpg",
    "tags": [
      "image-to-video",
      "audio",
      "sora"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "resolution",
        "aspect_ratio",
        "duration",
        "delete_video",
        "image_url"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Front-facing 'invisible' action-cam on a skydiver in freefall above bright clouds; camera locked on his face. He speaks over the wind with clear lipsync: 'This is insanely fun! You've got to try it\u2014book a tandem and go!' Natural wind roar, voice close-mic'd and slightly compressed so it's intelligible. Midday sun, goggles and jumpsuit flutter, altimeter visible, parachute rig on shoulders. Energetic but stable framing with subtle shake; brief horizon roll. End on first tug of canopy and wind noise dropping."
          ],
          "maxLength": 5000,
          "minLength": 1,
          "title": "Prompt",
          "description": "The text prompt describing the video you want to generate",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "9:16",
            "16:9"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "resolution": {
          "enum": [
            "auto",
            "720p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "auto"
        },
        "duration": {
          "enum": [
            4,
            8,
            12
          ],
          "description": "Duration of the generated video in seconds",
          "type": "integer",
          "title": "Duration",
          "default": 4
        },
        "delete_video": {
          "description": "Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.",
          "type": "boolean",
          "title": "Delete Video",
          "default": true
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/sora-2-i2v-input.png"
          ],
          "description": "The URL of the image to use as the first frame",
          "type": "string",
          "title": "Image URL"
        }
      },
      "title": "ImageToVideoInput",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/ovi/image-to-video",
    "name": "Ovi",
    "description": "Ovi can generate videos with audio from image and text inputs.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/elephant/0C5YI172kcCI9lcCtXDJI_61f25dd2c735440aafb1a2ec647b6bd0.jpg",
    "tags": [
      "image-to-audio-video",
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "OviI2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "An intimate close-up of a European woman with long dark hair as she gently brushes her hair in a softly lit bedroom, her delicate hand moving in the foreground. She looks directly into the camera with calm, focused eyes, a faint serene smile glowing in the warm lamp light. She says, <S>[soft whisper] I am an artificial intelligence.<E>.<AUDCAP>Soft whispering female voice, ASMR tone with gentle breaths, cozy room acoustics, subtle emphasis on \"I am an artificial intelligence\".<ENDAUDCAP>"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps.",
          "default": 30
        },
        "audio_negative_prompt": {
          "title": "Audio Negative Prompt",
          "type": "string",
          "description": "Negative prompt for audio generation.",
          "default": "robotic, muffled, echo, distorted"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": "jitter, bad hands, blur, distortion"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/ovi_i2v_input.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The image URL to guide video generation."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_inference_steps",
        "audio_negative_prompt",
        "seed",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 4,
    "pricing_unit": "videos"
  },
  {
    "id": "veed/fabric-1.0/fast",
    "name": "Fabric 1.0 Fast",
    "description": "VEED Fabric 1.0 is an image-to-video API that turns any image into a talking video",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/zebra/AGRvOvMtrM0o02wz8-hRF_cb5739a5199b49a7971c5319881c6765.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "audio_url",
        "resolution"
      ],
      "type": "object",
      "properties": {
        "resolution": {
          "enum": [
            "720p",
            "480p"
          ],
          "description": "Resolution",
          "type": "string",
          "title": "Resolution"
        },
        "audio_url": {
          "examples": [
            "https://v3.fal.media/files/elephant/Oz_g4AwQvXtXpUHL3Pa7u_Hope.mp3"
          ],
          "maxLength": 2083,
          "type": "string",
          "format": "uri",
          "minLength": 1,
          "title": "Audio Url"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/NLVPfOI4XL1cWT2PmmqT3_Hope.png"
          ],
          "maxLength": 2083,
          "type": "string",
          "format": "uri",
          "minLength": 1,
          "title": "Image Url"
        }
      },
      "title": "FabricOneLipsyncInput",
      "required": [
        "image_url",
        "audio_url",
        "resolution"
      ]
    }
  },
  {
    "id": "fal-ai/bytedance/omnihuman/v1.5",
    "name": "Bytedance OmniHuman v1.5",
    "description": "Omnihuman v1.5 is a new and improved version of Omnihuman. It generates video using an image of a human figure paired with an audio file. It produces vivid, high-quality videos where the character\u2019s emotions and movements maintain a strong correlation with the audio.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/penguin/E4JFEyBXM1DccJUOvp5_e_6414b61bc2e141edb34671e5308addef.jpg",
    "tags": [
      "image-to-video",
      "lipsync",
      ""
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "audio_url"
      ],
      "type": "object",
      "properties": {
        "audio_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/omnihuman_v15_input_audio.mp3"
          ],
          "description": "The URL of the audio file to generate the video. Audio must be under 30s long.",
          "type": "string",
          "title": "Audio Url"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/omnihuman_v15_input_image.png"
          ],
          "description": "The URL of the image used to generate the video",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "OmniHumanv15Input",
      "required": [
        "image_url",
        "audio_url"
      ]
    }
  },
  {
    "id": "veed/fabric-1.0",
    "name": "Fabric 1.0",
    "description": "VEED Fabric 1.0 is an image-to-video API that turns any image into a talking video",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/zebra/t3xqW_dkjrcRc2vmUS0EN_10a217d1a5ba4488be7bb1967189ef65.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "audio_url",
        "resolution"
      ],
      "type": "object",
      "properties": {
        "resolution": {
          "enum": [
            "720p",
            "480p"
          ],
          "description": "Resolution",
          "type": "string",
          "title": "Resolution"
        },
        "audio_url": {
          "examples": [
            "https://v3.fal.media/files/elephant/Oz_g4AwQvXtXpUHL3Pa7u_Hope.mp3"
          ],
          "maxLength": 2083,
          "type": "string",
          "format": "uri",
          "minLength": 1,
          "title": "Audio Url"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/NLVPfOI4XL1cWT2PmmqT3_Hope.png"
          ],
          "maxLength": 2083,
          "type": "string",
          "format": "uri",
          "minLength": 1,
          "title": "Image Url"
        }
      },
      "title": "FabricOneLipsyncInput",
      "required": [
        "image_url",
        "audio_url",
        "resolution"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1/standard/ai-avatar",
    "name": "Kling AI Avatar",
    "description": "Kling AI Avatar Standard:  Endpoint for creating avatar videos with realistic humans, animals, cartoons, or stylized characters",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/rabbit/me_wmKnQJJevTKvSLGMF7_2948b05301c24578b9d28acb927f9c5c.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AIAvatarInput",
      "type": "object",
      "properties": {
        "prompt": {
          "description": "The prompt to use for the video generation.",
          "type": "string",
          "title": "Prompt",
          "default": "."
        },
        "audio_url": {
          "examples": [
            "https://v3.fal.media/files/rabbit/9_0ZG_geiWjZOmn9yscO6_output.mp3"
          ],
          "description": "The URL of the audio file.",
          "type": "string",
          "title": "Audio Url"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/kling_ai_avatar_input.jpg"
          ],
          "description": "The URL of the image to use as your avatar",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "audio_url",
        "prompt"
      ],
      "required": [
        "image_url",
        "audio_url"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1/pro/ai-avatar",
    "name": "Kling AI Avatar Pro",
    "description": "Kling AI Avatar Pro: The premium endpoint for creating avatar videos with realistic humans, animals, cartoons, or stylized characters",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/tiger/JkgpF_2-txAoKmW7MuTqt_0871571d0ba34433b57f86fbce62d273.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AIAvatarInput",
      "type": "object",
      "properties": {
        "prompt": {
          "description": "The prompt to use for the video generation.",
          "type": "string",
          "title": "Prompt",
          "default": "."
        },
        "audio_url": {
          "examples": [
            "https://v3.fal.media/files/rabbit/9_0ZG_geiWjZOmn9yscO6_output.mp3"
          ],
          "description": "The URL of the audio file.",
          "type": "string",
          "title": "Audio Url"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/kling_ai_avatar_input.jpg"
          ],
          "description": "The URL of the image to use as your avatar",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "audio_url",
        "prompt"
      ],
      "required": [
        "image_url",
        "audio_url"
      ]
    }
  },
  {
    "id": "decart/lucy-14b/image-to-video",
    "name": "Decart Lucy 14b",
    "description": "Lucy-14B delivers lightning fast performance that redefines what's possible with image-to-video AI",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/panda/CmMm-4CuFQUroMjHGYrv9_99edaa2eb5b34834b08717f4fbc23cca.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "resolution",
        "aspect_ratio",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cinematic video begins with a woman standing in an art studio, wearing a paint-splattered apron over a white off-shoulder blouse, surrounded by colorful canvases on easels. She gently plays with her hair for a moment, then straightens her head and looks directly at the camera with a warm smile. After holding the smile, she gracefully twirls around in place, her apron flowing slightly with the motion, creating a playful and artistic atmosphere against the backdrop of her vibrant paintings."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text description of the desired video content",
          "maxLength": 1500
        },
        "resolution": {
          "enum": [
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video.",
          "default": "16:9"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated\n            and uploaded before returning the response. This will increase the\n            latency of the function but it allows you to get the image directly\n            in the response without going through the CDN.\n        ",
          "default": true
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/lucy-14b/lucy-14b-art-swirl-image.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "title": "Lucy14BImageToVideoInput",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 8,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/lite/reference-to-video",
    "name": "Bytedance",
    "description": "Seedance lite reference-to-video allows the use of 1 to 4 images as reference to create a high-quality video.",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/kangaroo/B49-COdFROSlS850S1PfV_be7c6c85a41b4410ae02216253e5c6f8.jpg",
    "tags": [
      "reference-to-video",
      "image-to-video",
      ""
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "camera_fixed",
        "seed",
        "enable_safety_checker",
        "reference_image_urls"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The girl catches the puppy and hugs it."
          ],
          "description": "The text prompt used to generate the video",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16",
            "auto"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "description": "Video resolution - 480p for faster generation, 720p for higher quality",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "duration": {
          "enum": [
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
          ],
          "description": "Duration of the video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "camera_fixed": {
          "description": "Whether to fix the camera position",
          "type": "boolean",
          "title": "Camera Fixed",
          "default": false
        },
        "seed": {
          "description": "Random seed to control video generation. Use -1 for random.",
          "type": "integer",
          "title": "Seed"
        },
        "reference_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/seedance_reference.jpeg",
              "https://storage.googleapis.com/falserverless/example_inputs/seedance_reference_2.jpeg"
            ]
          ],
          "description": "Reference images to generate the video with.",
          "type": "array",
          "title": "Reference Image Urls",
          "items": {
            "type": "string"
          }
        }
      },
      "title": "SeedanceReferenceToVideoInput",
      "required": [
        "prompt",
        "reference_image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/decart/lucy-5b/image-to-video",
    "name": "Decart",
    "description": "Lucy-5B is a model that can create 5-second I2V videos in under 5 seconds, achieving >1x RTF end-to-end",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/kangaroo/srM1hEjGsuYwd4UhvzpE7_c5bddd630600497e918bb16e99e21653.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ProcessRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cat is walking slowly in the garden"
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 1500,
          "description": "Text description of the desired video content"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video.",
          "default": "16:9"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": true
        },
        "resolution": {
          "enum": [
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video",
          "default": "720p"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/monkey/OlpQEYh7oNeJ3qKsdiaym_ia5ECOgFbfcniMDu01_18_da73e078e0924472b51d92f3e3fba98c.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "resolution",
        "aspect_ratio",
        "sync_mode"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 3,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/pixverse/v5/transition",
    "name": "Pixverse",
    "description": "Create seamless transition between images using PixVerse v5",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TransitionRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Scene slowly transition into cat swimming under water"
          ],
          "description": "The prompt for the transition",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "first_image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/owQh2DAzk8UU7J02nr5RY_Co2P4boLv6meIZ5t9gKvL_8685da151df343ab8bf82165c928e2a5.jpg"
          ],
          "description": "URL of the image to use as the first frame",
          "type": "string",
          "title": "First Image Url"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "end_image_url": {
          "examples": [
            "https://v3.fal.media/files/kangaroo/RgedFs_WSnq5BgER7qDx1_ONrbTJ1YAGXz-9JnSsBoB_bdc8750387734bfe940319f469f7b0b2.jpg"
          ],
          "description": "URL of the image to use as the last frame",
          "type": "string",
          "title": "End Image Url"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed",
        "first_image_url",
        "end_image_url"
      ],
      "required": [
        "prompt",
        "first_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/pixverse/v5/effects",
    "name": "Pixverse",
    "description": "Generate high quality video clips with different effects using PixVerse v5",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "EffectInput",
      "type": "object",
      "properties": {
        "negative_prompt": {
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video.",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "effect": {
          "enum": [
            "Kiss Me AI",
            "Kiss",
            "Muscle Surge",
            "Warmth of Jesus",
            "Anything, Robot",
            "The Tiger Touch",
            "Hug",
            "Holy Wings",
            "Microwave",
            "Zombie Mode",
            "Squid Game",
            "Baby Face",
            "Black Myth: Wukong",
            "Long Hair Magic",
            "Leggy Run",
            "Fin-tastic Mermaid",
            "Punch Face",
            "Creepy Devil Smile",
            "Thunder God",
            "Eye Zoom Challenge",
            "Who's Arrested?",
            "Baby Arrived",
            "Werewolf Rage",
            "Bald Swipe",
            "BOOM DROP",
            "Huge Cutie",
            "Liquid Metal",
            "Sharksnap!",
            "Dust Me Away",
            "3D Figurine Factor",
            "Bikini Up",
            "My Girlfriends",
            "My Boyfriends",
            "Subject 3 Fever",
            "Earth Zoom",
            "Pole Dance",
            "Vroom Dance",
            "GhostFace Terror",
            "Dragon Evoker",
            "Skeletal Bae",
            "Summoning succubus",
            "Halloween Voodoo Doll",
            "3D Naked-Eye AD",
            "Package Explosion",
            "Dishes Served",
            "Ocean ad",
            "Supermarket AD"
          ],
          "description": "The effect to apply to the video",
          "type": "string",
          "title": "Effect"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/q5ahL3KS7ikt3MvpNUG8l_image%20(72).webp"
          ],
          "description": "Optional URL of the image to use as the first frame. If not provided, generates from text",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "effect",
        "image_url",
        "resolution",
        "duration",
        "negative_prompt"
      ],
      "required": [
        "effect",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/pixverse/v5/image-to-video",
    "name": "Pixverse v5 Image to Video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v5",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/panda/eTq_2p2OlIBu7MyDFdtWz_6290f4acd92c4382b04ed302b2aa5a3a.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoRequestV5",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman warrior with her hammer walking with his glacier wolf."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
          ],
          "description": "URL of the image to use as the first frame",
          "type": "string",
          "title": "Image Url"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/infinitalk",
    "name": "Infinitalk",
    "description": "Infinitalk model generates a talking avatar video from an image and audio file. The avatar lip-syncs to the provided audio with natural facial expressions.",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/tgT82rlusP7Mfw1gs8CsE_0cd1e1a621dd484b8c84973e3a1292bf.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "InfiniTalkSingleAudioRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman with colorful hair talking on a podcast."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the video to generate. Must be either 480p or 720p.",
          "default": "480p"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The acceleration level to use for generation.",
          "default": "regular"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/gmpc0QevDF9bBsL1EAYVF_1c637094161147559f0910a68275dc34.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "audio_url": {
          "examples": [
            "https://v3.fal.media/files/penguin/PtiCYda53E9Dav25QmQYI_output.mp3"
          ],
          "title": "Audio URL",
          "type": "string",
          "description": "The URL of the audio file."
        },
        "num_frames": {
          "minimum": 41,
          "maximum": 721,
          "type": "integer",
          "title": "Number of Frames",
          "description": "Number of frames to generate. Must be between 41 to 721.",
          "default": 145
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen.",
          "default": 42
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "audio_url",
        "prompt",
        "num_frames",
        "resolution",
        "seed",
        "acceleration"
      ],
      "required": [
        "image_url",
        "audio_url",
        "prompt"
      ]
    }
  },
  {
    "id": "moonvalley/marey/i2v",
    "name": "Marey Realism V1.5",
    "description": "Generate a video starting from an image as the first frame with Marey, a generative video model trained exclusively on fully licensed data.",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/ZYJf9OjFksJF5QIMxEjCh_85dff19060504c08b66d4a0675788c3a.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MareyInputI2V",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Detailed Description: In a hidden jungle grotto, a majestic waterfall plunges into a dark, serene pool below. Ethereal sunbeams slice through the dense canopy high above, illuminating the swirling mist generated by the powerful cascade. The light rays dance across the scene, highlighting the vibrant green foliage that clings to the dark, wet rock walls. The constant roar of the falling water echoes through the secluded space, as the surface of the pool ripples and churns from the impact, creating a mesmerizing display of nature's raw power and tranquil beauty. Background: Brilliant sunbeams pierce through an opening in the dense jungle canopy, their ethereal rays shifting and shimmering as they cut through the misty air. Middleground: A powerful column of white water cascades down a dark, foliage-covered cliff face, creating a stark contrast with the shadowy recesses of the grotto. Foreground: The waterfall crashes into a dark, churning pool of water, sending up a fine spray and creating ever-expanding ripples across the surface."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate a video from"
        },
        "duration": {
          "enum": [
            "5s",
            "10s"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video.",
          "default": "5s"
        },
        "image_url": {
          "examples": [
            "https://d1kaxrqq3vfrw5.cloudfront.net/fal-launch-assets/guide-assets/fal-i2v-example-input.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The URL of the image to use as the first frame of the video."
        },
        "dimensions": {
          "enum": [
            "1920x1080",
            "1080x1920",
            "1152x1152",
            "1536x1152",
            "1152x1536"
          ],
          "title": "Dimensions",
          "type": "string",
          "description": "The dimensions of the generated video in width x height format.",
          "default": "1920x1080"
        },
        "guidance_scale": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "title": "Guidance Scale",
          "description": "Controls how strongly the generation is guided by the prompt (0-20). Higher values follow the prompt more closely."
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for random number generation. Use -1 for random seed each run.",
          "default": -1
        },
        "negative_prompt": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Negative Prompt",
          "description": "Negative prompt used to guide the model away from undesirable features.",
          "default": "<synthetic> <scene cut> low-poly, flat shader, bad rigging, stiff animation, uncanny eyes, low-quality textures, looping glitch, cheap effect, overbloom, bloom spam, default lighting, game asset, stiff face, ugly specular, AI artifacts"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "dimensions",
        "duration",
        "negative_prompt",
        "seed",
        "guidance_scale",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "pricing_unit": "5 seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/bytedance/video-stylize",
    "name": "Bytedance",
    "description": "Transform your images into stylized videos using this workflow.",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/koala/LxwcxJuokX_e4sZ6EopoG_fb133832f45f4366b13faa832797092d.jpg",
    "tags": [
      "image-to-video",
      "effects"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "style",
        "image_url"
      ],
      "type": "object",
      "properties": {
        "style": {
          "examples": [
            "Manga style"
          ],
          "description": "The style for your character in the video. Please use a short description.",
          "type": "string",
          "maxLength": 100,
          "title": "Style"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/kangaroo/-KmSPIcXeGA3Z_iiH4C75_tmph2ry_0_8.png"
          ],
          "description": "URL of the image to make the stylized video from.",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "StylizeInput",
      "required": [
        "style",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/image-to-video/lora",
    "name": "Wan v2.2 A14B Image-to-Video A14B with LoRAs",
    "description": "Wan-2.2 image-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts and images. This endpoint supports LoRAs made for Wan 2.2",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/Pu175Pi1Z0phr_hCod2pk_51e51de631a54b58ba789155b6955c94.jpg",
    "tags": [
      "image-to-video",
      "motion",
      "lora"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanLoRAI2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Cars racing in slow motion"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "shift": {
          "description": "Shift value for the video. Must be between 1.0 and 10.0.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            5
          ],
          "title": "Shift",
          "default": 5
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "examples": [
            "regular"
          ],
          "default": "regular"
        },
        "num_interpolated_frames": {
          "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
          "type": "integer",
          "minimum": 0,
          "maximum": 4,
          "examples": [
            1
          ],
          "title": "Number of Interpolated Frames",
          "default": 1
        },
        "reverse_video": {
          "title": "Reverse Video",
          "type": "boolean",
          "description": "If true, the video will be reversed.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "LoRA weights to be used in the inference.",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "frames_per_second": {
          "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
          "type": "integer",
          "minimum": 4,
          "maximum": 60,
          "title": "Frames per Second",
          "examples": [
            16
          ],
          "default": 16
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "num_frames": {
          "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
          "type": "integer",
          "minimum": 17,
          "maximum": 161,
          "title": "Number of Frames",
          "examples": [
            81
          ],
          "default": 81
        },
        "end_image_url": {
          "title": "End Image URL",
          "type": "string",
          "description": "URL of the end image."
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale (1st Stage)",
          "default": 3.5
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
          "examples": [
            "balanced"
          ],
          "default": "balanced"
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p, 580p, or 720p).",
          "examples": [
            "720p"
          ],
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/gallery/car_720p.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
          "examples": [
            "high"
          ],
          "default": "high"
        },
        "guidance_scale_2": {
          "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            4
          ],
          "title": "Guidance Scale (2nd Stage)",
          "default": 4
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "interpolator_model": {
          "enum": [
            "none",
            "film",
            "rife"
          ],
          "title": "Interpolator Model",
          "type": "string",
          "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
          "examples": [
            "film"
          ],
          "default": "film"
        },
        "adjust_fps_for_interpolation": {
          "examples": [
            true
          ],
          "title": "Adjust FPS for Interpolation",
          "type": "boolean",
          "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
          "default": true
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 40,
          "examples": [
            27
          ],
          "title": "Number of Inference Steps",
          "default": 27
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "num_frames",
        "frames_per_second",
        "negative_prompt",
        "seed",
        "resolution",
        "aspect_ratio",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "guidance_scale",
        "guidance_scale_2",
        "shift",
        "interpolator_model",
        "num_interpolated_frames",
        "adjust_fps_for_interpolation",
        "video_quality",
        "video_write_mode",
        "loras",
        "reverse_video",
        "end_image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/minimax/hailuo-02-fast/image-to-video",
    "name": "Minimax",
    "description": "Create blazing fast and economical videos with MiniMax Hailuo-02 Image To Video API at 512p resolution",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/f_EeVaEkzmhhcRXL1Xruj_8fd7a6cbb43b460b8a6ff550a153f4af.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastImageToVideoHailuo02Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "duration": {
          "enum": [
            "6",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.",
          "default": "6"
        },
        "prompt": {
          "examples": [
            "Extremely realistic movement An old samurai is breaking a stone in half"
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/tiger/U9HN_tm5-3Ls52SbD6CrW_image.webp"
          ],
          "title": "Image Url",
          "type": "string"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "prompt_optimizer"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 2,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/veo3/image-to-video",
    "name": "Veo3",
    "description": "Veo 3 is the latest state-of-the art video generation model from Google DeepMind",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-5.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "aspect_ratio",
        "duration",
        "generate_audio",
        "resolution"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman looks into the camera, breathes in, then exclaims energetically, \"have you guys checked out Veo3 Image-to-Video on Fal? It's incredible!\""
          ],
          "description": "The text prompt describing how the image should be animated",
          "type": "string",
          "title": "Prompt"
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "Resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "9:16",
            "16:9",
            "1:1"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 50% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "duration": {
          "enum": [
            "4s",
            "6s",
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/veo3-i2v-input.png"
          ],
          "description": "URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.",
          "type": "string",
          "title": "Image URL"
        }
      },
      "title": "ImageToVideoPreviewInput",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 40,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/image-to-video/turbo",
    "name": "Wan",
    "description": "Wan-2.2 Turbo image-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. ",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-1.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanTurboI2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p, 580p, or 720p).",
          "examples": [
            "720p"
          ],
          "default": "720p"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "examples": [
            "regular"
          ],
          "default": "regular"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
          "examples": [
            "balanced"
          ],
          "default": "balanced"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/wan/dragon-warrior.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
          "examples": [
            "high"
          ],
          "default": "high"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "end_image_url": {
          "title": "End Image URL",
          "type": "string",
          "description": "URL of the end image."
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "seed",
        "resolution",
        "aspect_ratio",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "video_quality",
        "video_write_mode",
        "end_image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 2,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/wan/v2.2-5b/image-to-video",
    "name": "Wan v2.2 5B",
    "description": "Wan 2.2's 5B model produces up to 5 seconds of video 720p at 24FPS with fluid motion and powerful prompt understanding",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanSmallI2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "shift": {
          "description": "Shift value for the video. Must be between 1.0 and 10.0.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            5
          ],
          "title": "Shift",
          "default": 5
        },
        "num_interpolated_frames": {
          "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
          "type": "integer",
          "minimum": 0,
          "maximum": 4,
          "examples": [
            0
          ],
          "title": "Number of Interpolated Frames",
          "default": 0
        },
        "frames_per_second": {
          "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
          "type": "integer",
          "minimum": 4,
          "maximum": 60,
          "title": "Frames per Second",
          "examples": [
            24
          ],
          "default": 24
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale",
          "default": 3.5
        },
        "num_frames": {
          "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
          "type": "integer",
          "minimum": 17,
          "maximum": 161,
          "title": "Number of Frames",
          "examples": [
            81
          ],
          "default": 81
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
          "examples": [
            "balanced"
          ],
          "default": "balanced"
        },
        "resolution": {
          "enum": [
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (580p or 720p).",
          "examples": [
            "720p"
          ],
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/wan/dragon-warrior.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
          "examples": [
            "high"
          ],
          "default": "high"
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "interpolator_model": {
          "enum": [
            "none",
            "film",
            "rife"
          ],
          "title": "Interpolator Model",
          "type": "string",
          "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
          "examples": [
            "film"
          ],
          "default": "film"
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 50,
          "examples": [
            40
          ],
          "title": "Number of Inference Steps",
          "default": 40
        },
        "adjust_fps_for_interpolation": {
          "examples": [
            true
          ],
          "title": "Adjust FPS for Interpolation",
          "type": "boolean",
          "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "num_frames",
        "frames_per_second",
        "negative_prompt",
        "seed",
        "resolution",
        "aspect_ratio",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "guidance_scale",
        "shift",
        "interpolator_model",
        "num_interpolated_frames",
        "adjust_fps_for_interpolation",
        "video_quality",
        "video_write_mode"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 3,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/image-to-video",
    "name": "Wan v2.2 A14B",
    "description": "fal-ai/wan/v2.2-A14B/image-to-video",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/penguin/xWl1TIQn-uRe7BsctByJk_3e01d1a4f7ff488c9483be0d81f5a3cc.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanI2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "shift": {
          "description": "Shift value for the video. Must be between 1.0 and 10.0.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            5
          ],
          "title": "Shift",
          "default": 5
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "examples": [
            "regular"
          ],
          "default": "regular"
        },
        "num_interpolated_frames": {
          "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
          "type": "integer",
          "minimum": 0,
          "maximum": 4,
          "examples": [
            1
          ],
          "title": "Number of Interpolated Frames",
          "default": 1
        },
        "frames_per_second": {
          "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
          "type": "integer",
          "minimum": 4,
          "maximum": 60,
          "title": "Frames per Second",
          "examples": [
            16
          ],
          "default": 16
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "num_frames": {
          "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
          "type": "integer",
          "minimum": 17,
          "maximum": 161,
          "title": "Number of Frames",
          "examples": [
            81
          ],
          "default": 81
        },
        "end_image_url": {
          "title": "End Image URL",
          "type": "string",
          "description": "URL of the end image."
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale (1st Stage)",
          "default": 3.5
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
          "examples": [
            "balanced"
          ],
          "default": "balanced"
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p, 580p, or 720p).",
          "examples": [
            "720p"
          ],
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/wan/dragon-warrior.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
          "examples": [
            "high"
          ],
          "default": "high"
        },
        "guidance_scale_2": {
          "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale (2nd Stage)",
          "default": 3.5
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "interpolator_model": {
          "enum": [
            "none",
            "film",
            "rife"
          ],
          "title": "Interpolator Model",
          "type": "string",
          "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
          "examples": [
            "film"
          ],
          "default": "film"
        },
        "adjust_fps_for_interpolation": {
          "examples": [
            true
          ],
          "title": "Adjust FPS for Interpolation",
          "type": "boolean",
          "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
          "default": true
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 40,
          "examples": [
            27
          ],
          "title": "Number of Inference Steps",
          "default": 27
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "num_frames",
        "frames_per_second",
        "negative_prompt",
        "seed",
        "resolution",
        "aspect_ratio",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "guidance_scale",
        "guidance_scale_2",
        "shift",
        "interpolator_model",
        "num_interpolated_frames",
        "adjust_fps_for_interpolation",
        "video_quality",
        "video_write_mode",
        "end_image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 8,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/bytedance/omnihuman",
    "name": "OmniHuman",
    "description": "OmniHuman generates video using an image of a human figure paired with an audio file. It produces vivid, high-quality videos where the character\u2019s emotions and movements maintain a strong correlation with the audio.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "tags": [
      "image-to-video",
      "lipsync"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "audio_url"
      ],
      "type": "object",
      "properties": {
        "audio_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/omnihuman_audio.mp3"
          ],
          "description": "The URL of the audio file to generate the video. Audio must be under 30s long.",
          "type": "string",
          "title": "Audio Url"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/omnihuman.png"
          ],
          "description": "The URL of the image used to generate the video",
          "type": "string",
          "title": "Image Url"
        }
      },
      "title": "OmniHumanInput",
      "required": [
        "image_url",
        "audio_url"
      ]
    }
  },
  {
    "id": "fal-ai/ltxv-13b-098-distilled/image-to-video",
    "name": "LTX-Video 13B 0.9.8 Distilled",
    "description": "Generate long videos from prompts and images using LTX Video-0.9.8 13B Distilled and custom LoRA",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-5.jpg",
    "tags": [
      "video",
      "ltx-video",
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Distilled model input",
      "type": "object",
      "properties": {
        "second_pass_skip_initial_steps": {
          "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
          "type": "integer",
          "minimum": 1,
          "maximum": 11,
          "title": "Second Pass Skip Initial Steps",
          "examples": [
            5
          ],
          "default": 5
        },
        "first_pass_num_inference_steps": {
          "description": "Number of inference steps during the first pass.",
          "type": "integer",
          "minimum": 2,
          "maximum": 12,
          "title": "Number of Inference Steps",
          "examples": [
            8
          ],
          "default": 8
        },
        "frame_rate": {
          "description": "The frame rate of the video.",
          "type": "integer",
          "minimum": 1,
          "maximum": 60,
          "title": "Frame Rate",
          "examples": [
            24
          ],
          "default": 24
        },
        "reverse_video": {
          "examples": [
            false
          ],
          "title": "Reverse Video",
          "type": "boolean",
          "description": "Whether to reverse the video.",
          "default": false
        },
        "prompt": {
          "examples": [
            "The astronaut gets up and walks away"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide generation"
        },
        "expand_prompt": {
          "examples": [
            false
          ],
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using a language model.",
          "default": false
        },
        "temporal_adain_factor": {
          "description": "The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.",
          "type": "number",
          "examples": [
            0.5
          ],
          "maximum": 1,
          "title": "Temporal AdaIN Factor",
          "minimum": 0,
          "multipleOf": 0.05,
          "default": 0.5
        },
        "loras": {
          "description": "LoRA weights to use for generation",
          "type": "array",
          "title": "Loras",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "num_frames": {
          "description": "The number of frames in the video.",
          "type": "integer",
          "minimum": 9,
          "maximum": 1441,
          "title": "Number of Frames",
          "examples": [
            121
          ],
          "default": 121
        },
        "second_pass_num_inference_steps": {
          "description": "Number of inference steps during the second pass.",
          "type": "integer",
          "minimum": 2,
          "maximum": 12,
          "title": "Second Pass Number of Inference Steps",
          "examples": [
            8
          ],
          "default": 8
        },
        "negative_prompt": {
          "description": "Negative prompt for generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
        },
        "enable_detail_pass": {
          "examples": [
            false
          ],
          "title": "Enable Detail Pass",
          "type": "boolean",
          "description": "Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.",
          "default": false
        },
        "resolution": {
          "examples": [
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video.",
          "enum": [
            "480p",
            "720p"
          ],
          "default": "720p"
        },
        "aspect_ratio": {
          "examples": [
            "auto"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the video.",
          "enum": [
            "9:16",
            "1:1",
            "16:9",
            "auto"
          ],
          "default": "auto"
        },
        "tone_map_compression_ratio": {
          "description": "The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.",
          "type": "number",
          "examples": [
            0
          ],
          "maximum": 1,
          "title": "Tone Map Compression Ratio",
          "minimum": 0,
          "multipleOf": 0.05,
          "default": 0
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/ltxv-image-input.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "Image URL for Image-to-Video task"
        },
        "constant_rate_factor": {
          "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
          "type": "integer",
          "minimum": 0,
          "maximum": 51,
          "title": "Constant Rate Factor",
          "examples": [
            29
          ],
          "default": 29
        },
        "seed": {
          "description": "Random seed for generation",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "DistilledImageToVideoInput",
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "loras",
        "resolution",
        "aspect_ratio",
        "seed",
        "num_frames",
        "first_pass_num_inference_steps",
        "second_pass_num_inference_steps",
        "second_pass_skip_initial_steps",
        "frame_rate",
        "expand_prompt",
        "reverse_video",
        "enable_safety_checker",
        "enable_detail_pass",
        "temporal_adain_factor",
        "tone_map_compression_ratio",
        "constant_rate_factor",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 2,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/veo3/fast/image-to-video",
    "name": "Veo 3 Fast [Image to Video]",
    "description": "Now with a 50% price drop. Generate videos from your image prompts using Veo 3 fast.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "aspect_ratio",
        "duration",
        "generate_audio",
        "resolution"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman looks into the camera, breathes in, then exclaims energetically, \"have you guys checked out Veo3 Image-to-Video on Fal? It's incredible!\""
          ],
          "description": "The text prompt describing how the image should be animated",
          "type": "string",
          "title": "Prompt"
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "Resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "9:16",
            "16:9",
            "1:1"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 33% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "duration": {
          "enum": [
            "4s",
            "6s",
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/veo3-i2v-input.png"
          ],
          "description": "URL of the input image to animate. Should be 720p or higher resolution in 16:9 or 9:16 aspect ratio. If the image is not in 16:9 or 9:16 aspect ratio, it will be cropped to fit.",
          "type": "string",
          "title": "Image URL"
        }
      },
      "title": "ImageToVideoPreviewFastInput",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 15,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/vidu/q1/reference-to-video",
    "name": "Vidu",
    "description": "Generate video clips from your multiple image references using Vidu Q1",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Q1ReferenceToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A young woman and a monkey inside a colorful house"
          ],
          "maxLength": 1500,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 1500 characters"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the output video",
          "default": "16:9"
        },
        "bgm": {
          "title": "Bgm",
          "type": "boolean",
          "description": "Whether to add background music to the generated video",
          "default": false
        },
        "reference_image_urls": {
          "examples": [
            [
              "https://v3.fal.media/files/panda/HDpZj0eLjWwCpjA5__0l1_0e6cd0b9eb7a4a968c0019a4eee15e46.png",
              "https://v3.fal.media/files/zebra/153izt1cBlMU-TwD0_B7Q_ea34618f5d974653a16a755aa61e488a.png",
              "https://v3.fal.media/files/koala/RCSZ7VEEKGFDfMoGHCwzo_f626718793e94769b1ad36d5891864a4.png"
            ]
          ],
          "title": "Reference Image Urls",
          "type": "array",
          "description": "URLs of the reference images to use for consistent subject appearance. Q1 model supports up to 7 reference images.",
          "items": {
            "type": "string"
          }
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "reference_image_urls",
        "seed",
        "aspect_ratio",
        "movement_amplitude",
        "bgm"
      ],
      "required": [
        "prompt",
        "reference_image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/ai-avatar/single-text",
    "name": "Ai Avatar",
    "description": "MultiTalk model generates a talking avatar video from an image and text. Converts text to speech automatically, then generates the avatar speaking with lip-sync.",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/penguin/ETFEnZEbEj9nc6e1XdFG8_6f87551d505640c89d59f8018dd0ffb0.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AvatarSingleTextRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "An elderly man with a white beard and headphones records audio with a microphone. He appears engaged and expressive, suggesting a podcast or voiceover."
          ],
          "description": "The text prompt to guide video generation.",
          "type": "string",
          "title": "Prompt"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "description": "Resolution of the video to generate. Must be either 480p or 720p.",
          "type": "string",
          "title": "Resolution",
          "default": "480p"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "description": "The acceleration level to use for generation.",
          "type": "string",
          "title": "Acceleration",
          "default": "regular"
        },
        "text_input": {
          "examples": [
            "Spend more time with people who make you feel alive, and less with things that drain your soul."
          ],
          "description": "The text input to guide video generation.",
          "type": "string",
          "title": "Text Input"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/panda/HuM21CXMf0q7OO2zbvwhV_c4533aada79a495b90e50e32dc9b83a8.png"
          ],
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
          "type": "string",
          "title": "Image URL"
        },
        "voice": {
          "examples": [
            "Bill"
          ],
          "description": "The voice to use for speech generation",
          "type": "string",
          "enum": [
            "Aria",
            "Roger",
            "Sarah",
            "Laura",
            "Charlie",
            "George",
            "Callum",
            "River",
            "Liam",
            "Charlotte",
            "Alice",
            "Matilda",
            "Will",
            "Jessica",
            "Eric",
            "Chris",
            "Brian",
            "Daniel",
            "Lily",
            "Bill"
          ],
          "title": "Voice"
        },
        "seed": {
          "description": "Random seed for reproducibility. If None, a random seed is chosen.",
          "type": "integer",
          "title": "Seed",
          "default": 42
        },
        "num_frames": {
          "minimum": 41,
          "maximum": 241,
          "type": "integer",
          "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
          "title": "Number of Frames",
          "default": 136
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "text_input",
        "voice",
        "prompt",
        "num_frames",
        "resolution",
        "seed",
        "acceleration"
      ],
      "required": [
        "image_url",
        "text_input",
        "voice",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/ai-avatar",
    "name": "Ai Avatar",
    "description": "MultiTalk model generates a talking avatar video from an image and audio file. The avatar lip-syncs to the provided audio with natural facial expressions.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AvatarSingleAudioRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman with colorful hair talking on a podcast."
          ],
          "description": "The text prompt to guide video generation.",
          "type": "string",
          "title": "Prompt"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "description": "Resolution of the video to generate. Must be either 480p or 720p.",
          "type": "string",
          "title": "Resolution",
          "default": "480p"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "description": "The acceleration level to use for generation.",
          "type": "string",
          "title": "Acceleration",
          "default": "regular"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/gmpc0QevDF9bBsL1EAYVF_1c637094161147559f0910a68275dc34.png"
          ],
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
          "type": "string",
          "title": "Image URL"
        },
        "audio_url": {
          "examples": [
            "https://v3.fal.media/files/penguin/PtiCYda53E9Dav25QmQYI_output.mp3"
          ],
          "description": "The URL of the audio file.",
          "type": "string",
          "title": "Audio URL"
        },
        "num_frames": {
          "minimum": 41,
          "maximum": 241,
          "type": "integer",
          "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
          "title": "Number of Frames",
          "default": 145
        },
        "seed": {
          "description": "Random seed for reproducibility. If None, a random seed is chosen.",
          "type": "integer",
          "title": "Seed",
          "default": 42
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "audio_url",
        "prompt",
        "num_frames",
        "resolution",
        "seed",
        "acceleration"
      ],
      "required": [
        "image_url",
        "audio_url",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/ai-avatar/multi-text",
    "name": "Ai Avatar",
    "description": "MultiTalk model generates a multi-person conversation video from an image and text inputs. Converts text to speech for each person, generating a realistic conversation scene.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AvatarMultiTextRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Two kids talking on a lunch."
          ],
          "description": "The text prompt to guide video generation.",
          "type": "string",
          "title": "Prompt"
        },
        "second_text_input": {
          "examples": [
            "I dont know I am eating this because our mother gave it to us. I think it is something called milky pie."
          ],
          "description": "The text input to guide video generation.",
          "type": "string",
          "title": "Second Text Input"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "description": "The acceleration level to use for generation.",
          "type": "string",
          "title": "Acceleration",
          "default": "regular"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "description": "Resolution of the video to generate. Must be either 480p or 720p.",
          "type": "string",
          "title": "Resolution",
          "default": "480p"
        },
        "first_text_input": {
          "examples": [
            "Do you know what are we eating?"
          ],
          "description": "The text input to guide video generation.",
          "type": "string",
          "title": "First Text Input"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/vhkIF86hmgNTBll_lF1xI_3c7476642b19435aa763fe3b49cf99c7.png"
          ],
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
          "type": "string",
          "title": "Image URL"
        },
        "voice2": {
          "enum": [
            "Aria",
            "Roger",
            "Sarah",
            "Laura",
            "Charlie",
            "George",
            "Callum",
            "River",
            "Liam",
            "Charlotte",
            "Alice",
            "Matilda",
            "Will",
            "Jessica",
            "Eric",
            "Chris",
            "Brian",
            "Daniel",
            "Lily",
            "Bill"
          ],
          "description": "The second person's voice to use for speech generation",
          "type": "string",
          "title": "Voice2",
          "default": "Roger"
        },
        "voice1": {
          "enum": [
            "Aria",
            "Roger",
            "Sarah",
            "Laura",
            "Charlie",
            "George",
            "Callum",
            "River",
            "Liam",
            "Charlotte",
            "Alice",
            "Matilda",
            "Will",
            "Jessica",
            "Eric",
            "Chris",
            "Brian",
            "Daniel",
            "Lily",
            "Bill"
          ],
          "description": "The first person's voice to use for speech generation",
          "type": "string",
          "title": "Voice1",
          "default": "Sarah"
        },
        "seed": {
          "description": "Random seed for reproducibility. If None, a random seed is chosen.",
          "type": "integer",
          "title": "Seed",
          "default": 81
        },
        "num_frames": {
          "minimum": 41,
          "maximum": 241,
          "type": "integer",
          "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
          "title": "Number of Frames",
          "default": 191
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "first_text_input",
        "second_text_input",
        "voice1",
        "voice2",
        "prompt",
        "num_frames",
        "resolution",
        "seed",
        "acceleration"
      ],
      "required": [
        "image_url",
        "first_text_input",
        "second_text_input",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/ai-avatar/multi",
    "name": "Ai Avatar",
    "description": "MultiTalk model generates a multi-person conversation video from an image and audio files. Creates a realistic scene where multiple people speak in sequence.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AvatarMultiAudioPersonRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A smiling man and woman wearing headphones sit in front of microphones, appearing to host a podcast. They are engaged in conversation, looking at each other and the camera as they speak. The scene captures a lively and collaborative podcasting session."
          ],
          "description": "The text prompt to guide video generation.",
          "type": "string",
          "title": "Prompt"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "description": "Resolution of the video to generate. Must be either 480p or 720p.",
          "type": "string",
          "title": "Resolution",
          "default": "480p"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "description": "The acceleration level to use for generation.",
          "type": "string",
          "title": "Acceleration",
          "default": "regular"
        },
        "first_audio_url": {
          "examples": [
            "https://v3.fal.media/files/monkey/1XKPx3Xu-IhNLbuinVSwP_output.mp3"
          ],
          "description": "The URL of the Person 1 audio file.",
          "type": "string",
          "title": "First Audio URL"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/elephant/Q2ZU6q-d-1boGXhpDgWs9_15a22f816fd34cad969b2329946267b3.png"
          ],
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped.",
          "type": "string",
          "title": "Image URL"
        },
        "second_audio_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/oVKyL8JZ1K2GreeIMxVzm_output.mp3"
          ],
          "description": "The URL of the Person 2 audio file.",
          "type": "string",
          "title": "Second Audio URL"
        },
        "seed": {
          "description": "Random seed for reproducibility. If None, a random seed is chosen.",
          "type": "integer",
          "title": "Seed",
          "default": 81
        },
        "use_only_first_audio": {
          "description": "Whether to use only the first audio file.",
          "type": "boolean",
          "title": "Use Only First Audio",
          "default": false
        },
        "num_frames": {
          "minimum": 41,
          "maximum": 241,
          "type": "integer",
          "description": "Number of frames to generate. Must be between 81 to 129 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
          "title": "Number of Frames",
          "default": 181
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "first_audio_url",
        "second_audio_url",
        "prompt",
        "num_frames",
        "resolution",
        "seed",
        "use_only_first_audio",
        "acceleration"
      ],
      "required": [
        "image_url",
        "first_audio_url",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-02/pro/image-to-video",
    "name": "MiniMax Hailuo 02 [Pro] (Image to Video)",
    "description": "MiniMax Hailuo-02 Image To Video API (Pro, 1080p): Advanced image-to-video generation model with 1080p resolution",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ProImageToVideoHailuo02Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "Man walked into winter cave with polar bear"
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000
        },
        "end_image_url": {
          "title": "End Image Url",
          "type": "string",
          "description": "Optional URL of the image to use as the last frame of the video"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/minimax/1749891352437225630-389852416840474630_1749891352.png"
          ],
          "title": "Image Url",
          "type": "string"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "prompt_optimizer",
        "end_image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 8,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/lite/image-to-video",
    "name": "Seedance 1.0 Lite",
    "description": "Seedance 1.0 Lite",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "camera_fixed",
        "seed",
        "enable_safety_checker",
        "image_url",
        "end_image_url"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A little dog is running in the sunshine. The camera follows the dog as it plays in a garden."
          ],
          "description": "The text prompt used to generate the video",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16",
            "auto"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "auto"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p",
            "1080p"
          ],
          "description": "Video resolution - 480p for faster generation, 720p for higher quality",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "duration": {
          "enum": [
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
          ],
          "description": "Duration of the video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/koala/f_xmiodPjhiKjdBkFmTu1.png"
          ],
          "description": "The URL of the image used to generate video",
          "type": "string",
          "title": "Image Url"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "camera_fixed": {
          "description": "Whether to fix the camera position",
          "type": "boolean",
          "title": "Camera Fixed",
          "default": false
        },
        "end_image_url": {
          "description": "The URL of the image the video ends with. Defaults to None.",
          "type": "string",
          "title": "End Image Url"
        },
        "seed": {
          "description": "Random seed to control video generation. Use -1 for random.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "SeedanceImageToVideoInput",
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/hunyuan-avatar",
    "name": "Hunyuan Avatar",
    "description": "HunyuanAvatar is a High-Fidelity Audio-Driven Human Animation model for Multiple Characters .",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-3.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "audio_url",
        "image_url",
        "text",
        "num_frames",
        "num_inference_steps",
        "turbo_mode",
        "seed"
      ],
      "type": "object",
      "properties": {
        "text": {
          "title": "Text",
          "type": "string",
          "description": "Text prompt describing the scene.",
          "default": "A cat is singing."
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/tiger/Y8EgvVqxORBCqWC1OlX3D_3c4c8bbe7f3941a2aea93e278ba14803.jpg",
            "https://v3.fal.media/files/zebra/HWILyw2UYI50Sp_4mDxqr_src2.png"
          ],
          "description": "The URL of the reference image.",
          "type": "string",
          "title": "Image Url"
        },
        "turbo_mode": {
          "title": "Turbo Mode",
          "type": "boolean",
          "description": "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
          "default": true
        },
        "audio_url": {
          "examples": [
            "https://v3.fal.media/files/koala/80RpP2FOhXZUV3NRKUWZu_2.WAV"
          ],
          "description": "The URL of the audio file.",
          "type": "string",
          "title": "Audio Url"
        },
        "seed": {
          "description": "Random seed for generation.",
          "type": "integer",
          "title": "Seed"
        },
        "num_inference_steps": {
          "minimum": 30,
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "title": "Num Inference Steps",
          "maximum": 50,
          "default": 30
        },
        "num_frames": {
          "minimum": 129,
          "maximum": 401,
          "type": "integer",
          "title": "Num Frames",
          "description": "Number of video frames to generate at 25 FPS. If greater than the input audio length, it will capped to the length of the input audio.",
          "default": 129
        }
      },
      "title": "Input",
      "required": [
        "audio_url",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v2.1/pro/image-to-video",
    "name": "Kling 2.1 (pro)",
    "description": "Kling 2.1 Pro is an advanced endpoint for the Kling 2.1 model, offering professional-grade videos with enhanced visual fidelity, precise camera movements, and dynamic motion control, perfect for cinematic storytelling.\n\n",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoV21ProRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Warm, incandescent streetlights paint the rain-slicked cobblestones in pools of amber light as a couple walks hand-in-hand, their silhouettes stark against the blurry backdrop of a city shrouded in a gentle downpour; the camera lingers on the subtle textures of their rain-soaked coats and the glistening reflections dancing on the wet pavement, creating a sense of intimate vulnerability and shared quietude."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "tail_image_url": {
          "description": "URL of the image to be used for the end of the video",
          "type": "string",
          "title": "Tail Image Url"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/lion/_I_io6Gtk83c72d-afXf8_image.webp"
          ],
          "description": "URL of the image to be used for the video",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "negative_prompt",
        "cfg_scale",
        "tail_image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 9,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/hunyuan-portrait",
    "name": "Hunyuan Portrait",
    "description": "HunyuanPortrait is a diffusion-based framework for generating lifelike, temporally consistent portrait animations.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-4.jpeg",
    "tags": [
      "animation",
      "lip sync"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Input",
      "type": "object",
      "properties": {
        "video_url": {
          "examples": [
            "https://v3.fal.media/files/panda/2GQH1q-bJOamqCGWMtKvS_what_if.mp4"
          ],
          "title": "Video Url",
          "type": "string",
          "description": "The URL of the driving video."
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation. If None, a random seed will be used."
        },
        "use_arcface": {
          "title": "Use Arcface",
          "type": "boolean",
          "description": "Whether to use ArcFace for face recognition.",
          "default": true
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/elephant/GG7iU-4GmzkX3_gIXutRV_image.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The URL of the source image."
        }
      },
      "x-fal-order-properties": [
        "video_url",
        "image_url",
        "seed",
        "use_arcface"
      ],
      "required": [
        "video_url",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/standard/elements",
    "name": "Kling 1.6 Elements",
    "description": "Generate video clips from your multiple image references using Kling 1.6 (standard)",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/kling-1-6-image-to-video.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MultiImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cute girl and a baby cow sleeping together on a bed"
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "input_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/web-examples/kling-elements/first_image.jpeg",
              "https://storage.googleapis.com/falserverless/web-examples/kling-elements/second_image.png"
            ]
          ],
          "description": "List of image URLs to use for video generation. Supports up to 4 images.",
          "type": "array",
          "title": "Input Image Urls",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "input_image_urls",
        "duration",
        "aspect_ratio",
        "negative_prompt"
      ],
      "required": [
        "prompt",
        "input_image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/pro/elements",
    "name": "Kling 1.6 Elements",
    "description": "Generate video clips from your multiple image references using Kling 1.6 (pro)",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/kling-1-6-image-to-video.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MultiImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cute girl and a baby cow sleeping together on a bed"
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "input_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/web-examples/kling-elements/first_image.jpeg",
              "https://storage.googleapis.com/falserverless/web-examples/kling-elements/second_image.png"
            ]
          ],
          "description": "List of image URLs to use for video generation. Supports up to 4 images.",
          "type": "array",
          "title": "Input Image Urls",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "input_image_urls",
        "duration",
        "aspect_ratio",
        "negative_prompt"
      ],
      "required": [
        "prompt",
        "input_image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/ltx-video-13b-distilled/image-to-video",
    "name": "LTX Video-0.9.7 13B Distilled",
    "description": "Generate videos from prompts and images using LTX Video-0.9.7 13B Distilled and custom LoRA",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/rabbit/N3sm2TCARXV47JxgfxZJt_8caf31dada5249d996b99fea8028fef8.jpg",
    "tags": [
      "video",
      "ltx-video",
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "DistilledImageToVideoInput",
      "type": "object",
      "properties": {
        "second_pass_skip_initial_steps": {
          "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
          "type": "integer",
          "minimum": 1,
          "title": "Second Pass Skip Initial Steps",
          "examples": [
            5
          ],
          "maximum": 20,
          "default": 5
        },
        "first_pass_num_inference_steps": {
          "description": "Number of inference steps during the first pass.",
          "type": "integer",
          "minimum": 2,
          "title": "First Pass Num Inference Steps",
          "examples": [
            8
          ],
          "maximum": 20,
          "default": 8
        },
        "frame_rate": {
          "description": "The frame rate of the video.",
          "type": "integer",
          "minimum": 1,
          "title": "Frame Rate",
          "examples": [
            30
          ],
          "maximum": 60,
          "default": 30
        },
        "reverse_video": {
          "examples": [
            false
          ],
          "title": "Reverse Video",
          "type": "boolean",
          "description": "Whether to reverse the video.",
          "default": false
        },
        "prompt": {
          "examples": [
            "The astronaut gets up and walks away"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide generation"
        },
        "expand_prompt": {
          "examples": [
            false
          ],
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using a language model.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "LoRA weights to use for generation",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "num_frames": {
          "description": "The number of frames in the video.",
          "type": "integer",
          "minimum": 9,
          "title": "Num Frames",
          "examples": [
            121
          ],
          "maximum": 161,
          "default": 121
        },
        "second_pass_num_inference_steps": {
          "description": "Number of inference steps during the second pass.",
          "type": "integer",
          "minimum": 2,
          "title": "Second Pass Num Inference Steps",
          "examples": [
            8
          ],
          "maximum": 20,
          "default": 8
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for generation",
          "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "examples": [
            "720p"
          ],
          "description": "Resolution of the generated video (480p or 720p).",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "1:1",
            "16:9",
            "auto"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "examples": [
            "auto"
          ],
          "description": "The aspect ratio of the video.",
          "default": "auto"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/ltxv-image-input.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "Image URL for Image-to-Video task"
        },
        "constant_rate_factor": {
          "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
          "type": "integer",
          "minimum": 20,
          "title": "Constant Rate Factor",
          "examples": [
            35
          ],
          "maximum": 60,
          "default": 35
        },
        "first_pass_skip_final_steps": {
          "minimum": 0,
          "title": "First Pass Skip Final Steps",
          "type": "integer",
          "maximum": 20,
          "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
          "default": 1
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "loras",
        "resolution",
        "aspect_ratio",
        "seed",
        "num_frames",
        "first_pass_num_inference_steps",
        "first_pass_skip_final_steps",
        "second_pass_num_inference_steps",
        "second_pass_skip_initial_steps",
        "frame_rate",
        "expand_prompt",
        "reverse_video",
        "enable_safety_checker",
        "constant_rate_factor",
        "image_url"
      ],
      "description": "Distilled model input",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/ltx-video-13b-dev/image-to-video",
    "name": "LTX Video-0.9.7 13B",
    "description": "Generate videos from prompts and images using LTX Video-0.9.7 13B and custom LoRA",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-5.jpg",
    "tags": [
      "video",
      "ltx-video",
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "loras",
        "resolution",
        "aspect_ratio",
        "seed",
        "num_frames",
        "first_pass_num_inference_steps",
        "first_pass_skip_final_steps",
        "second_pass_num_inference_steps",
        "second_pass_skip_initial_steps",
        "frame_rate",
        "expand_prompt",
        "reverse_video",
        "enable_safety_checker",
        "image_url",
        "constant_rate_factor"
      ],
      "type": "object",
      "properties": {
        "second_pass_skip_initial_steps": {
          "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
          "type": "integer",
          "minimum": 1,
          "maximum": 50,
          "title": "Second Pass Skip Initial Steps",
          "examples": [
            17
          ],
          "default": 17
        },
        "first_pass_num_inference_steps": {
          "description": "Number of inference steps during the first pass.",
          "type": "integer",
          "minimum": 2,
          "maximum": 50,
          "title": "First Pass Num Inference Steps",
          "examples": [
            30
          ],
          "default": 30
        },
        "frame_rate": {
          "description": "The frame rate of the video.",
          "type": "integer",
          "minimum": 1,
          "maximum": 60,
          "title": "Frame Rate",
          "examples": [
            30
          ],
          "default": 30
        },
        "prompt": {
          "examples": [
            "The astronaut gets up and walks away"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide generation"
        },
        "reverse_video": {
          "examples": [
            false
          ],
          "title": "Reverse Video",
          "type": "boolean",
          "description": "Whether to reverse the video.",
          "default": false
        },
        "expand_prompt": {
          "examples": [
            false
          ],
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using a language model.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "LoRA weights to use for generation",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "second_pass_num_inference_steps": {
          "description": "Number of inference steps during the second pass.",
          "type": "integer",
          "minimum": 2,
          "maximum": 50,
          "title": "Second Pass Num Inference Steps",
          "examples": [
            30
          ],
          "default": 30
        },
        "num_frames": {
          "description": "The number of frames in the video.",
          "type": "integer",
          "minimum": 9,
          "maximum": 161,
          "title": "Num Frames",
          "examples": [
            121
          ],
          "default": 121
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for generation",
          "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "examples": [
            "720p"
          ],
          "description": "Resolution of the generated video (480p or 720p).",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "1:1",
            "16:9",
            "auto"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "examples": [
            "auto"
          ],
          "description": "The aspect ratio of the video.",
          "default": "auto"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/ltxv-image-input.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "Image URL for Image-to-Video task"
        },
        "constant_rate_factor": {
          "description": "The constant rate factor (CRF) to compress input media with. Compressed input media more closely matches the model's training data, which can improve motion quality.",
          "type": "integer",
          "minimum": 20,
          "maximum": 60,
          "title": "Constant Rate Factor",
          "examples": [
            35
          ],
          "default": 35
        },
        "first_pass_skip_final_steps": {
          "minimum": 0,
          "maximum": 50,
          "type": "integer",
          "title": "First Pass Skip Final Steps",
          "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
          "default": 3
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        }
      },
      "title": "ImageToVideoInput",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 4,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/ltx-video-lora/image-to-video",
    "name": "LTX Video-0.9.7 LoRA",
    "description": "Generate videos from prompts and images using LTX Video-0.9.7 and custom LoRA",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-5.jpg",
    "tags": [
      "video",
      "ltx-video",
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoInput",
      "type": "object",
      "properties": {
        "number_of_steps": {
          "description": "The number of inference steps to use.",
          "type": "integer",
          "minimum": 1,
          "title": "Number Of Steps",
          "examples": [
            30
          ],
          "maximum": 50,
          "default": 30
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "examples": [
            "720p"
          ],
          "description": "The resolution of the video.",
          "default": "720p"
        },
        "reverse_video": {
          "examples": [
            false
          ],
          "title": "Reverse Video",
          "type": "boolean",
          "description": "Whether to reverse the video.",
          "default": false
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "1:1",
            "9:16",
            "auto"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "examples": [
            "auto"
          ],
          "description": "The aspect ratio of the video.",
          "default": "auto"
        },
        "frame_rate": {
          "description": "The frame rate of the video.",
          "type": "integer",
          "minimum": 1,
          "title": "Frame Rate",
          "examples": [
            25
          ],
          "maximum": 60,
          "default": 25
        },
        "expand_prompt": {
          "examples": [
            false
          ],
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using the LLM.",
          "default": false
        },
        "number_of_frames": {
          "description": "The number of frames in the video.",
          "type": "integer",
          "minimum": 9,
          "title": "Number Of Frames",
          "examples": [
            89
          ],
          "maximum": 161,
          "default": 89
        },
        "image_url": {
          "examples": [
            "https://h2.inkwai.com/bs2/upload-ylab-stunt/se/ai_portal_queue_mmu_image_upscale_aiweb/3214b798-e1b4-4b00-b7af-72b5b0417420_raw_image_0.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The URL of the image to use as input."
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "The LoRA weights to use for generation.",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "prompt": {
          "examples": [
            "The astronaut gets up and walks away"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for generation."
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use.",
          "default": "blurry, low quality, low resolution, inconsistent motion, jittery, distorted"
        }
      },
      "description": "Request model for image-to-video generation.",
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "loras",
        "resolution",
        "aspect_ratio",
        "number_of_frames",
        "number_of_steps",
        "frame_rate",
        "seed",
        "expand_prompt",
        "reverse_video",
        "enable_safety_checker",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 4,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/pixverse/v4.5/transition",
    "name": "Pixverse",
    "description": "Create seamless transition between images using PixVerse v4.5",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TransitionRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Scene slowly transition into cat swimming under water"
          ],
          "description": "The prompt for the transition",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "first_image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/owQh2DAzk8UU7J02nr5RY_Co2P4boLv6meIZ5t9gKvL_8685da151df343ab8bf82165c928e2a5.jpg"
          ],
          "description": "URL of the image to use as the first frame",
          "type": "string",
          "title": "First Image Url"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "end_image_url": {
          "examples": [
            "https://v3.fal.media/files/kangaroo/RgedFs_WSnq5BgER7qDx1_ONrbTJ1YAGXz-9JnSsBoB_bdc8750387734bfe940319f469f7b0b2.jpg"
          ],
          "description": "URL of the image to use as the last frame",
          "type": "string",
          "title": "End Image Url"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed",
        "first_image_url",
        "end_image_url"
      ],
      "required": [
        "prompt",
        "first_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/pixverse/v4.5/image-to-video/fast",
    "name": "Pixverse",
    "description": "Generate fast high quality video clips from text and image prompts using PixVerse v4.5",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastImageToVideoRequestV4",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman warrior with her hammer walking with his glacier wolf."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "camera_movement": {
          "enum": [
            "horizontal_left",
            "horizontal_right",
            "vertical_up",
            "vertical_down",
            "zoom_in",
            "zoom_out",
            "crane_up",
            "quickly_zoom_in",
            "quickly_zoom_out",
            "smooth_zoom_in",
            "camera_rotation",
            "robo_arm",
            "super_dolly_out",
            "whip_pan",
            "hitchcock",
            "left_follow",
            "right_follow",
            "pan_left",
            "pan_right",
            "fix_bg"
          ],
          "description": "The type of camera movement to apply to the video",
          "type": "string",
          "title": "Camera Movement"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
          ],
          "description": "URL of the image to use as the first frame",
          "type": "string",
          "title": "Image Url"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "negative_prompt",
        "style",
        "seed",
        "image_url",
        "camera_movement"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 2,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/pixverse/v4.5/image-to-video",
    "name": "Pixverse",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v4.5",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoRequestV4",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman warrior with her hammer walking with his glacier wolf."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "camera_movement": {
          "enum": [
            "horizontal_left",
            "horizontal_right",
            "vertical_up",
            "vertical_down",
            "zoom_in",
            "zoom_out",
            "crane_up",
            "quickly_zoom_in",
            "quickly_zoom_out",
            "smooth_zoom_in",
            "camera_rotation",
            "robo_arm",
            "super_dolly_out",
            "whip_pan",
            "hitchcock",
            "left_follow",
            "right_follow",
            "pan_left",
            "pan_right",
            "fix_bg"
          ],
          "description": "The type of camera movement to apply to the video",
          "type": "string",
          "title": "Camera Movement"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
          ],
          "description": "URL of the image to use as the first frame",
          "type": "string",
          "title": "Image Url"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed",
        "image_url",
        "camera_movement"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/pixverse/v4.5/effects",
    "name": "Pixverse",
    "description": "Generate high quality video clips with different effects using PixVerse v4.5",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "EffectInput",
      "type": "object",
      "properties": {
        "negative_prompt": {
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video.",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "effect": {
          "enum": [
            "Kiss Me AI",
            "Kiss",
            "Muscle Surge",
            "Warmth of Jesus",
            "Anything, Robot",
            "The Tiger Touch",
            "Hug",
            "Holy Wings",
            "Microwave",
            "Zombie Mode",
            "Squid Game",
            "Baby Face",
            "Black Myth: Wukong",
            "Long Hair Magic",
            "Leggy Run",
            "Fin-tastic Mermaid",
            "Punch Face",
            "Creepy Devil Smile",
            "Thunder God",
            "Eye Zoom Challenge",
            "Who's Arrested?",
            "Baby Arrived",
            "Werewolf Rage",
            "Bald Swipe",
            "BOOM DROP",
            "Huge Cutie",
            "Liquid Metal",
            "Sharksnap!",
            "Dust Me Away",
            "3D Figurine Factor",
            "Bikini Up",
            "My Girlfriends",
            "My Boyfriends",
            "Subject 3 Fever",
            "Earth Zoom",
            "Pole Dance",
            "Vroom Dance",
            "GhostFace Terror",
            "Dragon Evoker",
            "Skeletal Bae",
            "Summoning succubus",
            "Halloween Voodoo Doll",
            "3D Naked-Eye AD",
            "Package Explosion",
            "Dishes Served",
            "Ocean ad",
            "Supermarket AD"
          ],
          "description": "The effect to apply to the video",
          "type": "string",
          "title": "Effect"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/q5ahL3KS7ikt3MvpNUG8l_image%20(72).webp"
          ],
          "description": "Optional URL of the image to use as the first frame. If not provided, generates from text",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "effect",
        "image_url",
        "resolution",
        "duration",
        "negative_prompt"
      ],
      "required": [
        "effect",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/hunyuan-custom",
    "name": "Hunyuan Custom",
    "description": "HunyuanCustom revolutionizes video generation with unmatched identity consistency across multiple input types. Its innovative fusion modules and alignment networks outperform competitors, maintaining subject integrity while responding flexibly to text, image, audio, and video conditions.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "HunyuanCustomRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Realistic, High-quality. A woman is playing a violin."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt for video generation (max 500 characters)."
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio (W:H)",
          "type": "string",
          "description": "The aspect ratio of the video to generate.",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "512p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
          "default": "512p"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_frames": {
          "minimum": 81,
          "title": "Number of Frames",
          "type": "integer",
          "maximum": 129,
          "description": "The number of frames to generate.",
          "default": 129
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/hidream/woman.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image input."
        },
        "fps": {
          "minimum": 16,
          "title": "Frames per second",
          "type": "integer",
          "maximum": 30,
          "description": "The frames per second of the generated video.",
          "default": 25
        },
        "enable_prompt_expansion": {
          "examples": [
            true
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for generating the video."
        },
        "num_inference_steps": {
          "minimum": 10,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 30,
          "description": "The number of inference steps to run. Lower gets faster results, higher gets better results.",
          "default": 30
        },
        "negative_prompt": {
          "examples": [
            "Ugly, blurry."
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": "Aerial view, aerial view, overexposed, low quality, deformation, a poor composition, bad hands, bad teeth, bad eyes, bad limbs, distortion, blurring, text, subtitles, static, picture, black border."
        },
        "cfg_scale": {
          "minimum": 1.5,
          "title": "CFG Scale",
          "type": "number",
          "maximum": 13,
          "description": "Classifier-Free Guidance scale for the generation.",
          "default": 7.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_url",
        "num_inference_steps",
        "seed",
        "aspect_ratio",
        "resolution",
        "fps",
        "cfg_scale",
        "num_frames",
        "enable_prompt_expansion",
        "enable_safety_checker"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/framepack/f1",
    "name": "Framepack F1",
    "description": "Framepack is an efficient Image-to-video model that autoregressively generates videos.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/koala/dUfFd9Z7aSX06gL2_qXn0_image.webp",
    "tags": [
      "image to video",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FramePackF1Request",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A mesmerising video of a deep sea jellyfish moving through an inky-black ocean. The jellyfish glows softly with an amber bioluminescence. The overall scene is lifelike."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt for video generation (max 500 characters)."
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio (W:H)",
          "type": "string",
          "description": "The aspect ratio of the video to generate.",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "720p",
            "480p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
          "default": "480p"
        },
        "num_frames": {
          "minimum": 30,
          "title": "Number of Frames",
          "type": "integer",
          "maximum": 900,
          "description": "The number of frames to generate.",
          "default": 180
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/framepack/framepack.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image input."
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 32,
          "description": "Guidance scale for the generation.",
          "default": 10
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "The seed to use for generating the video."
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "negative_prompt": {
          "examples": [
            "Ugly, blurry distorted, bad quality"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "cfg_scale": {
          "minimum": 0,
          "title": "CFG Scale",
          "type": "number",
          "maximum": 7,
          "description": "Classifier-Free Guidance scale for the generation.",
          "default": 1
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_url",
        "seed",
        "aspect_ratio",
        "resolution",
        "cfg_scale",
        "guidance_scale",
        "num_frames",
        "enable_safety_checker"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/vidu/q1/start-end-to-video",
    "name": "Vidu Start End to Video",
    "description": "Vidu Q1 Start-End to Video generates smooth transition 1080p videos between specified start and end images.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Q1StartEndToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Dragon lands on a rock"
          ],
          "maxLength": 1500,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 1500 characters"
        },
        "start_image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/sgsdKvPigPhJ1S7Hl5bWc_first_frame_q1.png"
          ],
          "title": "Start Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        },
        "end_image_url": {
          "examples": [
            "https://v3.fal.media/files/kangaroo/CASBu_OmOnZ8IafirarFL_last_frame_q1.png"
          ],
          "title": "End Image Url",
          "type": "string",
          "description": "URL of the image to use as the last frame"
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Seed for the random number generator"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "start_image_url",
        "end_image_url",
        "seed",
        "movement_amplitude"
      ],
      "required": [
        "prompt",
        "start_image_url",
        "end_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/vidu/q1/image-to-video",
    "name": "Vidu Image to Video",
    "description": "Vidu Q1 Image to Video generates high-quality 1080p videos with exceptional visual quality and motion diversity from a single image",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Q1ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The astronaut waved and the camera moved up."
          ],
          "maxLength": 1500,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 1500 characters"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Seed for the random number generator"
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/video_models/vidu_i2v.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "seed",
        "movement_amplitude"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/ltx-video-v097/image-to-video",
    "name": "LTX Video-0.9.7",
    "description": "Deprecated.\nUse fal-ai/ltx-video-13b-dev or fal-ai/ltx-video-13b-distilled instead.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "tags": [
      "video",
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The astronaut gets up and walks away"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide generation"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p or 720p).",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "default": "16:9"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using the model's own capabilities.",
          "default": true
        },
        "image_url": {
          "examples": [
            "https://h2.inkwai.com/bs2/upload-ylab-stunt/se/ai_portal_queue_mmu_image_upscale_aiweb/3214b798-e1b4-4b00-b7af-72b5b0417420_raw_image_0.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "Image URL for Image-to-Video task"
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "Number of inference steps",
          "default": 40
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for generation",
          "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "resolution",
        "aspect_ratio",
        "seed",
        "num_inference_steps",
        "expand_prompt",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 2,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/magi/image-to-video",
    "name": "MAGI-1",
    "description": "MAGI-1 generates videos from images with exceptional understanding of physical interactions and prompting",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-2.jpg",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MagiImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A crisp, wintery mountain landscape unfolds as a snowboarder, equipped with a selfie pole, gracefully navigates a snow-covered slope, the camera perspective offering an exhilarating attached-third-person view of the descent;  the vibrant, snowy scenery sweeps past, punctuated by moments of controlled spins and effortless glides, creating a dynamic visual rhythm that complements the exhilarating pace of the ride;  as the snowboarder carves through pristine powder, the camera captures fleeting moments of breathtaking views\u2014towering pines dusted with snow, sunlit peaks piercing a cerulean sky\u2014a symphony of nature\u2019s grandeur displayed for the viewer to share;  a sense of freedom and exhilaration permeates the scene, punctuated by the subtle whoosh of wind and the satisfying crunch of snow, culminating in a breathtaking panorama as the snowboarder reaches the bottom, leaving the viewer with a lingering sense of wonder and the desire to experience the thrill firsthand."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/kangaroo/sGqTf5scZcC5VNfOLbxwE_maxresdefault-2740110268.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "enum": [
            4,
            8,
            16,
            32,
            64
          ],
          "title": "Num Inference Steps",
          "type": "integer",
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "default": 16
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "num_frames": {
          "minimum": 96,
          "title": "Num Frames",
          "type": "integer",
          "maximum": 192,
          "description": "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
          "default": 96
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "num_frames",
        "seed",
        "resolution",
        "num_inference_steps",
        "enable_safety_checker",
        "aspect_ratio"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 20,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/pixverse/v4/effects",
    "name": "Pixverse",
    "description": "Generate high quality video clips with different effects using PixVerse v4",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "EffectInput",
      "type": "object",
      "properties": {
        "negative_prompt": {
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video.",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "effect": {
          "enum": [
            "Kiss Me AI",
            "Kiss",
            "Muscle Surge",
            "Warmth of Jesus",
            "Anything, Robot",
            "The Tiger Touch",
            "Hug",
            "Holy Wings",
            "Microwave",
            "Zombie Mode",
            "Squid Game",
            "Baby Face",
            "Black Myth: Wukong",
            "Long Hair Magic",
            "Leggy Run",
            "Fin-tastic Mermaid",
            "Punch Face",
            "Creepy Devil Smile",
            "Thunder God",
            "Eye Zoom Challenge",
            "Who's Arrested?",
            "Baby Arrived",
            "Werewolf Rage",
            "Bald Swipe",
            "BOOM DROP",
            "Huge Cutie",
            "Liquid Metal",
            "Sharksnap!",
            "Dust Me Away",
            "3D Figurine Factor",
            "Bikini Up",
            "My Girlfriends",
            "My Boyfriends",
            "Subject 3 Fever",
            "Earth Zoom",
            "Pole Dance",
            "Vroom Dance",
            "GhostFace Terror",
            "Dragon Evoker",
            "Skeletal Bae",
            "Summoning succubus",
            "Halloween Voodoo Doll",
            "3D Naked-Eye AD",
            "Package Explosion",
            "Dishes Served",
            "Ocean ad",
            "Supermarket AD"
          ],
          "description": "The effect to apply to the video",
          "type": "string",
          "title": "Effect"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/q5ahL3KS7ikt3MvpNUG8l_image%20(72).webp"
          ],
          "description": "Optional URL of the image to use as the first frame. If not provided, generates from text",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "effect",
        "image_url",
        "resolution",
        "duration",
        "negative_prompt"
      ],
      "required": [
        "effect",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/magi-distilled/image-to-video",
    "name": "MAGI-1 (Distilled)",
    "description": "MAGI-1 distilled generates videos faster from images with exceptional understanding of physical interactions and prompting",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-2.jpg",
    "tags": [
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MagiImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Close-up shot: the old sea captain stares intently, pipe in mouth, wisps of smoke curling around his weathered face. The camera begins to pull back out over the ocean. Finally, the camera sinks below the waves deeply, fading to dark blue and finally to black."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "image_url": {
          "examples": [
            "https://raw.githubusercontent.com/painebenjamin/pointy-seeds/refs/heads/main/captain-start.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the input image to represent the first frame of the video. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "enum": [
            4,
            8,
            16,
            32
          ],
          "title": "Num Inference Steps",
          "type": "integer",
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "default": 16
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "num_frames": {
          "minimum": 96,
          "title": "Num Frames",
          "type": "integer",
          "maximum": 192,
          "description": "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
          "default": 96
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "num_frames",
        "seed",
        "resolution",
        "num_inference_steps",
        "enable_safety_checker",
        "aspect_ratio"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 8,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/framepack/flf2v",
    "name": "Framepack",
    "description": "Framepack is an efficient Image-to-video model that autoregressively generates videos.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-5.jpg",
    "tags": [
      "image to video",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FramePackF2LFRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A tabby cat is confidely strolling toward the camera, when it spins and with a flash of magic reveals itself to be a cat-dragon hybrid with glistening amber scales."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt for video generation (max 500 characters)."
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio (W:H)",
          "type": "string",
          "description": "The aspect ratio of the video to generate.",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "720p",
            "480p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
          "default": "480p"
        },
        "num_frames": {
          "minimum": 30,
          "title": "Number of Frames",
          "type": "integer",
          "maximum": 1800,
          "description": "The number of frames to generate.",
          "default": 240
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/wan_flf/first_frame.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image input."
        },
        "strength": {
          "minimum": 0,
          "title": "Strength of last frame",
          "type": "number",
          "maximum": 1,
          "description": "Determines the influence of the final frame on the generated video. Higher values result in the output being more heavily influenced by the last frame.",
          "default": 0.8
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 32,
          "description": "Guidance scale for the generation.",
          "default": 10
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "The seed to use for generating the video."
        },
        "end_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/wan_flf/last_frame.png"
          ],
          "title": "End Image Url",
          "type": "string",
          "description": "URL of the end image input."
        },
        "negative_prompt": {
          "examples": [
            "Ugly, blurry distorted, bad quality"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "cfg_scale": {
          "minimum": 0,
          "title": "CFG Scale",
          "type": "number",
          "maximum": 7,
          "description": "Classifier-Free Guidance scale for the generation.",
          "default": 1
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_url",
        "seed",
        "aspect_ratio",
        "resolution",
        "cfg_scale",
        "guidance_scale",
        "num_frames",
        "enable_safety_checker",
        "end_image_url",
        "strength"
      ],
      "required": [
        "prompt",
        "image_url",
        "end_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/wan-flf2v",
    "name": "Wan-2.1 First-Last-Frame-to-Video",
    "description": "Wan-2.1 flf2v generates dynamic videos by intelligently bridging a given first frame to a desired end frame through smooth, coherent motion sequences.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-2.jpg",
    "tags": [
      "image to video",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanFLF2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A tabby cat is confidely strolling toward the camera, when it spins and with a flash of magic reveals itself to be a cat-dragon hybrid with glistening amber scales."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "shift": {
          "minimum": 1,
          "maximum": 10,
          "type": "number",
          "title": "Shift",
          "description": "Shift parameter for video generation.",
          "default": 5
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "examples": [
            "regular"
          ],
          "default": "regular"
        },
        "frames_per_second": {
          "minimum": 5,
          "maximum": 24,
          "type": "integer",
          "title": "Frames Per Second",
          "description": "Frames per second of the generated video. Must be between 5 to 24.",
          "default": 16
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "start_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/wan_flf/first_frame.png"
          ],
          "title": "Start Image Url",
          "type": "string",
          "description": "URL of the starting image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "end_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/wan_flf/last_frame.png"
          ],
          "title": "End Image Url",
          "type": "string",
          "description": "URL of the ending image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "negative_prompt": {
          "examples": [
            "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        },
        "num_frames": {
          "minimum": 81,
          "maximum": 100,
          "type": "integer",
          "title": "Num Frames",
          "description": "Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
          "default": 81
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "guide_scale": {
          "minimum": 1,
          "maximum": 10,
          "type": "number",
          "title": "Guide Scale",
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 40,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "default": 30
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "start_image_url",
        "end_image_url",
        "num_frames",
        "frames_per_second",
        "seed",
        "resolution",
        "num_inference_steps",
        "guide_scale",
        "shift",
        "enable_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "aspect_ratio"
      ],
      "required": [
        "prompt",
        "start_image_url",
        "end_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/framepack",
    "name": "Framepack",
    "description": "Framepack is an efficient Image-to-video model that autoregressively generates videos.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3.fal.media/files/koala/dUfFd9Z7aSX06gL2_qXn0_image.webp",
    "tags": [
      "image to video",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FramePackRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A mesmerising video of a deep sea jellyfish moving through an inky-black ocean. The jellyfish glows softly with an amber bioluminescence. The overall scene is lifelike."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt for video generation (max 500 characters)."
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio (W:H)",
          "type": "string",
          "description": "The aspect ratio of the video to generate.",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "720p",
            "480p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the video to generate. 720p generations cost 1.5x more than 480p generations.",
          "default": "480p"
        },
        "num_frames": {
          "minimum": 30,
          "title": "Number of Frames",
          "type": "integer",
          "maximum": 900,
          "description": "The number of frames to generate.",
          "default": 180
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/framepack/framepack.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image input."
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 32,
          "description": "Guidance scale for the generation.",
          "default": 10
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "The seed to use for generating the video."
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "negative_prompt": {
          "examples": [
            "Ugly, blurry distorted, bad quality"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "cfg_scale": {
          "minimum": 0,
          "title": "CFG Scale",
          "type": "number",
          "maximum": 7,
          "description": "Classifier-Free Guidance scale for the generation.",
          "default": 1
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_url",
        "seed",
        "aspect_ratio",
        "resolution",
        "cfg_scale",
        "guidance_scale",
        "num_frames",
        "enable_safety_checker"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/pixverse/v4/image-to-video/fast",
    "name": "PixVerse v4: Image to Video Fast",
    "description": "Generate fast high quality video clips from text and image prompts using PixVerse v4",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastImageToVideoRequestV4",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman warrior with her hammer walking with his glacier wolf."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "camera_movement": {
          "enum": [
            "horizontal_left",
            "horizontal_right",
            "vertical_up",
            "vertical_down",
            "zoom_in",
            "zoom_out",
            "crane_up",
            "quickly_zoom_in",
            "quickly_zoom_out",
            "smooth_zoom_in",
            "camera_rotation",
            "robo_arm",
            "super_dolly_out",
            "whip_pan",
            "hitchcock",
            "left_follow",
            "right_follow",
            "pan_left",
            "pan_right",
            "fix_bg"
          ],
          "description": "The type of camera movement to apply to the video",
          "type": "string",
          "title": "Camera Movement"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
          ],
          "description": "URL of the image to use as the first frame",
          "type": "string",
          "title": "Image Url"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "negative_prompt",
        "style",
        "seed",
        "image_url",
        "camera_movement"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 2,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/pixverse/v4/image-to-video",
    "name": "PixVerse v4: Image to Video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v4",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoRequestV4",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A woman warrior with her hammer walking with his glacier wolf."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "camera_movement": {
          "enum": [
            "horizontal_left",
            "horizontal_right",
            "vertical_up",
            "vertical_down",
            "zoom_in",
            "zoom_out",
            "crane_up",
            "quickly_zoom_in",
            "quickly_zoom_out",
            "smooth_zoom_in",
            "camera_rotation",
            "robo_arm",
            "super_dolly_out",
            "whip_pan",
            "hitchcock",
            "left_follow",
            "right_follow",
            "pan_left",
            "pan_right",
            "fix_bg"
          ],
          "description": "The type of camera movement to apply to the video",
          "type": "string",
          "title": "Camera Movement"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/qL93Je8ezvzQgDOEzTjKF_KhGKZTEebZcDw6T5rwQPK_output.png"
          ],
          "description": "URL of the image to use as the first frame",
          "type": "string",
          "title": "Image Url"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed",
        "image_url",
        "camera_movement"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/pixverse/v3.5/effects",
    "name": "PixVerse v3.5: Effects",
    "description": "Generate high quality video clips with different effects using PixVerse v3.5",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "EffectInput",
      "type": "object",
      "properties": {
        "negative_prompt": {
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video.",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "effect": {
          "enum": [
            "Kiss Me AI",
            "Kiss",
            "Muscle Surge",
            "Warmth of Jesus",
            "Anything, Robot",
            "The Tiger Touch",
            "Hug",
            "Holy Wings",
            "Microwave",
            "Zombie Mode",
            "Squid Game",
            "Baby Face",
            "Black Myth: Wukong",
            "Long Hair Magic",
            "Leggy Run",
            "Fin-tastic Mermaid",
            "Punch Face",
            "Creepy Devil Smile",
            "Thunder God",
            "Eye Zoom Challenge",
            "Who's Arrested?",
            "Baby Arrived",
            "Werewolf Rage",
            "Bald Swipe",
            "BOOM DROP",
            "Huge Cutie",
            "Liquid Metal",
            "Sharksnap!",
            "Dust Me Away",
            "3D Figurine Factor",
            "Bikini Up",
            "My Girlfriends",
            "My Boyfriends",
            "Subject 3 Fever",
            "Earth Zoom",
            "Pole Dance",
            "Vroom Dance",
            "GhostFace Terror",
            "Dragon Evoker",
            "Skeletal Bae",
            "Summoning succubus",
            "Halloween Voodoo Doll",
            "3D Naked-Eye AD",
            "Package Explosion",
            "Dishes Served",
            "Ocean ad",
            "Supermarket AD"
          ],
          "description": "The effect to apply to the video",
          "type": "string",
          "title": "Effect"
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/koala/q5ahL3KS7ikt3MvpNUG8l_image%20(72).webp"
          ],
          "description": "Optional URL of the image to use as the first frame. If not provided, generates from text",
          "type": "string",
          "title": "Image Url"
        }
      },
      "x-fal-order-properties": [
        "effect",
        "image_url",
        "resolution",
        "duration",
        "negative_prompt"
      ],
      "required": [
        "effect",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/pixverse/v3.5/transition",
    "name": "PixVerse v3.5: Transition",
    "description": "Create seamless transition between images using PixVerse v3.5",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TransitionRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Scene slowly transition into cat swimming under water"
          ],
          "description": "The prompt for the transition",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "first_image_url": {
          "examples": [
            "https://v3.fal.media/files/zebra/owQh2DAzk8UU7J02nr5RY_Co2P4boLv6meIZ5t9gKvL_8685da151df343ab8bf82165c928e2a5.jpg"
          ],
          "description": "URL of the image to use as the first frame",
          "type": "string",
          "title": "First Image Url"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "end_image_url": {
          "examples": [
            "https://v3.fal.media/files/kangaroo/RgedFs_WSnq5BgER7qDx1_ONrbTJ1YAGXz-9JnSsBoB_bdc8750387734bfe940319f469f7b0b2.jpg"
          ],
          "description": "URL of the image to use as the last frame",
          "type": "string",
          "title": "End Image Url"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed",
        "first_image_url",
        "end_image_url"
      ],
      "required": [
        "prompt",
        "first_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2-flash/image-to-video",
    "name": "Luma Ray 2 Flash (Image to Video)",
    "description": "Ray2 Flash is a fast video generative model capable of creating realistic visuals with natural, coherent motion.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Ray2ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
          ],
          "maxLength": 5000,
          "type": "string",
          "minLength": 3,
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "21:9",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "540p",
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
          "default": "540p"
        },
        "loop": {
          "title": "Loop",
          "type": "boolean",
          "description": "Whether the video should loop (end of video is blended with the beginning)",
          "default": false
        },
        "duration": {
          "enum": [
            "5s",
            "9s"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video",
          "default": "5s"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "Initial image to start the video from. Can be used together with end_image_url."
        },
        "end_image_url": {
          "title": "End Image Url",
          "type": "string",
          "description": "Final image to end the video with. Can be used together with image_url."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "end_image_url",
        "aspect_ratio",
        "loop",
        "resolution",
        "duration"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "5 seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/pika/v1.5/pikaffects",
    "name": "Pika Effects (v1.5)",
    "description": "Pika Effects are AI-powered video effects designed to modify objects, characters, and environments in a fun, engaging, and visually compelling manner.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/2uSfx4xu1fXv4am4PvLAm_499f61b93f924a7496982491a87fb169.jpg",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "pikaffect",
        "prompt",
        "negative_prompt",
        "seed"
      ],
      "type": "object",
      "properties": {
        "pikaffect": {
          "enum": [
            "Cake-ify",
            "Crumble",
            "Crush",
            "Decapitate",
            "Deflate",
            "Dissolve",
            "Explode",
            "Eye-pop",
            "Inflate",
            "Levitate",
            "Melt",
            "Peel",
            "Poke",
            "Squish",
            "Ta-da",
            "Tear"
          ],
          "title": "Pikaffect",
          "type": "string",
          "examples": [
            "Crush"
          ],
          "description": "The Pikaffect to apply"
        },
        "prompt": {
          "examples": [
            "A duck getting crushed"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide the effect"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt to guide the model"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/zebra/2Ro7MtV3BGarwQXPtdK6B_148325d4459c4e34917e8eb5c25877d4.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the input image"
        }
      },
      "title": "PikaffectsRequest",
      "description": "Request model for Pikaffects endpoint",
      "required": [
        "image_url",
        "pikaffect"
      ]
    }
  },
  {
    "id": "fal-ai/pika/v2/turbo/image-to-video",
    "name": "Pika Image to Video Turbo (v2)",
    "description": "in the style of TOK fast, turbo",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/izszWyAu5LZ56Z-ZK63x5_1c8004b9a1054d0d849848569196d293.jpg",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "seed",
        "negative_prompt",
        "resolution",
        "duration"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A pink heart exploding."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "duration": {
          "title": "Duration",
          "type": "integer",
          "description": "The duration of the generated video in seconds",
          "default": 5
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated video",
          "default": "720p"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "A negative prompt to guide the model",
          "default": ""
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/elephant/dJjBQXNHRbGJn4aUv4-g9_hearth.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "title": "ImageToVideoRequest",
      "description": "Base request for image-to-video generation",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 4,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/pika/v2.2/image-to-video",
    "name": "Pika Image to Video (v2.2)",
    "description": "Pika v2.2 creates videos from images with high quality output.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/koala/mATl0lc8FwiR6WceFEDfH_692743a190bc4859a00caa338a1809c5.jpg",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "seed",
        "negative_prompt",
        "resolution",
        "duration"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "a woman looking into camera slowly smiling"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "duration": {
          "enum": [
            5,
            10
          ],
          "title": "Duration",
          "type": "integer",
          "description": "The duration of the generated video in seconds",
          "default": 5
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "examples": [
            "1080p",
            "720p"
          ],
          "description": "The resolution of the generated video",
          "default": "720p"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "A negative prompt to guide the model",
          "default": ""
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/pika/pika%202.2/pika_input.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "title": "Pika22ImageToVideoRequest",
      "description": "Request model for Pika 2.2 image-to-video generation",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 4,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/pika/v2.1/image-to-video",
    "name": "Pika Image to Video (v2.1)",
    "description": "Pika v2.1 creates videos from images with high quality output.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/9yJyc4ezyAPejLJlzquI9_f8b95aa25041426fbc0c0861ae80a2c6.jpg",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "seed",
        "negative_prompt",
        "resolution",
        "duration"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A pink heart exploding."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "duration": {
          "title": "Duration",
          "type": "integer",
          "description": "The duration of the generated video in seconds",
          "default": 5
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated video",
          "default": "720p"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "A negative prompt to guide the model",
          "default": ""
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/elephant/dJjBQXNHRbGJn4aUv4-g9_hearth.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "title": "ImageToVideoRequest",
      "description": "Base request for image-to-video generation",
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 8,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/pika/v2.2/pikascenes",
    "name": "Pika Scenes (v2.2)",
    "description": "Pika Scenes v2.2 creates videos from a images with high quality output.",
    "category": "image-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/3FYXmzqtjqf6xQ5YVxbKi_bf6ff3d3904a42c783662e7e1fa21ce9.jpg",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "image_urls",
        "prompt",
        "negative_prompt",
        "seed",
        "aspect_ratio",
        "resolution",
        "duration",
        "ingredients_mode"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "wide angle, Two PEOPLE sit at a small table. sipping tea while gazing at a cloud in the distance."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt describing the desired video"
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "examples": [
            "1080p",
            "720p"
          ],
          "description": "The resolution of the generated video",
          "default": "1080p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1",
            "4:5",
            "5:4",
            "3:2",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            5,
            10
          ],
          "title": "Duration",
          "type": "integer",
          "examples": [
            5,
            10
          ],
          "description": "The duration of the generated video in seconds",
          "default": 5
        },
        "ingredients_mode": {
          "enum": [
            "precise",
            "creative"
          ],
          "title": "Ingredients Mode",
          "type": "string",
          "description": "Mode for integrating multiple images. Precise mode is more accurate, creative mode is more creative.",
          "default": "precise"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator"
        },
        "image_urls": {
          "examples": [
            [
              "https://v3b.fal.media/files/b/panda/-bb0zMqjGK5SQWCEYvrmd_woman.png",
              "https://v3b.fal.media/files/b/penguin/wtGUSrOzlxoHJki8-B11e_van-gogh.jpg"
            ]
          ],
          "title": "Image Urls",
          "type": "array",
          "description": "URLs of images to combine into a video",
          "items": {
            "type": "string"
          }
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "A negative prompt to guide the model",
          "default": "ugly, bad, terrible"
        }
      },
      "title": "Pika22PikascenesRequest",
      "description": "Request model for Pika 2.2 Pikascenes (collection-to-video) generation",
      "required": [
        "image_urls",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/vidu/image-to-video",
    "name": "Vidu Image to Video",
    "description": "Vidu Image to Video generates high-quality videos with exceptional visual quality and motion diversity from a single image",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/vidu/vidu.webp",
    "tags": [
      "motion",
      "image to video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "maxLength": 1500,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 1500 characters"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/vidu/stylish_woman.webp"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "seed",
        "movement_amplitude"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/vidu/start-end-to-video",
    "name": "Vidu Start-End to Video",
    "description": "Vidu Start-End to Video generates smooth transition videos between specified start and end images.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/vidu/vidu.webp",
    "tags": [
      "motion",
      "transition"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "StartEndToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Transform the car frame into a complete vehicle."
          ],
          "maxLength": 1500,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 1500 characters"
        },
        "start_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/vidu/2-carchasis.png"
          ],
          "title": "Start Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        },
        "end_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/web-examples/vidu/2-carbody.png"
          ],
          "title": "End Image Url",
          "type": "string",
          "description": "URL of the image to use as the last frame"
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "start_image_url",
        "end_image_url",
        "seed",
        "movement_amplitude"
      ],
      "required": [
        "prompt",
        "start_image_url",
        "end_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/vidu/reference-to-video",
    "name": "Vidu Reference to Video",
    "description": "Vidu Reference to Video creates videos by using a reference images and combining them with a prompt.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/vidu/vidu.webp",
    "tags": [
      "motion",
      "reference"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ReferenceToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The little devil is looking at the apple on the beach and walking around it."
          ],
          "maxLength": 1500,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 1500 characters"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the output video",
          "default": "16:9"
        },
        "reference_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference1.png",
              "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference2.png",
              "https://storage.googleapis.com/falserverless/web-examples/vidu/new-examples/reference3.png"
            ]
          ],
          "title": "Reference Image Urls",
          "type": "array",
          "description": "URLs of the reference images to use for consistent subject appearance",
          "items": {
            "type": "string"
          }
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "reference_image_urls",
        "seed",
        "aspect_ratio",
        "movement_amplitude"
      ],
      "required": [
        "prompt",
        "reference_image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/vidu/template-to-video",
    "name": "Vidu Template to Video",
    "description": "Vidu Template to Video lets you create different effects by applying motion templates to your images.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/vidu/vidu.webp",
    "tags": [
      "motion",
      "template"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TemplateToVideoRequest",
      "type": "object",
      "properties": {
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the output video",
          "default": "16:9"
        },
        "template": {
          "enum": [
            "dreamy_wedding",
            "romantic_lift",
            "sweet_proposal",
            "couple_arrival",
            "cupid_arrow",
            "pet_lovers",
            "lunar_newyear",
            "hug",
            "kiss",
            "dynasty_dress",
            "wish_sender",
            "love_pose",
            "hair_swap",
            "youth_rewind",
            "morphlab",
            "live_photo",
            "emotionlab",
            "live_memory",
            "interaction",
            "christmas",
            "pet_finger",
            "eat_mushrooms",
            "beast_chase_library",
            "beast_chase_supermarket",
            "petal_scattered",
            "emoji_figure",
            "hair_color_change",
            "multiple_people_kissing",
            "beast_chase_amazon",
            "beast_chase_mountain",
            "balloonman_explodes_pro",
            "get_thinner",
            "jump2pool",
            "bodyshake",
            "jiggle_up",
            "shake_it_dance",
            "subject_3",
            "pubg_winner_hit",
            "shake_it_down",
            "blueprint_supreme",
            "hip_twist",
            "motor_dance",
            "rat_dance",
            "kwok_dance",
            "leg_sweep_dance",
            "heeseung_march",
            "shake_to_max",
            "dame_un_grrr",
            "i_know",
            "lit_bounce",
            "wave_dance",
            "chill_dance",
            "hip_flicking",
            "sakura_season",
            "zongzi_wrap",
            "zongzi_drop",
            "dragonboat_shot",
            "rain_kiss",
            "child_memory",
            "couple_drop",
            "couple_walk",
            "flower_receive",
            "love_drop",
            "cheek_kiss",
            "carry_me",
            "blow_kiss",
            "love_fall",
            "french_kiss_8s",
            "workday_feels",
            "love_story",
            "bloom_magic",
            "ghibli",
            "minecraft",
            "box_me",
            "claw_me",
            "clayshot",
            "manga_meme",
            "quad_meme",
            "pixel_me",
            "clayshot_duo",
            "irasutoya",
            "american_comic",
            "simpsons_comic",
            "yayoi_kusama_style",
            "pop_art",
            "jojo_style",
            "slice_therapy",
            "balloon_flyaway",
            "flying",
            "paperman",
            "pinch",
            "bloom_doorobear",
            "gender_swap",
            "nap_me",
            "sexy_me",
            "spin360",
            "smooth_shift",
            "paper_fall",
            "jump_to_cloud",
            "pilot",
            "sweet_dreams",
            "soul_depart",
            "punch_hit",
            "watermelon_hit",
            "split_stance_pet",
            "make_face",
            "break_glass",
            "split_stance_human",
            "covered_liquid_metal",
            "fluffy_plunge",
            "pet_belly_dance",
            "water_float",
            "relax_cut",
            "head_to_balloon",
            "cloning",
            "across_the_universe_jungle",
            "clothes_spinning_remnant",
            "across_the_universe_jurassic",
            "across_the_universe_moon",
            "fisheye_pet",
            "hitchcock_zoom",
            "cute_bangs",
            "earth_zoom_out",
            "fisheye_human",
            "drive_yacht",
            "virtual_singer",
            "earth_zoom_in",
            "aliens_coming",
            "drive_ferrari",
            "bjd_style",
            "virtual_fitting",
            "orbit",
            "zoom_in",
            "ai_outfit",
            "spin180",
            "orbit_dolly",
            "orbit_dolly_fast",
            "auto_spin",
            "walk_forward",
            "outfit_show",
            "zoom_in_fast",
            "zoom_out_image",
            "zoom_out_startend",
            "muscling",
            "captain_america",
            "hulk",
            "cap_walk",
            "hulk_dive",
            "exotic_princess",
            "beast_companion",
            "cartoon_doll",
            "golden_epoch",
            "oscar_gala",
            "fashion_stride",
            "star_carpet",
            "flame_carpet",
            "frost_carpet",
            "mecha_x",
            "style_me",
            "tap_me",
            "saber_warrior",
            "pet2human",
            "graduation",
            "fishermen",
            "happy_birthday",
            "fairy_me",
            "ladudu_me",
            "ladudu_me_random",
            "squid_game",
            "superman",
            "grow_wings",
            "clevage",
            "fly_with_doraemon",
            "creatice_product_down",
            "pole_dance",
            "hug_from_behind",
            "creatice_product_up_cybercity",
            "creatice_product_up_bluecircuit",
            "creatice_product_up",
            "run_fast",
            "background_explosion"
          ],
          "title": "Template",
          "type": "string",
          "description": "AI video template to use. Pricing varies by template: Standard templates (hug, kiss, love_pose, etc.) cost 4 credits ($0.20), Premium templates (lunar_newyear, dynasty_dress, dreamy_wedding, etc.) cost 6 credits ($0.30), and Advanced templates (live_photo) cost 10 credits ($0.50).",
          "default": "hug"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        },
        "input_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/web-examples/vidu/hug.PNG"
            ]
          ],
          "title": "Input Image Urls",
          "type": "array",
          "description": "URLs of the images to use with the template. Number of images required varies by template: 'dynasty_dress' and 'shop_frame' accept 1-2 images, 'wish_sender' requires exactly 3 images, all other templates accept only 1 image.",
          "items": {
            "type": "string"
          }
        }
      },
      "x-fal-order-properties": [
        "template",
        "input_image_urls",
        "seed",
        "aspect_ratio"
      ],
      "required": [
        "input_image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/wan-i2v-lora",
    "name": "Wan-2.1 Image-to-Video with LoRAs",
    "description": "Add custom LoRAs to Wan-2.1 is a image-to-video model that generates high-quality videos with high visual quality and motion diversity from images",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_02.jpg",
    "tags": [
      "image to video",
      "motion",
      "lora"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanLoRAI2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Cars race in slow motion."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "shift": {
          "minimum": 1,
          "title": "Shift",
          "type": "number",
          "description": "Shift parameter for video generation.",
          "maximum": 10,
          "default": 5
        },
        "reverse_video": {
          "title": "Reverse Video",
          "type": "boolean",
          "description": "If true, the video will be reversed.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "LoRA weights to be used in the inference.",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "frames_per_second": {
          "minimum": 5,
          "title": "Frames Per Second",
          "type": "integer",
          "description": "Frames per second of the generated video. Must be between 5 to 24.",
          "maximum": 24,
          "default": 16
        },
        "turbo_mode": {
          "title": "Turbo Mode",
          "type": "boolean",
          "description": "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
          "default": true
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "num_frames": {
          "minimum": 81,
          "title": "Num Frames",
          "type": "integer",
          "description": "Number of frames to generate. Must be between 81 to 100 (inclusive). If the number of frames is greater than 81, the video will be generated with 1.25x more billing units.",
          "maximum": 100,
          "default": 81
        },
        "negative_prompt": {
          "examples": [
            "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the output video.",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
          "default": "720p"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/gallery/car_720p.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "guide_scale": {
          "minimum": 1,
          "title": "Guide Scale",
          "type": "number",
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "maximum": 10,
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Num Inference Steps",
          "type": "integer",
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "maximum": 40,
          "default": 30
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_url",
        "num_frames",
        "frames_per_second",
        "seed",
        "resolution",
        "num_inference_steps",
        "guide_scale",
        "shift",
        "enable_safety_checker",
        "enable_prompt_expansion",
        "aspect_ratio",
        "loras",
        "reverse_video",
        "turbo_mode"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 15,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/hunyuan-video-image-to-video",
    "name": "Hunyuan Video Image-to-Video Inference",
    "description": "Image to Video for the high-quality Hunyuan Video I2V model.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video-image-to-video.webp",
    "tags": [
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "HunyuanVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Two muscular cats boxing in a boxing ring."
          ],
          "maxLength": 1000,
          "type": "string",
          "title": "Prompt",
          "description": "The prompt to generate the video from."
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio (W:H)",
          "type": "string",
          "description": "The aspect ratio of the video to generate.",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the video to generate.",
          "default": "720p"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/hunyuan_i2v.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image input."
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for generating the video."
        },
        "num_frames": {
          "enum": [
            "129"
          ],
          "title": "Number of Frames",
          "type": "string",
          "description": "The number of frames to generate.",
          "default": 129
        },
        "i2v_stability": {
          "title": "I2V Stability",
          "type": "boolean",
          "description": "Turning on I2V Stability reduces hallucination but also reduces motion.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "seed",
        "aspect_ratio",
        "resolution",
        "num_frames",
        "i2v_stability"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/ltx-video-v095/image-to-video",
    "name": "LTX Video-0.9.5",
    "description": "Generate videos from prompts and images using LTX Video-0.9.5",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/ltx-0.9.5.webp",
    "tags": [
      "video",
      "image-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The astronaut gets up and walks away"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide generation"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p or 720p).",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "default": "16:9"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using the model's own capabilities.",
          "default": true
        },
        "image_url": {
          "examples": [
            "https://h2.inkwai.com/bs2/upload-ylab-stunt/se/ai_portal_queue_mmu_image_upscale_aiweb/3214b798-e1b4-4b00-b7af-72b5b0417420_raw_image_0.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "Image URL for Image-to-Video task"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "default": 40
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for generation",
          "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "resolution",
        "aspect_ratio",
        "seed",
        "num_inference_steps",
        "expand_prompt",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/minimax/video-01-director/image-to-video",
    "name": "MiniMax (Hailuo AI) Video 01 Director - Image to Video",
    "description": "Generate video clips more accurately with respect to initial image, natural language descriptions, and using camera movement instructions for shot control.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/red_clouds.jpg",
    "tags": [
      "motion",
      "transformation",
      "camera-controls"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoDirectorRequest",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "[Push in, Follow]A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse.[Pan left] The street opens into a small plaza where street vendors sell steaming food under colorful awnings."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000,
          "description": "Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "prompt_optimizer"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 10,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/skyreels-i2v",
    "name": "Skyreels V1 (Image-to-Video)",
    "description": "SkyReels V1 is the first and most advanced open-source human-centric video foundation model. By fine-tuning HunyuanVideo on O(10M) high-quality film and television clips",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/skyreels-i2v.webp",
    "tags": [
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SkyreelsI2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the output video",
          "default": "16:9"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/panda/TuXlMwArpQcdYNCLAEM8K.webp"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image input."
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "Guidance scale for generation (between 1.0 and 20.0)",
          "default": 6
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation. If not provided, a random seed will be used."
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "Number of denoising steps (between 1 and 50). Higher values give better quality but take longer.",
          "default": 30
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt to guide generation away from certain attributes."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "seed",
        "guidance_scale",
        "num_inference_steps",
        "negative_prompt",
        "aspect_ratio"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 6,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2/image-to-video",
    "name": "Luma Ray 2 (Image to Video)",
    "description": "Ray2 is a large-scale video generative model capable of creating realistic visuals with natural, coherent motion.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Ray2ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
          ],
          "maxLength": 5000,
          "type": "string",
          "minLength": 3,
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "21:9",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "540p",
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
          "default": "540p"
        },
        "loop": {
          "title": "Loop",
          "type": "boolean",
          "description": "Whether the video should loop (end of video is blended with the beginning)",
          "default": false
        },
        "duration": {
          "enum": [
            "5s",
            "9s"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video",
          "default": "5s"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "Initial image to start the video from. Can be used together with end_image_url."
        },
        "end_image_url": {
          "title": "End Image Url",
          "type": "string",
          "description": "Final image to end the video with. Can be used together with image_url."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "end_image_url",
        "aspect_ratio",
        "loop",
        "resolution",
        "duration"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/hunyuan-video-img2vid-lora",
    "name": "Hunyuan Video Image-to-Video LoRA Inference",
    "description": "Image to Video for the Hunyuan Video model using a custom trained LoRA.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video.webp?v=1",
    "tags": [
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Input",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A low angle shot of a man walking down a street, illuminated by the neon signs of the bars around him"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for generating the video."
        },
        "image_url": {
          "examples": [
            "https://d3phaj0sisr2ct.cloudfront.net/research/eugene.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL to the image to generate the video from. The image must be 960x544 or it will get cropped and resized to that size."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "seed"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/pixverse/v3.5/image-to-video/fast",
    "name": "PixVerse v3.5: Image to Video Fast",
    "description": "Generate high quality video clips from text and image prompts quickly using PixVerse v3.5 Fast",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
          ],
          "description": "URL of the image to use as the first frame",
          "type": "string",
          "title": "Image Url"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "negative_prompt",
        "style",
        "seed",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 2,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/pixverse/v3.5/image-to-video",
    "name": "PixVerse v3.5: Image to Video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v3.5",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
          ],
          "description": "URL of the image to use as the first frame",
          "type": "string",
          "title": "Image Url"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 1,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/minimax/video-01-subject-reference",
    "name": "MiniMax (Hailuo AI) Video 01 Subject Reference",
    "description": "Generate video clips maintaining consistent, realistic facial features and identity across dynamic video content",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/minimax-video-01-subject-reference.webp",
    "tags": [
      "subject",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SubjectReferenceRequest",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000
        },
        "subject_reference_image_url": {
          "examples": [
            "https://fal.media/files/tiger/s2xnjhLpjM6L8ISxlDCAw.png"
          ],
          "title": "Subject Reference Image Url",
          "type": "string",
          "description": "URL of the subject reference image to use for consistent subject appearance"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "subject_reference_image_url",
        "prompt_optimizer"
      ],
      "required": [
        "prompt",
        "subject_reference_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/standard/image-to-video",
    "name": "Kling 1.6",
    "description": "Generate video clips from your images using Kling 1.6 (std)",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Snowflakes fall as a car moves forward along the road."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/kling/kling_input.jpeg"
          ],
          "title": "Image Url",
          "type": "string"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 5,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/sadtalker/reference",
    "name": "Sad Talker",
    "description": "Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/sadtalker.jpeg",
    "tags": [
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SadTalkerRefVideoInput",
      "type": "object",
      "properties": {
        "pose_style": {
          "minimum": 0,
          "maximum": 45,
          "type": "integer",
          "title": "Pose Style",
          "description": "The style of the pose",
          "default": 0
        },
        "source_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/sadtalker/anime_girl.png"
          ],
          "title": "Source Image Url",
          "type": "string",
          "description": "URL of the source image"
        },
        "driven_audio_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/sadtalker/deyu.wav"
          ],
          "title": "Driven Audio Url",
          "type": "string",
          "description": "URL of the driven audio"
        },
        "reference_pose_video_url": {
          "examples": [
            "https://github.com/OpenTalker/SadTalker/raw/main/examples/ref_video/WDA_AlexandriaOcasioCortez_000.mp4"
          ],
          "title": "Reference Pose Video Url",
          "type": "string",
          "description": "URL of the reference video"
        },
        "face_enhancer": {
          "enum": [
            "gfpgan"
          ],
          "title": "Face Enhancer",
          "type": "string",
          "description": "The type of face enhancer to use",
          "examples": [
            null
          ]
        },
        "face_model_resolution": {
          "enum": [
            "256",
            "512"
          ],
          "title": "Face Model Resolution",
          "type": "string",
          "description": "The resolution of the face model",
          "default": "256"
        },
        "expression_scale": {
          "description": "The scale of the expression",
          "type": "number",
          "minimum": 0,
          "maximum": 3,
          "title": "Expression Scale",
          "multipleOf": 0.1,
          "default": 1
        },
        "still_mode": {
          "title": "Still Mode",
          "type": "boolean",
          "description": "Whether to use still mode. Fewer head motion, works with preprocess `full`.",
          "default": false
        },
        "preprocess": {
          "enum": [
            "crop",
            "extcrop",
            "resize",
            "full",
            "extfull"
          ],
          "title": "Preprocess",
          "type": "string",
          "description": "The type of preprocessing to use",
          "default": "crop"
        }
      },
      "x-fal-order-properties": [
        "source_image_url",
        "driven_audio_url",
        "reference_pose_video_url",
        "pose_style",
        "face_model_resolution",
        "expression_scale",
        "face_enhancer",
        "still_mode",
        "preprocess"
      ],
      "required": [
        "source_image_url",
        "driven_audio_url",
        "reference_pose_video_url"
      ]
    }
  },
  {
    "id": "fal-ai/minimax/video-01-live/image-to-video",
    "name": "MiniMax (Hailuo AI) Video 01 Live",
    "description": "Generate video clips from your images using MiniMax Video model",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_016.jpg",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/elephant/8kkhB12hEZI2kkbU8pZPA_test.jpeg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of the image to use as the first frame"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "prompt_optimizer"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 10,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/ltx-video/image-to-video",
    "name": "LTX Video (preview)",
    "description": "Generate videos from images using LTX Video",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/model_tests/cogvideox/panda.gif.gif",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A lone astronaut in a white spacesuit with gold-tinted visor drifts weightlessly through a sleek, cylindrical corridor of a spaceship. Their movements are slow and graceful as they gently push off the metallic walls with their gloved hands, rotating slightly as they float from right to left across the frame. The corridor features brushed aluminum panels with blue LED strips running along the ceiling, casting a cool glow on the astronaut's suit. Various cables, pipes, and control panels line the walls. The camera follows the astronaut's movement in a handheld style, slightly swaying and adjusting focus, maintaining a medium shot that captures both the astronaut and the corridor's depth. Small particles of dust catch the light as they float in the zero-gravity environment. The scene appears cinematic, with lens flares occasionally reflecting off the metallic surfaces and the astronaut's visor."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "guidance_scale": {
          "maximum": 10,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The guidance scale to use.",
          "exclusiveMinimum": 1,
          "default": 3
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "The seed to use for random number generation."
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Number of Inference Steps",
          "description": "The number of inference steps to take.",
          "default": 30
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to generate the video from.",
          "default": "low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/kangaroo/4OePu2ifG7SKxTM__TQrQ_72929fec9fb74790bb8c8b760450c9b9.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL of the image to generate the video from."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "seed",
        "num_inference_steps",
        "guidance_scale",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/cogvideox-5b/image-to-video",
    "name": "CogVideoX-5B",
    "description": "Generate videos from images and prompts using CogVideoX-5B",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/model_tests/cogvideox/panda.gif.gif",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A low angle shot of a man walking down a street, illuminated by the neon signs of the bars around him"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "use_rife": {
          "title": "Use Rife",
          "type": "boolean",
          "description": "Use RIFE for video interpolation",
          "default": true
        },
        "image_url": {
          "examples": [
            "https://d3phaj0sisr2ct.cloudfront.net/research/eugene.jpg"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "The URL to the image to generate the video from."
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. We currently support one lora.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "video_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Video Size",
          "description": "The size of the generated video.",
          "default": {
            "height": 480,
            "width": 720
          }
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
          "maximum": 20,
          "default": 7
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        "
        },
        "export_fps": {
          "minimum": 4,
          "title": "Export Fps",
          "type": "integer",
          "description": "The target FPS of the video",
          "maximum": 32,
          "default": 16
        },
        "negative_prompt": {
          "examples": [
            "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to generate video from",
          "default": ""
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to perform.",
          "maximum": 50,
          "default": 50
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "video_size",
        "negative_prompt",
        "loras",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "use_rife",
        "export_fps",
        "image_url"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 4,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/kling-video/v1/pro/image-to-video",
    "name": "Kling 1.0",
    "description": "Generate video clips from your images using Kling 1.0 (pro)",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/GoSnDOnX0Tea08N7iI7oM.jpeg",
    "tags": [
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": null,
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/kling-video/v1.5/pro/image-to-video",
    "name": "Kling 1.5",
    "description": "Generate video clips from your images using Kling 1.5 (pro)",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "KlingV15ProImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Snowflakes fall as a car moves along the road."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "tail_image_url": {
          "description": "URL of the image to be used for the end of the video",
          "type": "string",
          "title": "Tail Image Url"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/kling/kling_input.jpeg"
          ],
          "title": "Image Url",
          "type": "string"
        },
        "static_mask_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/kling/new_static_mask.png"
          ],
          "description": "URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)",
          "type": "string",
          "title": "Static Mask Url"
        },
        "dynamic_masks": {
          "description": "List of dynamic masks",
          "type": "array",
          "title": "Dynamic Masks",
          "items": {
            "$ref": "#/components/schemas/DynamicMask"
          }
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "aspect_ratio",
        "tail_image_url",
        "negative_prompt",
        "cfg_scale",
        "static_mask_url",
        "dynamic_masks"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/kling-video/v1/standard/image-to-video",
    "name": "Kling 1.0",
    "description": "Generate video clips from your images using Kling 1.0",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/GoSnDOnX0Tea08N7iI7oM.jpeg",
    "tags": [
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "V1ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Snowflakes fall as a car moves forward along the road."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt",
          "description": "The prompt for the video"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "tail_image_url": {
          "description": "URL of the image to be used for the end of the video",
          "type": "string",
          "title": "Tail Image Url"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/kling/kling_input.jpeg"
          ],
          "description": "URL of the image to be used for the video",
          "type": "string",
          "title": "Image Url"
        },
        "static_mask_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/kling/new_static_mask.png"
          ],
          "description": "URL of the image for Static Brush Application Area (Mask image created by users using the motion brush)",
          "type": "string",
          "title": "Static Mask Url"
        },
        "dynamic_masks": {
          "description": "List of dynamic masks",
          "type": "array",
          "title": "Dynamic Masks",
          "items": {
            "$ref": "#/components/schemas/DynamicMask"
          }
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "duration",
        "negative_prompt",
        "cfg_scale",
        "tail_image_url",
        "static_mask_url",
        "dynamic_masks"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits_per_5sec": 5,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/stable-video",
    "name": "High Quality Stable Video Diffusion",
    "description": "Generate short video clips from your images using SVD v1.1",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/fast-svd.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageInput",
      "type": "object",
      "properties": {
        "motion_bucket_id": {
          "minimum": 1,
          "maximum": 255,
          "type": "integer",
          "title": "Motion Bucket Id",
          "description": "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
          "default": 127
        },
        "fps": {
          "minimum": 10,
          "maximum": 100,
          "type": "integer",
          "title": "Fps",
          "description": "The frames per second of the generated video.",
          "default": 25
        },
        "cond_aug": {
          "minimum": 0,
          "maximum": 10,
          "type": "number",
          "title": "Cond Aug",
          "description": "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
          "default": 0.02
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/svd/rocket.png",
            "https://storage.googleapis.com/falserverless/model_tests/svd/mustang.png",
            "https://storage.googleapis.com/falserverless/model_tests/svd/ship.png",
            "https://storage.googleapis.com/falserverless/model_tests/svd/rocket2.png"
          ],
          "title": "Image Url",
          "type": "string",
          "minLength": 1,
          "description": "The URL of the image to use as a starting point for the generation."
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "seed",
        "motion_bucket_id",
        "cond_aug",
        "fps"
      ],
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/amt-interpolation/frame-interpolation",
    "name": "AMT Frame Interpolation",
    "description": "Interpolate between image frames",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/amt-interpolation.webp",
    "tags": [
      "interpolation",
      "editing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AMTFrameInterpolationInput",
      "type": "object",
      "properties": {
        "frames": {
          "examples": [
            [
              {
                "url": "https://storage.googleapis.com/falserverless/model_tests/amt-interpolation/start.png"
              },
              {
                "url": "https://storage.googleapis.com/falserverless/model_tests/amt-interpolation/end.png"
              }
            ]
          ],
          "title": "Frames",
          "type": "array",
          "description": "Frames to interpolate",
          "items": {
            "$ref": "#/components/schemas/Frame"
          }
        },
        "recursive_interpolation_passes": {
          "max": 10,
          "title": "Recursive Interpolation Passes",
          "type": "integer",
          "description": "Number of recursive interpolation passes",
          "min": 1,
          "default": 4
        },
        "output_fps": {
          "max": 60,
          "title": "Output FPS",
          "type": "integer",
          "description": "Output frames per second",
          "min": 1,
          "default": 24
        }
      },
      "x-fal-order-properties": [
        "frames",
        "output_fps",
        "recursive_interpolation_passes"
      ],
      "required": [
        "frames"
      ]
    }
  },
  {
    "id": "fal-ai/live-portrait",
    "name": "Live Portrait",
    "description": "Transfer expression from a video to a portrait.",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/model_tests/live-portrait/XKEmk3mAzGHUjK3qqH-UL.jpeg",
    "tags": [
      "expression",
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LivePortraitInput",
      "type": "object",
      "properties": {
        "smile": {
          "minimum": -2,
          "maximum": 2,
          "type": "number",
          "description": "Amount to smile",
          "title": "Smile",
          "default": 0
        },
        "video_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/live-portrait/liveportrait-example.mp4"
          ],
          "description": "URL of the video to drive the lip syncing.",
          "type": "string",
          "title": "Video Url"
        },
        "eyebrow": {
          "minimum": -30,
          "maximum": 30,
          "type": "number",
          "description": "Amount to raise or lower eyebrows",
          "title": "Eyebrow",
          "default": 0
        },
        "flag_stitching": {
          "description": "Whether to enable stitching. Recommended to set to True.",
          "type": "boolean",
          "title": "Flag Stitching",
          "default": true
        },
        "blink": {
          "minimum": -30,
          "maximum": 30,
          "type": "number",
          "description": "Amount to blink the eyes",
          "title": "Blink",
          "default": 0
        },
        "rotate_pitch": {
          "minimum": -45,
          "maximum": 45,
          "type": "number",
          "description": "Amount to rotate the face in pitch",
          "title": "Rotate Pitch",
          "default": 0
        },
        "wink": {
          "minimum": 0,
          "maximum": 25,
          "type": "number",
          "description": "Amount to wink",
          "title": "Wink",
          "default": 0
        },
        "scale": {
          "description": "Scaling factor for the face crop.",
          "type": "number",
          "title": "Scale",
          "default": 2.3
        },
        "eee": {
          "minimum": -40,
          "maximum": 40,
          "type": "number",
          "description": "Amount to shape mouth in 'eee' position",
          "title": "Eee",
          "default": 0
        },
        "flag_pasteback": {
          "description": "Whether to paste-back/stitch the animated face cropping from the face-cropping space to the original image space.",
          "type": "boolean",
          "title": "Flag Pasteback",
          "default": true
        },
        "pupil_y": {
          "minimum": -45,
          "maximum": 45,
          "type": "number",
          "description": "Amount to move pupils vertically",
          "title": "Pupil Y",
          "default": 0
        },
        "rotate_yaw": {
          "minimum": -45,
          "maximum": 45,
          "type": "number",
          "description": "Amount to rotate the face in yaw",
          "title": "Rotate Yaw",
          "default": 0
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/live-portrait/XKEmk3mAzGHUjK3qqH-UL.jpeg"
          ],
          "description": "URL of the image to be animated",
          "type": "string",
          "title": "Image Url"
        },
        "woo": {
          "minimum": -100,
          "maximum": 100,
          "type": "number",
          "description": "Amount to shape mouth in 'woo' position",
          "title": "Woo",
          "default": 0
        },
        "aaa": {
          "minimum": -200,
          "maximum": 200,
          "type": "number",
          "description": "Amount to open mouth in 'aaa' shape",
          "title": "Aaa",
          "default": 0
        },
        "flag_do_rot": {
          "description": "Whether to conduct the rotation when flag_do_crop is True.",
          "type": "boolean",
          "title": "Flag Do Rot",
          "default": true
        },
        "flag_relative": {
          "description": "Whether to use relative motion.",
          "type": "boolean",
          "title": "Flag Relative",
          "default": true
        },
        "flag_eye_retargeting": {
          "description": "Whether to enable eye retargeting.",
          "type": "boolean",
          "title": "Flag Eye Retargeting",
          "default": false
        },
        "flag_lip_zero": {
          "description": "Whether to set the lip to closed state before animation. Only takes effect when flag_eye_retargeting and flag_lip_retargeting are False.",
          "type": "boolean",
          "title": "Flag Lip Zero",
          "default": true
        },
        "batch_size": {
          "description": "Batch size for the model. The larger the batch size, the faster the model will run, but the more memory it will consume.",
          "type": "integer",
          "title": "Batch Size",
          "default": 32
        },
        "rotate_roll": {
          "minimum": -45,
          "maximum": 45,
          "type": "number",
          "description": "Amount to rotate the face in roll",
          "title": "Rotate Roll",
          "default": 0
        },
        "pupil_x": {
          "minimum": -45,
          "maximum": 45,
          "type": "number",
          "description": "Amount to move pupils horizontally",
          "title": "Pupil X",
          "default": 0
        },
        "vy_ratio": {
          "description": "Vertical offset ratio for face crop. Positive values move up, negative values move down.",
          "type": "number",
          "title": "Vy Ratio",
          "default": -0.125
        },
        "dsize": {
          "description": "Size of the output image.",
          "type": "integer",
          "title": "Dsize",
          "default": 512
        },
        "enable_safety_checker": {
          "description": "\n        Whether to enable the safety checker. If enabled, the model will check if the input image contains a face before processing it.\n        The safety checker will process the input image\n        ",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": false
        },
        "vx_ratio": {
          "description": "Horizontal offset ratio for face crop.",
          "type": "number",
          "title": "Vx Ratio",
          "default": 0
        },
        "flag_lip_retargeting": {
          "description": "Whether to enable lip retargeting.",
          "type": "boolean",
          "title": "Flag Lip Retargeting",
          "default": false
        },
        "flag_do_crop": {
          "description": "Whether to crop the source portrait to the face-cropping space.",
          "type": "boolean",
          "title": "Flag Do Crop",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "video_url",
        "image_url",
        "blink",
        "eyebrow",
        "wink",
        "pupil_x",
        "pupil_y",
        "aaa",
        "eee",
        "woo",
        "smile",
        "flag_lip_zero",
        "rotate_pitch",
        "rotate_yaw",
        "rotate_roll",
        "flag_eye_retargeting",
        "flag_lip_retargeting",
        "flag_stitching",
        "flag_relative",
        "flag_pasteback",
        "flag_do_crop",
        "flag_do_rot",
        "dsize",
        "scale",
        "vx_ratio",
        "vy_ratio",
        "batch_size",
        "enable_safety_checker"
      ],
      "required": [
        "video_url",
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/luma-dream-machine/image-to-video",
    "name": "Luma Dream Machine",
    "description": "Generate video clips from your images using Luma Dream Machine v1.5",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/JtiRw34MZ1GkgxRnH52Cs.png",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Low-angle shot of a majestic tiger prowling through a snowy landscape, leaving paw prints on the white blanket"
          ],
          "maxLength": 5000,
          "type": "string",
          "minLength": 3,
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "21:9",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "loop": {
          "title": "Loop",
          "type": "boolean",
          "description": "Whether the video should loop (end of video is blended with the beginning)",
          "default": false
        },
        "end_image_url": {
          "title": "End Image Url",
          "type": "string",
          "description": "An image to blend the end of the video with"
        },
        "image_url": {
          "examples": [
            "https://fal.media/files/koala/1oLY4Bjp4XdGBBTSsrGlE.jpeg"
          ],
          "title": "Image Url",
          "type": "string"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "end_image_url",
        "aspect_ratio",
        "loop"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "credits": 10,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/musetalk",
    "name": "MuseTalk",
    "description": "MuseTalk is a real-time high quality audio-driven lip-syncing model. Use MuseTalk to animate a face with your own audio.",
    "category": "image-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/wgGNp3M_u50xIisUZ_Wm8.png",
    "tags": [
      "animation",
      "lip sync",
      "real-time"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MuseTalkInput",
      "type": "object",
      "properties": {
        "source_video_url": {
          "examples": [
            "https://raw.githubusercontent.com/TMElyralab/MuseTalk/main/data/video/sun.mp4"
          ],
          "title": "Source Video Url",
          "type": "string",
          "description": "URL of the source video"
        },
        "audio_url": {
          "examples": [
            "https://raw.githubusercontent.com/TMElyralab/MuseTalk/main/data/audio/sun.wav"
          ],
          "title": "Audio Url",
          "type": "string",
          "description": "URL of the audio"
        }
      },
      "x-fal-order-properties": [
        "source_video_url",
        "audio_url"
      ],
      "required": [
        "source_video_url",
        "audio_url"
      ]
    }
  },
  {
    "id": "fal-ai/sadtalker",
    "name": "Sad Talker",
    "description": "Learning Realistic 3D Motion Coefficients for Stylized Audio-Driven Single Image Talking Face Animation",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/sadtalker.jpeg",
    "tags": [
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SadTalkerInput",
      "type": "object",
      "properties": {
        "pose_style": {
          "minimum": 0,
          "maximum": 45,
          "type": "integer",
          "title": "Pose Style",
          "description": "The style of the pose",
          "default": 0
        },
        "source_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/sadtalker/anime_girl.png"
          ],
          "title": "Source Image Url",
          "type": "string",
          "description": "URL of the source image"
        },
        "driven_audio_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/sadtalker/deyu.wav"
          ],
          "title": "Driven Audio Url",
          "type": "string",
          "description": "URL of the driven audio"
        },
        "face_enhancer": {
          "enum": [
            "gfpgan"
          ],
          "title": "Face Enhancer",
          "type": "string",
          "description": "The type of face enhancer to use",
          "examples": [
            null
          ]
        },
        "face_model_resolution": {
          "enum": [
            "256",
            "512"
          ],
          "title": "Face Model Resolution",
          "type": "string",
          "description": "The resolution of the face model",
          "default": "256"
        },
        "expression_scale": {
          "description": "The scale of the expression",
          "type": "number",
          "minimum": 0,
          "maximum": 3,
          "title": "Expression Scale",
          "multipleOf": 0.1,
          "default": 1
        },
        "still_mode": {
          "title": "Still Mode",
          "type": "boolean",
          "description": "Whether to use still mode. Fewer head motion, works with preprocess `full`.",
          "default": false
        },
        "preprocess": {
          "enum": [
            "crop",
            "extcrop",
            "resize",
            "full",
            "extfull"
          ],
          "title": "Preprocess",
          "type": "string",
          "description": "The type of preprocessing to use",
          "default": "crop"
        }
      },
      "x-fal-order-properties": [
        "source_image_url",
        "driven_audio_url",
        "pose_style",
        "face_model_resolution",
        "expression_scale",
        "face_enhancer",
        "still_mode",
        "preprocess"
      ],
      "required": [
        "source_image_url",
        "driven_audio_url"
      ]
    }
  },
  {
    "id": "fal-ai/fast-svd-lcm",
    "name": "Stable Video Diffusion Turbo",
    "description": "Generate short video clips from your images using SVD v1.1 at Lightning Speed",
    "category": "image-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/fast-svd-turbo.webp",
    "tags": [
      "turbo"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastSVDImageInput",
      "type": "object",
      "properties": {
        "motion_bucket_id": {
          "minimum": 1,
          "maximum": 255,
          "type": "integer",
          "title": "Motion Bucket Id",
          "description": "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
          "default": 127
        },
        "fps": {
          "minimum": 1,
          "maximum": 25,
          "type": "integer",
          "title": "Fps",
          "description": "\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ",
          "default": 10
        },
        "steps": {
          "minimum": 1,
          "maximum": 20,
          "type": "integer",
          "title": "Steps",
          "description": "\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ",
          "default": 4
        },
        "cond_aug": {
          "minimum": 0,
          "maximum": 10,
          "type": "number",
          "title": "Cond Aug",
          "description": "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
          "default": 0.02
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/svd/rocket.png",
            "https://storage.googleapis.com/falserverless/model_tests/svd/mustang.png",
            "https://storage.googleapis.com/falserverless/model_tests/svd/ship.png",
            "https://storage.googleapis.com/falserverless/model_tests/svd/rocket2.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The URL of the image to use as a starting point for the generation."
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "motion_bucket_id",
        "cond_aug",
        "seed",
        "steps",
        "fps"
      ],
      "required": [
        "image_url"
      ]
    }
  },
  {
    "id": "fal-ai/flux-pro/v1.1-ultra",
    "name": "FLUX1.1 [pro] ultra",
    "description": "FLUX1.1 [pro] ultra is the newest version of FLUX1.1 [pro], maintaining professional-grade image quality while delivering up to 2K resolution with improved photo realism.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/flux-pro-v1-1-ultra.webp",
    "tags": [
      "high-res",
      "realism"
    ],
    "highlighted": true,
    "pinned": true,
    "input_schema": {
      "title": "FluxProUltraTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "enhance_prompt": {
          "title": "Enhance Prompt",
          "type": "boolean",
          "description": "Whether to enhance the prompt for better results.",
          "default": false
        },
        "aspect_ratio": {
          "anyOf": [
            {
              "enum": [
                "21:9",
                "16:9",
                "4:3",
                "3:2",
                "1:1",
                "2:3",
                "3:4",
                "9:16",
                "9:21"
              ],
              "type": "string"
            },
            {
              "type": "string"
            }
          ],
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image.",
          "default": "16:9"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "title": "Image URL",
          "type": "string",
          "description": "The image URL to generate an image from."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6"
          ],
          "title": "Safety Tolerance",
          "type": "string",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "default": "2"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "image_prompt_strength": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Image Prompt Strength",
          "description": "The strength of the image prompt, between 0 and 1.",
          "default": 0.1
        },
        "raw": {
          "title": "Raw",
          "type": "boolean",
          "description": "Generate less processed, more natural-looking images.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "safety_tolerance",
        "enhance_prompt",
        "image_url",
        "image_prompt_strength",
        "aspect_ratio",
        "raw"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/recraft/v3/text-to-image",
    "name": "Recraft V3",
    "description": "Recraft V3 is a text-to-image model with the ability to generate long texts, vector art, images in brand style, and much more. As of today, it is SOTA in image generation, proven by Hugging Face's industry-leading Text-to-Image Benchmark by Artificial Analysis.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/recraft-v3.webp",
    "tags": [
      "vector",
      "typography",
      "style"
    ],
    "highlighted": false,
    "pinned": true,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "a red panda eating a bamboo in front of a poster that says \"recraft V3 now available at fal\""
          ],
          "maxLength": 1000,
          "type": "string",
          "title": "Prompt",
          "minLength": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "default": "square_hd"
        },
        "style": {
          "enum": [
            "any",
            "realistic_image",
            "digital_illustration",
            "vector_illustration",
            "realistic_image/b_and_w",
            "realistic_image/hard_flash",
            "realistic_image/hdr",
            "realistic_image/natural_light",
            "realistic_image/studio_portrait",
            "realistic_image/enterprise",
            "realistic_image/motion_blur",
            "realistic_image/evening_light",
            "realistic_image/faded_nostalgia",
            "realistic_image/forest_life",
            "realistic_image/mystic_naturalism",
            "realistic_image/natural_tones",
            "realistic_image/organic_calm",
            "realistic_image/real_life_glow",
            "realistic_image/retro_realism",
            "realistic_image/retro_snapshot",
            "realistic_image/urban_drama",
            "realistic_image/village_realism",
            "realistic_image/warm_folk",
            "digital_illustration/pixel_art",
            "digital_illustration/hand_drawn",
            "digital_illustration/grain",
            "digital_illustration/infantile_sketch",
            "digital_illustration/2d_art_poster",
            "digital_illustration/handmade_3d",
            "digital_illustration/hand_drawn_outline",
            "digital_illustration/engraving_color",
            "digital_illustration/2d_art_poster_2",
            "digital_illustration/antiquarian",
            "digital_illustration/bold_fantasy",
            "digital_illustration/child_book",
            "digital_illustration/child_books",
            "digital_illustration/cover",
            "digital_illustration/crosshatch",
            "digital_illustration/digital_engraving",
            "digital_illustration/expressionism",
            "digital_illustration/freehand_details",
            "digital_illustration/grain_20",
            "digital_illustration/graphic_intensity",
            "digital_illustration/hard_comics",
            "digital_illustration/long_shadow",
            "digital_illustration/modern_folk",
            "digital_illustration/multicolor",
            "digital_illustration/neon_calm",
            "digital_illustration/noir",
            "digital_illustration/nostalgic_pastel",
            "digital_illustration/outline_details",
            "digital_illustration/pastel_gradient",
            "digital_illustration/pastel_sketch",
            "digital_illustration/pop_art",
            "digital_illustration/pop_renaissance",
            "digital_illustration/street_art",
            "digital_illustration/tablet_sketch",
            "digital_illustration/urban_glow",
            "digital_illustration/urban_sketching",
            "digital_illustration/vanilla_dreams",
            "digital_illustration/young_adult_book",
            "digital_illustration/young_adult_book_2",
            "vector_illustration/bold_stroke",
            "vector_illustration/chemistry",
            "vector_illustration/colored_stencil",
            "vector_illustration/contour_pop_art",
            "vector_illustration/cosmics",
            "vector_illustration/cutout",
            "vector_illustration/depressive",
            "vector_illustration/editorial",
            "vector_illustration/emotional_flat",
            "vector_illustration/infographical",
            "vector_illustration/marker_outline",
            "vector_illustration/mosaic",
            "vector_illustration/naivector",
            "vector_illustration/roundish_flat",
            "vector_illustration/segmented_colors",
            "vector_illustration/sharp_contrast",
            "vector_illustration/thin",
            "vector_illustration/vector_photo",
            "vector_illustration/vivid_shapes",
            "vector_illustration/engraving",
            "vector_illustration/line_art",
            "vector_illustration/line_circuit",
            "vector_illustration/linocut"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style of the generated images. Vector images cost 2X as much.",
          "default": "realistic_image"
        },
        "colors": {
          "title": "Colors",
          "type": "array",
          "description": "An array of preferable colors",
          "items": {
            "$ref": "#/components/schemas/RGBColor"
          },
          "default": []
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "style_id": {
          "format": "uuid4",
          "title": "Style Id",
          "type": "string",
          "description": "The ID of the custom style reference (optional)"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "style",
        "colors",
        "style_id",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "bria/text-to-image/3.2",
    "name": "Bria 3.2 Text-to-Image",
    "description": "Bria\u2019s Text-to-Image model, trained exclusively on licensed data for safe and risk-free commercial use. Excels in Text-Rendering and Aesthetics.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/monkey/EZR7hDbrO6DQ_MP-BYQPt_8bb97804d8fc4f21863b457a061b5f8a.jpg",
    "tags": [
      "image generation"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "InputModel",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Oil painting of a fluffy, wide-eyed cat sitting upright, holding a small wooden sign reading \u201cFeed Me.\u201d Rich textures, dramatic brushstrokes, warm tones, and vintage charm."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Prompt for image generation."
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "2:3",
            "3:2",
            "3:4",
            "4:3",
            "4:5",
            "5:4",
            "9:16",
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9",
          "default": "1:1"
        },
        "prompt_enhancer": {
          "description": "Whether to improve the prompt.",
          "type": "boolean",
          "title": "Prompt Enhancer",
          "default": true
        },
        "sync_mode": {
          "description": "If true, returns the image directly in the response (increases latency).",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "truncate_prompt": {
          "description": "Whether to truncate the prompt.",
          "type": "boolean",
          "title": "Truncate Prompt",
          "default": true
        },
        "guidance_scale": {
          "description": "Guidance scale for text.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "title": "Guidance Scale",
          "default": 5
        },
        "num_inference_steps": {
          "description": "Number of inference steps.",
          "type": "integer",
          "minimum": 20,
          "maximum": 50,
          "title": "Num Inference Steps",
          "default": 30
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility.",
          "default": 5555
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for image generation.",
          "default": "Logo,Watermark,Ugly,Morbid,Extra fingers,Poorly drawn hands,Mutation,Blurry,Extra limbs,Gross proportions,Missing arms,Mutated hands,Long neck,Duplicate,Mutilated,Mutilated hands,Poorly drawn face,Deformed,Bad anatomy,Cloned face,Malformed limbs,Missing legs,Too many fingers"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_inference_steps",
        "seed",
        "aspect_ratio",
        "negative_prompt",
        "guidance_scale",
        "truncate_prompt",
        "prompt_enhancer",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "generations"
  },
  {
    "id": "fal-ai/imagen4/preview/fast",
    "name": "Imagen 4",
    "description": "Google\u2019s highest quality image generation model",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/wOlG7nOgvzkPiOfnMUAnD_1088439693f7466ba053cadb887f4191.jpg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Atmospheric narrative illustration depicting a young woman with dark hair styled with a single star clip, eating dumplings at a small round table in a bustling, late-night eatery reminiscent of a vintage Hong Kong diner. The style blends clean linework with textured color fields, evoking a sense of place and story. The mood is intimate contentment amidst vibrant surroundings. Soft, warm overhead lighting from unseen hanging lamps casts gentle highlights on her face and the porcelain plate of dumplings, creating soft-edged shadows on the tiled tabletop and floor. The background features detailed elements like wall menus with stylized illustrations, a retro wall clock, steam rising from a soup bowl, and glimpses of other patrons blurred slightly for depth. The woman, viewed from a slightly high angle, crouches slightly on her chair, intensely focused on her food, rendered with expressive linework defining her pose and features. The color palette mixes muted teal wall tiles and green chairs with pops of warm yellow in her top, pink trousers, red chili oil dish, and ambient light, creating a cozy yet lively feel. Subtle paper texture or digital grain is visible throughout. Focus is sharp on the character and her immediate table setting"
          ],
          "title": "Prompt",
          "minLength": 3,
          "type": "string",
          "description": "The text prompt to generate an image from.",
          "maxLength": 5000
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "16:9",
            "9:16",
            "4:3",
            "3:4"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image.",
          "default": "1:1"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Number of Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        }
      },
      "title": "Imagen4TextToImageFastInput",
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/imagen4/preview",
    "name": "Imagen 4",
    "description": "Google\u2019s highest quality image generation model",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode",
        "resolution"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Capture an intimate close-up bathed in warm, soft, late-afternoon sunlight filtering into a quintessential 1960s kitchen. The focal point is a charmingly designed vintage package of all-purpose flour, resting invitingly on a speckled Formica countertop. The packaging itself evokes pure nostalgia: perhaps thick, slightly textured paper in a warm cream tone, adorned with simple, bold typography (a friendly serif or script) in classic red and blue \"ALL-PURPOSE FLOUR\", featuring a delightful illustration like a stylized sheaf of wheat or a cheerful baker character. In smaller bold print at the bottom of the package: \"NET WT 5 LBS (80 OZ) 2.27kg\". Focus sharply on the package details \u2013 the slightly soft edges of the paper bag, the texture of the vintage printing, the inviting \"All-Purpose Flour\" text. Subtle hints of the 1960s kitchen frame the shot \u2013 the chrome edge of the counter gleaming softly, a blurred glimpse of a pastel yellow ceramic tile backsplash, or the corner of a vintage metal canister set just out of focus. The shallow depth of field keeps attention locked on the beautifully designed package, creating an aesthetic rich in warmth, authenticity, and nostalgic appeal."
          ],
          "title": "Prompt",
          "minLength": 3,
          "type": "string",
          "description": "The text prompt to generate an image from.",
          "maxLength": 5000
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "16:9",
            "9:16",
            "4:3",
            "3:4"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image.",
          "default": "1:1"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Number of Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "resolution": {
          "enum": [
            "1K",
            "2K"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated image.",
          "default": "1K"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        }
      },
      "title": "Imagen4TextToImageInput",
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/hidream-i1-full",
    "name": "Hidream I1 Full",
    "description": "HiDream-I1 full is a new open-source image generative foundation model with 17B parameters that achieves state-of-the-art image generation quality within seconds.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/monkey/HzdkkAoX8-PqrYZUV0zOW_1efb1b99d0e84ce78dd35e8edc69fe09.jpg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "a cat holding a skateboard which has 'fal' written on it in red spray paint"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": {
            "height": 1024,
            "width": 1024
          }
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "A list of LoRAs to apply to the model. Each LoRA specifies its path, scale, and optional weight name.",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 50
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "loras"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/hidream-i1-dev",
    "name": "Hidream I1 Dev",
    "description": "HiDream-I1 dev is a new open-source image generative foundation model with 17B parameters that achieves state-of-the-art image generation quality within seconds.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training.jpg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "DevInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "a cat holding a skateboard which has 'fal' written on it in red spray paint"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": {
            "height": 1024,
            "width": 1024
          }
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/hidream-i1-fast",
    "name": "Hidream I1 Fast",
    "description": "HiDream-I1 fast is a new open-source image generative foundation model with 17B parameters that achieves state-of-the-art image generation quality within 16 steps.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/zebra/Ua1DJkXRU7nz46GKt6x5R_7b333b5e26bd413aa5d65d1959878828.jpg",
    "tags": [
      ""
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "FastInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "a cat holding a skateboard which has 'fal' written on it in red spray paint"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": {
            "height": 1024,
            "width": 1024
          }
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 16
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux/dev",
    "name": "FLUX.1 [dev]",
    "description": "FLUX.1 [dev] is a 12 billion parameter flow transformer that generates high-quality images from text. It is suitable for personal and commercial use.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "BaseInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "none"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 3.5
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/ideogram/v2",
    "name": "Ideogram V2",
    "description": "Generate high-quality images, posters, and logos with Ideogram V2. Features exceptional typography handling and realistic outputs optimized for commercial and creative use.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/monkey/8WNQdDJ1eYpnl12jwhCjT_c9879f96533a47ae82e07946a67b0c8c.jpg",
    "tags": [
      "realism",
      "typography"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A comic style illustration of a skeleton sitting on a toilet in a bathroom. The bathroom has a Halloween decoration with a pumpkin jack-o-lantern and bats flying around. There is a text above the skeleton that says \"Just Waiting for Halloween with Ideogram 2.0 at fal.ai\""
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "10:16",
            "16:10",
            "9:16",
            "16:9",
            "4:3",
            "3:4",
            "1:1",
            "1:3",
            "3:1",
            "3:2",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image",
          "default": "1:1"
        },
        "style": {
          "enum": [
            "auto",
            "general",
            "realistic",
            "design",
            "render_3D",
            "anime"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style of the generated image",
          "default": "auto"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt with MagicPrompt functionality.",
          "default": true
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for the random number generator"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "A negative prompt to avoid in the generated image",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "expand_prompt",
        "seed",
        "style",
        "sync_mode",
        "negative_prompt"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 2,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/stable-diffusion-v35-large",
    "name": "Stable Diffusion 3.5 Large",
    "description": "Stable Diffusion 3.5 Large is a Multimodal Diffusion Transformer (MMDiT) text-to-image model that features improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/zebra/Bi6nsyNxslnu2SfI3jtkZ_e52ae7331ca94401bce20e695e3838a8.jpg",
    "tags": [
      "diffusion",
      "typography",
      "style"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A dreamlike Japanese garden in perpetual twilight, bathed in bioluminescent cherry blossoms that emit a soft pink-purple glow. Floating paper lanterns drift lazily through the scene, their warm light creating dancing reflections in a mirror-like koi pond. Ethereal mist weaves between ancient stone pathways lined with glowing mushrooms in pastel blues and purples. A traditional wooden bridge arches gracefully over the water, dusted with fallen petals that sparkle like stardust. The scene is captured through a cinematic lens with perfect bokeh, creating an otherworldly atmosphere. In the background, a crescent moon hangs impossibly large in the sky, surrounded by a sea of stars and auroral wisps in teal and violet. Crystal formations emerge from the ground, refracting the ambient light into rainbow prisms. The entire composition follows the golden ratio, with moody film-like color grading reminiscent of Studio Ghibli, enhanced by volumetric god rays filtering through the luminous foliage. 8K resolution, masterful photography, hyperdetailed, magical realism."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. Defaults to landscape_4_3 if no controlnet has been passed, otherwise defaults to the size of the controlnet conditioning image."
        },
        "controlnet": {
          "title": "Controlnet",
          "description": "\n            ControlNet for inference.\n        ",
          "allOf": [
            {
              "$ref": "#/components/schemas/ControlNet"
            }
          ]
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "ip_adapter": {
          "title": "Ip Adapter",
          "description": "\n            IP-Adapter to use during inference.\n        ",
          "allOf": [
            {
              "$ref": "#/components/schemas/IPAdapter"
            }
          ]
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "controlnet",
        "image_size",
        "loras",
        "ip_adapter"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-general",
    "name": "FLUX.1 [dev] with Controlnets and Loras",
    "description": "A versatile endpoint for the FLUX.1 [dev] model that supports multiple AI extensions including LoRA, ControlNet conditioning, and IP-Adapter integration, enabling comprehensive control over image generation through various guidance methods.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/rabbit/SW4VnooC-y1J5oHp72c35_ef2d274c84d644769fec449d83da838f.jpg",
    "tags": [
      "lora",
      "controlnet",
      "ip-adapter"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "nag_end": {
          "title": "Proportion of steps to apply NAG",
          "type": "number",
          "maximum": 1,
          "description": "\n            The proportion of steps to apply NAG. After the specified proportion\n            of steps has been iterated, the remaining steps will use original\n            attention processors in FLUX.\n        ",
          "exclusiveMinimum": 0,
          "default": 0.25
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        "control_loras": {
          "description": "\n            The LoRAs to use for the image generation which use a control image. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/ControlLoraWeight"
          },
          "examples": [],
          "title": "Control Loras",
          "default": []
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "scheduler": {
          "enum": [
            "euler",
            "dpmpp_2m"
          ],
          "title": "Scheduler",
          "type": "string",
          "description": "Scheduler for the denoising process.",
          "default": "euler"
        },
        "easycontrols": {
          "title": "Easycontrols",
          "type": "array",
          "description": "\n        EasyControl Inputs to use for image generation.\n        ",
          "items": {
            "$ref": "#/components/schemas/EasyControlWeight"
          },
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "maximum": 20,
          "default": 3.5
        },
        "real_cfg_scale": {
          "minimum": 0,
          "title": "Real CFG scale",
          "type": "number",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "maximum": 5,
          "default": 3.5
        },
        "use_cfg_zero": {
          "title": "Use CFG-Zero-Init",
          "type": "boolean",
          "description": "\n            Uses CFG-zero init sampling as in https://arxiv.org/abs/2503.18886.\n        ",
          "default": false
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "reference_strength": {
          "minimum": -3,
          "title": "Reference Strength",
          "type": "number",
          "description": "Strength of reference_only generation. Only used if a reference image is provided.",
          "maximum": 3,
          "default": 0.65
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "sigma_schedule": {
          "enum": [
            "sgm_uniform"
          ],
          "title": "Sigma Schedule",
          "type": "string",
          "description": "Sigmas schedule for the denoising process."
        },
        "reference_end": {
          "minimum": 0,
          "title": "Reference End",
          "type": "number",
          "description": "\n            The percentage of the total timesteps when the reference guidance is to be ended.\n        ",
          "maximum": 1,
          "default": 1
        },
        "fill_image": {
          "title": "Fill Image",
          "description": "Use an image input to influence the generation. Can be used to fill images in masked areas.",
          "allOf": [
            {
              "$ref": "#/components/schemas/ImageFillInput"
            }
          ]
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "nag_scale": {
          "title": "NAG scale",
          "type": "number",
          "maximum": 10,
          "description": "\n            The scale for NAG. Higher values will result in a image that is more distant\n            to the negative prompt.\n        ",
          "exclusiveMinimum": 1,
          "default": 3
        },
        "reference_image_url": {
          "title": "Reference Image Url",
          "type": "string",
          "description": "URL of Image for Reference-Only"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "controlnet_unions": {
          "title": "Controlnet Unions",
          "type": "array",
          "description": "\n            The controlnet unions to use for the image generation. Only one controlnet is supported at the moment.\n        ",
          "items": {
            "$ref": "#/components/schemas/ControlNetUnion"
          },
          "default": []
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            Negative prompt to steer the image generation away from unwanted features.\n            By default, we will be using NAG for processing the negative prompt.\n        ",
          "default": ""
        },
        "nag_tau": {
          "title": "NAG Tau",
          "type": "number",
          "description": "\n            The tau for NAG. Controls the normalization of the hidden state.\n            Higher values will result in a less aggressive normalization,\n            but may also lead to unexpected changes with respect to the original image.\n            Not recommended to change this value.\n        ",
          "exclusiveMinimum": 0,
          "default": 2.5
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "description": "The number of images to generate. This is always set to 1 for streaming output.",
          "maximum": 10,
          "default": 1
        },
        "use_beta_schedule": {
          "title": "Use Beta Schedule",
          "type": "boolean",
          "description": "Specifies whether beta sigmas ought to be used.",
          "default": false
        },
        "nag_alpha": {
          "title": "NAG alpha",
          "type": "number",
          "maximum": 1,
          "description": "\n            The alpha value for NAG. This value is used as a final weighting\n            factor for steering the normalized guidance (positive and negative prompts)\n            in the direction of the positive prompt. Higher values will result in less\n            steering on the normalized guidance where lower values will result in\n            considering the positive prompt guidance more.\n        ",
          "exclusiveMinimum": 0,
          "default": 0.25
        },
        "base_shift": {
          "minimum": 0.01,
          "title": "Base Shift",
          "type": "number",
          "description": "Base shift for the scheduled timesteps",
          "maximum": 5,
          "default": 0.5
        },
        "ip_adapters": {
          "title": "Ip Adapters",
          "type": "array",
          "description": "\n        IP-Adapter to use for image generation.\n        ",
          "items": {
            "$ref": "#/components/schemas/IPAdapter"
          },
          "default": []
        },
        "use_real_cfg": {
          "title": "Use Real CFG",
          "type": "boolean",
          "description": "\n            Uses classical CFG as in SD1.5, SDXL, etc. Increases generation times and price when set to be true.\n            If using XLabs IP-Adapter v1, this will be turned on!.\n        ",
          "default": false
        },
        "controlnets": {
          "title": "Controlnets",
          "type": "array",
          "description": "\n            The controlnets to use for the image generation. Only one controlnet is supported at the moment.\n        ",
          "items": {
            "$ref": "#/components/schemas/ControlNet"
          },
          "default": []
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to perform.",
          "maximum": 50,
          "default": 28
        },
        "reference_start": {
          "minimum": 0,
          "title": "Reference Start",
          "type": "number",
          "description": "\n            The percentage of the total timesteps when the reference guidance is to bestarted.\n        ",
          "maximum": 1,
          "default": 0
        },
        "max_shift": {
          "minimum": 0.01,
          "title": "Max Shift",
          "type": "number",
          "description": "Max shift for the scheduled timesteps",
          "maximum": 5,
          "default": 1.15
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "control_loras",
        "controlnets",
        "controlnet_unions",
        "ip_adapters",
        "easycontrols",
        "fill_image",
        "guidance_scale",
        "real_cfg_scale",
        "use_real_cfg",
        "use_cfg_zero",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "reference_image_url",
        "reference_strength",
        "reference_start",
        "reference_end",
        "base_shift",
        "max_shift",
        "output_format",
        "use_beta_schedule",
        "sigma_schedule",
        "scheduler",
        "negative_prompt",
        "nag_scale",
        "nag_tau",
        "nag_alpha",
        "nag_end"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-lora",
    "name": "FLUX.1 [dev] with LoRAs",
    "description": "Super fast endpoint for the FLUX.1 [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/elephant/RqIQsOY3cgQMMtCedJKlf_c2fc262516d24b94afdc17a747292710.jpg",
    "tags": [
      "lora",
      "personalization"
    ],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "description": "The number of images to generate. This is always set to 1 for streaming output.",
          "title": "Num Images",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 35,
          "type": "number",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "title": "Guidance scale (CFG)",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "description": "The number of inference steps to perform.",
          "title": "Num Inference Steps",
          "default": 28
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-2-flex",
    "name": "Flux 2 Flex",
    "description": "Text-to-image generation with FLUX.2 [flex] from Black Forest Labs. Features adjustable inference steps and guidance scale for fine-tuned control. Enhanced typography and text rendering capabilities.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/Edbo1rxDUaaHKL0YFa_rG.png",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "enable_prompt_expansion",
        "seed",
        "safety_tolerance",
        "enable_safety_checker",
        "output_format",
        "sync_mode",
        "guidance_scale",
        "num_inference_steps"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A high-quality 3D render of a cute fluffy monster eating a giant donut; the fur simulation is incredibly detailed, the donut glaze is sticky and reflective, bright daylight lighting, shallow depth of field."
          ],
          "description": "The prompt to generate an image from.",
          "type": "string",
          "title": "Prompt"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image.",
          "title": "Image Size",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "description": "The format of the generated image.",
          "type": "string",
          "title": "Output Format",
          "default": "jpeg"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5"
          ],
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "type": "string",
          "title": "Safety Tolerance",
          "default": "2"
        },
        "enable_safety_checker": {
          "description": "Whether to enable the safety checker.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "seed": {
          "description": "The seed to use for the generation.",
          "type": "integer",
          "title": "Seed"
        },
        "guidance_scale": {
          "minimum": 1.5,
          "description": "The guidance scale to use for the generation.",
          "type": "number",
          "maximum": 10,
          "title": "Guidance Scale",
          "default": 3.5
        },
        "enable_prompt_expansion": {
          "description": "Whether to expand the prompt using the model's own knowledge.",
          "type": "boolean",
          "title": "Enable Prompt Expansion",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 2,
          "description": "The number of inference steps to perform.",
          "type": "integer",
          "maximum": 50,
          "title": "Number of Inference Steps",
          "default": 28
        }
      },
      "title": "Flux2FlexTextToImageInput",
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "processed megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-2/lora/edit",
    "name": "Flux 2",
    "description": "Image-to-image editing with LoRA support for FLUX.2 [dev] from Black Forest Labs. Specialized style transfer and domain-specific modifications.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/elephant/VKrrnNPFMS43mURu9kpQT.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "guidance_scale",
        "seed",
        "num_inference_steps",
        "image_size",
        "num_images",
        "acceleration",
        "enable_prompt_expansion",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "image_urls",
        "loras"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Make this donut realistic"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "title": "Number of Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "examples": [
            {
              "height": 1152,
              "width": 2016
            }
          ],
          "title": "Image Size",
          "description": "The size of the image to generate. The width and height must be between 512 and 2048 pixels.",
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ]
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "examples": [
            "regular"
          ],
          "description": "The acceleration level to use for the image generation.",
          "default": "regular"
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 20,
          "description": "Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "default": 2.5
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "List of LoRA weights to apply (maximum 3). Each LoRA can be a URL, HuggingFace repo ID, or local path.",
          "items": {
            "$ref": "#/components/schemas/LoRAInput"
          },
          "default": []
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded for better results.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 4,
          "title": "Number of Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/example_inputs/flux2_dev_lora_edit_input.png"
            ]
          ],
          "title": "Image URLs",
          "type": "array",
          "description": "The URsL of the images for editing. A maximum of 3 images are allowed, if more are provided, only the first 3 will be used.",
          "items": {
            "type": "string"
          }
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      },
      "title": "Flux2EditImageLoRAInput",
      "required": [
        "prompt",
        "image_urls"
      ]
    }
  },
  {
    "id": "fal-ai/flux-2/lora",
    "name": "Flux 2",
    "description": "Text-to-image generation with LoRA support for FLUX.2 [dev] from Black Forest Labs. Custom style adaptation and fine-tuned model variations.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/zebra/MtjYp0klXEPXUDp2Fg4_l.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "guidance_scale",
        "seed",
        "num_inference_steps",
        "image_size",
        "num_images",
        "acceleration",
        "enable_prompt_expansion",
        "sync_mode",
        "enable_safety_checker",
        "output_format",
        "loras"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Close shot a pianist plays in a luxurious room with tall windows overlooking a rainy metropolis. Shot with a 50mm lens at a side profile angle, soft tungsten light highlighting hands moving over keys. Capture detailed reflections in polished black piano surfaces, raindrops sliding down glass, and atmospheric warm/cool lighting contrast."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "title": "Number of Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the image to generate. The width and height must be between 512 and 2048 pixels.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "examples": [
            "regular"
          ],
          "description": "The acceleration level to use for the image generation.",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "List of LoRA weights to apply (maximum 3). Each LoRA can be a URL, HuggingFace repo ID, or local path.",
          "items": {
            "$ref": "#/components/schemas/LoRAInput"
          },
          "default": []
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded for better results.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 4,
          "title": "Number of Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 20,
          "description": "Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "default": 2.5
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      },
      "title": "Flux2TextToImageLoRAInput",
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-2",
    "name": "Flux 2",
    "description": "Text-to-image generation with FLUX.2 [dev] from Black Forest Labs. Enhanced realism, crisper text generation, and native editing capabilities.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/elephant/WOYzBNhV1n5k388ve0V4Z.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "guidance_scale",
        "seed",
        "num_inference_steps",
        "image_size",
        "num_images",
        "acceleration",
        "enable_prompt_expansion",
        "sync_mode",
        "enable_safety_checker",
        "output_format"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Dutch angle close-up of a survivor in post-apocalyptic setting, dust-covered face, dramatic harsh sunlight creating deep shadows, happy expression, desaturated dystopian color palette, gritty realism"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "title": "Number of Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the image to generate. The width and height must be between 512 and 2048 pixels.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "examples": [
            "regular"
          ],
          "description": "The acceleration level to use for the image generation.",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded for better results.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 4,
          "title": "Number of Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 20,
          "description": "Guidance Scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "default": 2.5
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for the generation. If not provided, a random seed will be used."
        }
      },
      "title": "Flux2TextToImageInput",
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-2-pro",
    "name": "Flux 2 Pro",
    "description": "Image editing with FLUX.2 [pro] from Black Forest Labs. Ideal for high-quality image manipulation, style transfer, and sequential editing workflows",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/rabbit/f6iNRKa938YPtKeegjG1W.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "seed",
        "safety_tolerance",
        "enable_safety_checker",
        "output_format",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "An intense close-up of knight's visor reflecting battle, sword raised, flames in background, chiaroscuro helmet shadows, hyper-detailed armor, square medieval, cinematic lighting"
          ],
          "description": "The prompt to generate an image from.",
          "type": "string",
          "title": "Prompt"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image.",
          "title": "Image Size",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "description": "The format of the generated image.",
          "type": "string",
          "title": "Output Format",
          "default": "jpeg"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5"
          ],
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "type": "string",
          "title": "Safety Tolerance",
          "default": "2"
        },
        "enable_safety_checker": {
          "description": "Whether to enable the safety checker.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "seed": {
          "description": "The seed to use for the generation.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "Flux2ProTextToImageInput",
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "processed megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/gemini-3-pro-image-preview",
    "name": "Gemini 3 Pro Image Preview",
    "description": "Nano Banana Pro (a.k.a Nano Banana 2) is Google's new state-of-the-art image generation and editing model",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/koala/Neuz3jAvI1MSVxj3tCrTU_afda4e7f4bc14945a716e864e1f609d8.jpg",
    "tags": [
      "realism",
      "typography"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "NanoBananaTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "An action shot of a black lab swimming in an inground suburban swimming pool. The camera is placed meticulously on the water line, dividing the image in half, revealing both the dogs head above water holding a tennis ball in it's mouth, and it's paws paddling underwater."
          ],
          "maxLength": 50000,
          "minLength": 3,
          "description": "The text prompt to generate an image from.",
          "title": "Prompt",
          "type": "string"
        },
        "num_images": {
          "minimum": 1,
          "description": "The number of images to generate.",
          "type": "integer",
          "title": "Number of Images",
          "maximum": 4,
          "default": 1
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "3:2",
            "4:3",
            "5:4",
            "1:1",
            "4:5",
            "3:4",
            "2:3",
            "9:16"
          ],
          "description": "The aspect ratio of the generated image.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "1:1"
        },
        "resolution": {
          "enum": [
            "1K",
            "2K",
            "4K"
          ],
          "description": "The resolution of the image to generate.",
          "type": "string",
          "title": "Resolution",
          "default": "1K"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "description": "The format of the generated image.",
          "type": "string",
          "title": "Output Format",
          "default": "png"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode",
        "resolution"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 3,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/nano-banana-pro",
    "name": "Nano Banana Pro",
    "description": "Nano Banana Pro (a.k.a Nano Banana 2) is Google's new state-of-the-art image generation and editing model",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/4eELX5wvo_7Qp2iNbl3Dm_09b7e837a37147cea386940f5aeb1fed.jpg",
    "tags": [
      "realism",
      "typography"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "NanoBananaTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "An action shot of a black lab swimming in an inground suburban swimming pool. The camera is placed meticulously on the water line, dividing the image in half, revealing both the dogs head above water holding a tennis ball in it's mouth, and it's paws paddling underwater."
          ],
          "maxLength": 50000,
          "type": "string",
          "title": "Prompt",
          "minLength": 3,
          "description": "The text prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Number of Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "3:2",
            "4:3",
            "5:4",
            "1:1",
            "4:5",
            "3:4",
            "2:3",
            "9:16"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image.",
          "default": "1:1"
        },
        "resolution": {
          "enum": [
            "1K",
            "2K",
            "4K"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the image to generate.",
          "default": "1K"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode",
        "resolution"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 3,
    "pricing_unit": "images"
  },
  {
    "id": "imagineart/imagineart-1.5-preview/text-to-image",
    "name": "Imagineart 1.5 Preview",
    "description": "ImagineArt 1.5 text-to-image model generates high-fidelity professional-grade visuals with lifelike realism, strong aesthetics, and text that actually reads correctly.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/dzrNfvK_MHMcQvZSBju-R_9731ad76917e41e4bd48796e82fa9bc3.jpg",
    "tags": [
      "visuals",
      "imagineart",
      "realism",
      "text"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "seed"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A high-angle, realistic photograph capturing a spontaneous moment of pure joy on a bright, sunny day. A young woman with long, wavy brown hair is sitting on the curb of an urban street, her head tilted all the way back as she laughs or shouts ecstatically up at the sky. She is wearing large black sunglasses, which have a bright glare from the sun, a white ribbed tank top with black trim, and black jeans. One of her hands is raised towards her face, fingers loosely curled near her sunglasses. The background is dominated by the strong graphic pattern of a black asphalt road with thick, white painted lines of a crosswalk. The lighting is harsh and direct, creating high contrast and deep shadows on the pavement, and brightly illuminating the woman's sun-kissed skin. The shot has a candid, in-the-moment feel, emphasizing the carefree and happy mood."
          ],
          "description": "Text prompt describing the desired image",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "3:1",
            "1:3",
            "3:2",
            "2:3"
          ],
          "description": "Image aspect ratio: 1:1, 3:1, 1:3, 16:9, 9:16, 4:3, 3:4, 3:2, 2:3",
          "type": "string",
          "examples": [
            "1:1",
            "3:1",
            "1:3",
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "3:2",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "default": "1:1"
        },
        "seed": {
          "examples": [
            0
          ],
          "description": "Seed for the image generation",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "ImagineArt_1_5_Input",
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/emu-3.5-image/text-to-image",
    "name": "Emu 3.5 Image",
    "description": "Generate images from text using Emu 3.5 Image",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/zebra/9k5Vd-GGgfiwpPTRXeXUT_ab24e212902a465499a09e586ec22f7f.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Emu35ImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Capture an intimate close-up bathed in warm, soft, late-afternoon sunlight filtering into a quintessential 1960s kitchen. The focal point is a charmingly designed vintage package of all-purpose flour, resting invitingly on a speckled Formica countertop. The packaging itself evokes pure nostalgia: perhaps thick, slightly textured paper in a warm cream tone, adorned with simple, bold typography (a friendly serif or script) in classic red and blue \"ALL-PURPOSE FLOUR\", featuring a delightful illustration like a stylized sheaf of wheat or a cheerful baker character. In smaller bold print at the bottom of the package: \"NET WT 5 LBS (80 OZ) 2.27kg\". Focus sharply on the package details \u2013 the slightly soft edges of the paper bag, the texture of the vintage printing, the inviting \"All-Purpose Flour\" text. Subtle hints of the 1960s kitchen frame the shot \u2013 the chrome edge of the counter gleaming softly, a blurred glimpse of a pastel yellow ceramic tile backsplash, or the corner of a vintage metal canister set just out of focus. The shallow depth of field keeps attention locked on the beautifully designed package, creating an aesthetic rich in warmth, authenticity, and nostalgic appeal."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to create the image."
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the output image.",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "3:2",
            "1:1",
            "2:3",
            "3:4",
            "9:16",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the output image.",
          "default": "1:1"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the output image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "Whether to return the image in sync mode.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the inference."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "resolution",
        "aspect_ratio",
        "enable_safety_checker",
        "seed",
        "output_format",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 3,
    "pricing_unit": "images"
  },
  {
    "id": "bria/fibo/generate",
    "name": "Fibo",
    "description": "SOTA Open source model trained on licensed data, transforming intent into structured control for precise, high-quality AI image generation in enterprise and agentic workflows.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/KZ0Rdf_H7CtVE7Gpqk7XB_430bc50472c44700aaee472dd73c18f1.jpg",
    "tags": [
      "bria",
      "fibo",
      "prompt-adherence"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "structured_prompt",
        "image_url",
        "seed",
        "steps_num",
        "aspect_ratio",
        "negative_prompt",
        "guidance_scale",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "description": "Prompt for image generation.",
          "title": "Prompt",
          "examples": [
            "A hyper-detailed, ultra-fluffy owl sitting in the trees at night, looking directly at the camera with wide, adorable, expressive eyes. Its feathers are soft and voluminous, catching the cool moonlight with subtle silver highlights. The owl\u2019s gaze is curious and full of charm, giving it a whimsical, storybook-like personality."
          ]
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "2:3",
            "3:2",
            "3:4",
            "4:3",
            "4:5",
            "5:4",
            "9:16",
            "16:9"
          ],
          "description": "Aspect ratio. Options: 1:1, 2:3, 3:2, 3:4, 4:3, 4:5, 5:4, 9:16, 16:9",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "1:1"
        },
        "steps_num": {
          "description": "Number of inference steps.",
          "type": "integer",
          "minimum": 20,
          "maximum": 50,
          "title": "Steps Num",
          "default": 50
        },
        "image_url": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "description": "Reference image (file or URL).",
          "title": "Image Url"
        },
        "sync_mode": {
          "description": "If true, returns the image directly in the response (increases latency).",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "guidance_scale": {
          "description": "Guidance scale for text.",
          "type": "integer",
          "minimum": 3,
          "maximum": 5,
          "title": "Guidance Scale",
          "default": 5
        },
        "seed": {
          "description": "Random seed for reproducibility.",
          "type": "integer",
          "title": "Seed",
          "default": 5555
        },
        "structured_prompt": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/StructuredPrompt"
            },
            {
              "type": "null"
            }
          ],
          "description": "The structured prompt to generate an image from."
        },
        "negative_prompt": {
          "description": "Negative prompt for image generation.",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "title": "GaiaInputModel"
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/piflow",
    "name": "Piflow",
    "description": "Use the faster speed of piflow to generate images with same quality to that of slower models.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/gxldXHbNIVlr0CpcbpWOj_ad5f5c3f5fa74edbbee97ada3ddeef02.jpg",
    "tags": [
      "text-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "PiQwenInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Photo of a coffee shop entrance featuring a chalkboard sign reading \"\u03c0-Qwen Coffee \ud83d\ude0a $2 per cup,\" with a neon light beside it displaying \"\u03c0-\u901a\u4e49\u5343\u95ee\". Next to it hangs a poster showing a beautiful Chinese woman, and beneath the poster is written \"e\u22482.71828-18284-59045-23536-02874-71352\"."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "\n            The size of the generated image. You can choose between some presets or custom height and width\n            that **must be multiples of 8**.\n        ",
          "default": "square_hd"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 8
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducible generation. If set to None, a random seed will be used."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "num_images",
        "output_format",
        "enable_safety_checker",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/gpt-image-1-mini",
    "name": "GPT Image 1 Mini",
    "description": "GPT Image 1 mini combines OpenAI's advanced language capabilities, powered by GPT-5, with GPT Image 1 Mini for efficient image generation. ",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/Z7Y5fVvUXaT1XzWGqVngY_f333390b078a4bed9491ccda3b9f0e90.jpg",
    "tags": [
      "text-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageRequestMini",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A serene landscape with mountains reflecting in a crystal-clear lake at sunset, photorealistic style"
          ],
          "description": "The prompt for image generation",
          "type": "string",
          "title": "Prompt"
        },
        "num_images": {
          "description": "Number of images to generate",
          "type": "integer",
          "minimum": 1,
          "title": "Number of Images",
          "examples": [
            1
          ],
          "maximum": 4,
          "default": 1
        },
        "image_size": {
          "enum": [
            "auto",
            "1024x1024",
            "1536x1024",
            "1024x1536"
          ],
          "description": "Aspect ratio for the generated image",
          "type": "string",
          "title": "Image Size",
          "default": "auto"
        },
        "background": {
          "enum": [
            "auto",
            "transparent",
            "opaque"
          ],
          "description": "Background for the generated image",
          "type": "string",
          "title": "Background",
          "default": "auto"
        },
        "quality": {
          "enum": [
            "auto",
            "low",
            "medium",
            "high"
          ],
          "description": "Quality for the generated image",
          "type": "string",
          "title": "Quality",
          "default": "auto"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "description": "Output format for the images",
          "type": "string",
          "title": "Output Format",
          "default": "png"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "background",
        "quality",
        "num_images",
        "output_format",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/reve/text-to-image",
    "name": "Reve",
    "description": "Reve\u2019s text-to-image model generates detailed visual output that closely follow your instructions, with strong aesthetic quality and accurate text rendering.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/jNWFUrGVBR4OL3rF3KBZp_f7c2b693436142a3bd3bd012ee26342c.jpg",
    "tags": [
      "text-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "num_images",
        "output_format",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "num_images": {
          "description": "Number of images to generate",
          "type": "integer",
          "examples": [
            1
          ],
          "title": "Number of Images",
          "minimum": 1,
          "maximum": 4,
          "default": 1
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "3:2",
            "2:3",
            "4:3",
            "3:4",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "examples": [
            "16:9"
          ],
          "description": "The desired aspect ratio of the generated image.",
          "default": "3:2"
        },
        "prompt": {
          "examples": [
            "A serene mountain landscape at sunset with snow-capped peaks"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text description of the desired image.",
          "minLength": 1,
          "maxLength": 2560
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "examples": [
            "png"
          ],
          "description": "Output format for the generated image.",
          "default": "png"
        }
      },
      "title": "ReveCreateInput",
      "description": "Input for Reve text-to-image generation",
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/hunyuan-image/v3/text-to-image",
    "name": "Hunyuan Image",
    "description": "Leverage the state-of-the-art capabilities of Hunyuan Image 3.0 to generate visual content that effectively conveys the messaging of your written material.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3.fal.media/files/kangaroo/en7kxz5HNAQKg5QuONGDH_760708cdbc4b49e1a96e6b7628e43c35.jpg",
    "tags": [
      "text-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "HunyuanTextToImageInputV3",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "200mm telephoto through crowd gaps; subject laughing, candid; creamy background compression, color pop from a single bold garment, catchlight in eyes."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt for image-to-image."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The desired size of the generated image.",
          "default": "square_hd"
        },
        "enable_prompt_expansion": {
          "examples": [
            true
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "Controls how much the model adheres to the prompt. Higher values mean stricter adherence.",
          "default": 7.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducible results. If None, a random seed is used."
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, watermark, signature"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to guide the image generation away from certain concepts.",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_images",
        "num_inference_steps",
        "guidance_scale",
        "seed",
        "enable_safety_checker",
        "sync_mode",
        "output_format",
        "enable_prompt_expansion"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/wan-25-preview/text-to-image",
    "name": "Wan 2.5 Text to Image",
    "description": "Wan 2.5 text-to-image model.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3.fal.media/files/penguin/6PlSnB3q28Mu0QjURXyBe_051522e72e02496da12bf011190ca281.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A lone samurai standing on the edge of a cliff at twilight, overlooking a vast valley shrouded in mist. The sky burns with deep orange and purple hues from the setting sun, casting long, dramatic shadows. The samurai\u2019s silhouette glows against the horizon, with their sword reflecting a glint of fading light. The overall style is hyper-realistic, cinematic, and moody, with dramatic contrast and atmospheric depth."
          ],
          "title": "Prompt",
          "type": "string",
          "minLength": 1,
          "description": "The prompt for image generation. Supports Chinese and English, max 2000 characters."
        },
        "num_images": {
          "description": "Number of images to generate. Values from 1 to 4.",
          "type": "integer",
          "minimum": 1,
          "maximum": 4,
          "examples": [
            1
          ],
          "title": "Num Images",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. Can use preset names like 'square', 'landscape_16_9', etc., or specific dimensions. Total pixels must be between 768\u00d7768 and 1440\u00d71440, with aspect ratio between [1:4, 4:1].",
          "examples": [
            "square",
            "landscape_16_9",
            "portrait_16_9",
            {
              "height": 1280,
              "width": 1280
            }
          ],
          "default": "square"
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "low resolution, error, worst quality, low quality, defects"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt to describe content to avoid. Max 500 characters."
        }
      },
      "description": "Input for text-to-image generation",
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_images",
        "image_size",
        "enable_prompt_expansion",
        "seed",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/flux/srpo",
    "name": "FLUX.1 SRPO [dev]",
    "description": "FLUX.1 SRPO [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/lion/ZNXdbSzAuCKiNcAobhmuq_433a1adbd71044199027c873cac81298.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseSRPOInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Mountain guide, sturdy build, wilderness wisdom, alert gaze, technical outdoor gear with rope coils, snow-capped peaks background, crisp mountain lighting, leading pose, wind-swept hair with full beard, weather-worn face with quiet confidence, alpine expert presence"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "none"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 4.5
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-1/srpo",
    "name": "FLUX.1 SRPO [dev]",
    "description": "FLUX.1 SRPO [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/elephant/sc5nHfAUsSmVjmNNzoHDo_0b10ed5de0c24d9f88df8ed0a350f49f.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseSRPOFlux1Input",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Mountain guide, sturdy build, wilderness wisdom, alert gaze, technical outdoor gear with rope coils, snow-capped peaks background, crisp mountain lighting, leading pose, wind-swept hair with full beard, weather-worn face with quiet confidence, alpine expert presence"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 4.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/hunyuan-image/v2.1/text-to-image",
    "name": "Hunyuan Image",
    "description": "Use the amazing capabilities of hunyuan image 2.1 to generate images that express the feelings of your text.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/monkey/fl_uWB5P9sMjDBhq_7hG0_644c0f46ad94482d8e2e09e180e64c88.jpg",
    "tags": [
      "text-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "HunyuanTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cute, cartoon-style anthropomorphic penguin plush toy, standing in a painting studio, wearing a red knitted scarf and beret."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The desired size of the generated image.",
          "default": "square_hd"
        },
        "use_reprompt": {
          "title": "Use Reprompt",
          "type": "boolean",
          "description": "Enable prompt enhancement for potentially better results.",
          "default": true
        },
        "use_refiner": {
          "title": "Use Refiner",
          "type": "boolean",
          "description": "Enable the refiner model for improved image quality.",
          "default": false
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "Controls how much the model adheres to the prompt. Higher values mean stricter adherence.",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "Number of denoising steps.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducible results. If None, a random seed is used."
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, watermark, signature"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to guide the image generation away from certain concepts.",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_images",
        "num_inference_steps",
        "guidance_scale",
        "seed",
        "use_reprompt",
        "use_refiner",
        "enable_safety_checker",
        "sync_mode",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/bytedance/seedream/v4/text-to-image",
    "name": "Bytedance Seedream v4",
    "description": "A new-generation image creation model ByteDance, Seedream 4.0 integrates image generation and image editing capabilities into a single, unified architecture.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/kangaroo/MTKbHTmLwlCPVvxnEPYVW_cd47bf24871b46af9747a5fcb7f4f97b.jpg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_images",
        "max_images",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "enhance_prompt_mode"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A trendy restaurant with a digital menu board displaying \"Seedream 4.0 is available on fal\" in elegant script, with diners enjoying their meals."
          ],
          "description": "The text prompt used to generate the image",
          "type": "string",
          "title": "Prompt"
        },
        "num_images": {
          "minimum": 1,
          "description": "Number of separate model generations to be run with the prompt.",
          "type": "integer",
          "title": "Num Images",
          "maximum": 6,
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9",
                "auto",
                "auto_2K",
                "auto_4K"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. Width and height must be between 1024 and 4096.",
          "title": "Image Size",
          "examples": [
            {
              "height": 4096,
              "width": 4096
            }
          ],
          "default": {
            "height": 2048,
            "width": 2048
          }
        },
        "enhance_prompt_mode": {
          "enum": [
            "standard",
            "fast"
          ],
          "description": "The mode to use for enhancing prompt enhancement. Standard mode provides higher quality results but takes longer to generate. Fast mode provides average quality results but takes less time to generate.",
          "type": "string",
          "title": "Enhance Prompt Mode",
          "default": "standard"
        },
        "max_images": {
          "minimum": 1,
          "description": "If set to a number greater than one, enables multi-image generation. The model will potentially return up to `max_images` images every generation, and in total, `num_images` generations will be carried out. In total, the number of images generated will be between `num_images` and `max_images*num_images`.",
          "type": "integer",
          "title": "Max Images",
          "maximum": 6,
          "default": 1
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "seed": {
          "description": "Random seed to control the stochasticity of image generation.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "SeedDream4T2IInput",
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/gemini-25-flash-image",
    "name": "Gemini 2.5 Flash Image",
    "description": "Nano Banana is Google's state-of-the-art image generation and editing model\n",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/penguin/f0TePjwvxUJQ2MJ4kDDtC_dba951a1d05a4c8f9324127e7751181e.jpg",
    "tags": [
      "text-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "NanoBananaTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "An action shot of a black lab swimming in an inground suburban swimming pool. The camera is placed meticulously on the water line, dividing the image in half, revealing both the dogs head above water holding a tennis ball in it's mouth, and it's paws paddling underwater."
          ],
          "maxLength": 5000,
          "minLength": 3,
          "description": "The text prompt to generate an image from.",
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "3:2",
            "4:3",
            "5:4",
            "1:1",
            "4:5",
            "3:4",
            "2:3",
            "9:16"
          ],
          "description": "The aspect ratio of the generated image.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "1:1"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Number of Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "description": "The format of the generated image.",
          "type": "string",
          "title": "Output Format",
          "default": "png"
        },
        "limit_generations": {
          "description": "Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.",
          "type": "boolean",
          "title": "Limit Generations",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode",
        "limit_generations"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/nano-banana",
    "name": "Nano Banana",
    "description": "Google's state-of-the-art image generation and editing model",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/zebra/eLGB_Z0WHjbSD4Ad5aY-g_83f5f6da4f09426489042866cb0e4e9c.jpg",
    "tags": [
      "image-generation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "NanoBananaTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "An action shot of a black lab swimming in an inground suburban swimming pool. The camera is placed meticulously on the water line, dividing the image in half, revealing both the dogs head above water holding a tennis ball in it's mouth, and it's paws paddling underwater."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 5000,
          "minLength": 3,
          "description": "The text prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Number of Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "3:2",
            "4:3",
            "5:4",
            "1:1",
            "4:5",
            "3:4",
            "2:3",
            "9:16"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image.",
          "default": "1:1"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "limit_generations": {
          "title": "Limit Generations",
          "type": "boolean",
          "description": "Experimental parameter to limit the number of generations from each round of prompting to 1. Set to `True` to to disregard any instructions in the prompt regarding the number of images to generate.",
          "default": false
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode",
        "limit_generations"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/bytedance/dreamina/v3.1/text-to-image",
    "name": "Bytedance",
    "description": "Dreamina showcases superior picture effects, with significant improvements in picture aesthetics, precise and diverse styles, and rich details.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/kangaroo/l70sBwCHmfC3XRlEd6GV5_ebd0a5807bba4b6ca02f3c3bffca5cc7.jpg",
    "tags": [
      "text-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "enhance_prompt",
        "num_images",
        "seed",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A 25-year-old korean woman selfie, front facing camera, lighting is soft and natural. If background is visible, it's a clean, modern apartment interior. The clothing color is clearly visible and distinct, adding a hint of color contrast"
          ],
          "description": "The text prompt used to generate the image",
          "type": "string",
          "title": "Prompt"
        },
        "num_images": {
          "minimum": 1,
          "description": "Number of images to generate",
          "type": "integer",
          "title": "Num Images",
          "maximum": 4,
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. Width and height must be between 512 and 2048.",
          "title": "Image Size",
          "default": {
            "height": 1536,
            "width": 2048
          }
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "seed": {
          "description": "Random seed to control the stochasticity of image generation.",
          "type": "integer",
          "title": "Seed"
        },
        "enhance_prompt": {
          "description": "Whether to use an LLM to enhance the prompt",
          "type": "boolean",
          "title": "Enhance Prompt",
          "default": false
        }
      },
      "title": "DreaminaInput",
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/text-to-image/lora",
    "name": "Wan v2.2 A14B Text-to-Image A14B with LoRAs",
    "description": "Wan 2.2's 14B model with LoRA support generates high-fidelity images with enhanced prompt alignment, style adaptability.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/lion/hV9rZRZFnLQo1Bns6llc7_148c4a2e142445cda4c87daed812f731.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanLoRAT2IRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "In this breathtaking wildlife documentary, we are drawn into an intimate close-up of a majestic lion's face, framed against the backdrop of a vast African savannah at dawn. The camera captures the raw power and nobility of the creature as it gazes intently into the distance, its golden-brown fur glistening under the soft, diffused light that bathes the scene in an ethereal glow. Harsh shadows dance across its features, accentuating the deep wrinkles around its eyes and the rugged texture of its fur, each strand a testament to its age and wisdom. The static camera angle invites viewers to immerse themselves in this moment of profound stillness, where the lion's intense focus hints at an unseen presence or a distant threat. As the sun ascends, the landscape transforms into a symphony of warm hues, enhancing the serene yet tense atmosphere that envelops this extraordinary encounter with nature's untamed beauty."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide image generation."
        },
        "shift": {
          "description": "Shift value for the image. Must be between 1.0 and 10.0.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            2
          ],
          "title": "Shift",
          "default": 2
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "examples": [
            "regular"
          ],
          "default": "regular"
        },
        "reverse_video": {
          "title": "Reverse Video",
          "type": "boolean",
          "description": "If true, the video will be reversed.",
          "default": false
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "examples": [
            "square_hd"
          ],
          "default": "square_hd"
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "LoRA weights to be used in the inference.",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale (1st Stage)",
          "default": 3.5
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "image_format": {
          "enum": [
            "png",
            "jpeg"
          ],
          "title": "Image Format",
          "type": "string",
          "description": "The format of the output image.",
          "examples": [
            "jpeg"
          ],
          "default": "jpeg"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "guidance_scale_2": {
          "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            4
          ],
          "title": "Guidance Scale (2nd Stage)",
          "default": 4
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 40,
          "examples": [
            27
          ],
          "title": "Number of Inference Steps",
          "default": 27
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "seed",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "guidance_scale",
        "guidance_scale_2",
        "shift",
        "loras",
        "reverse_video",
        "image_size",
        "image_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/wan/v2.2-5b/text-to-image",
    "name": "Wan",
    "description": "Wan 2.2's 5B model generates high-resolution, photorealistic images with powerful prompt understanding and fine-grained visual detail",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/kangaroo/xvsySaKCeM5ZulogiaTX2_f6fa9b031e374468bcb9e426528807e4.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanSmallT2IRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "In this breathtaking wildlife documentary, we are drawn into an intimate close-up of a majestic lion's face, framed against the backdrop of a vast African savannah at dawn. The camera captures the raw power and nobility of the creature as it gazes intently into the distance, its golden-brown fur glistening under the soft, diffused light that bathes the scene in an ethereal glow. Harsh shadows dance across its features, accentuating the deep wrinkles around its eyes and the rugged texture of its fur, each strand a testament to its age and wisdom. The static camera angle invites viewers to immerse themselves in this moment of profound stillness, where the lion's intense focus hints at an unseen presence or a distant threat. As the sun ascends, the landscape transforms into a symphony of warm hues, enhancing the serene yet tense atmosphere that envelops this extraordinary encounter with nature's untamed beauty."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide image generation."
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale",
          "default": 3.5
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "examples": [
            "square_hd"
          ],
          "default": "square_hd"
        },
        "image_format": {
          "enum": [
            "png",
            "jpeg"
          ],
          "title": "Image Format",
          "type": "string",
          "description": "The format of the output image.",
          "examples": [
            "jpeg"
          ],
          "default": "jpeg"
        },
        "shift": {
          "description": "Shift value for the image. Must be between 1.0 and 10.0.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            2
          ],
          "title": "Shift",
          "default": 2
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 50,
          "examples": [
            40
          ],
          "title": "Number of Inference Steps",
          "default": 40
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "seed",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "guidance_scale",
        "shift",
        "image_size",
        "image_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/text-to-image",
    "name": "Wan",
    "description": "Wan 2.2's 14B model generates high-resolution, photorealistic images with powerful prompt understanding and fine-grained visual detail",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanT2IRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "In this breathtaking wildlife documentary, we are drawn into an intimate close-up of a majestic lion's face, framed against the backdrop of a vast African savannah at dawn. The camera captures the raw power and nobility of the creature as it gazes intently into the distance, its golden-brown fur glistening under the soft, diffused light that bathes the scene in an ethereal glow. Harsh shadows dance across its features, accentuating the deep wrinkles around its eyes and the rugged texture of its fur, each strand a testament to its age and wisdom. The static camera angle invites viewers to immerse themselves in this moment of profound stillness, where the lion's intense focus hints at an unseen presence or a distant threat. As the sun ascends, the landscape transforms into a symphony of warm hues, enhancing the serene yet tense atmosphere that envelops this extraordinary encounter with nature's untamed beauty."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide image generation."
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale (1st Stage)",
          "default": 3.5
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "examples": [
            "regular"
          ],
          "default": "regular"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "examples": [
            "square_hd"
          ],
          "default": "square_hd"
        },
        "shift": {
          "description": "Shift value for the image. Must be between 1.0 and 10.0.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            2
          ],
          "title": "Shift",
          "default": 2
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "guidance_scale_2": {
          "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            4
          ],
          "title": "Guidance Scale (2nd Stage)",
          "default": 4
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 40,
          "examples": [
            27
          ],
          "title": "Number of Inference Steps",
          "default": 27
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "seed",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "guidance_scale",
        "guidance_scale_2",
        "shift",
        "image_size"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/qwen-image",
    "name": "Qwen Image",
    "description": "Qwen-Image is an image generation foundation model in the Qwen series that achieves significant advances in complex text rendering and precise image editing. ",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/koala/6JAMNCSti-vm-zJeZi6hA_626cdc11d4d04560ac9523fbd61f2eac.jpg",
    "tags": [
      "text-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseQwenImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Mount Fuji with cherry blossoms in the foreground, clear sky, peaceful spring day, soft natural light, realistic landscape."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the image with"
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level for image generation. Options: 'none', 'regular', 'high'. Higher acceleration increases speed. 'regular' balances speed and quality. 'high' is recommended for images without text.",
          "examples": [
            "none"
          ],
          "default": "none"
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 250,
          "description": "The number of inference steps to perform.",
          "default": 30
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use up to 3 LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "use_turbo": {
          "examples": [
            true
          ],
          "title": "Use Turbo",
          "type": "boolean",
          "description": "Enable turbo mode for faster generation with high quality. When enabled, uses optimized settings (10 steps, CFG=1.2).",
          "default": false
        },
        "negative_prompt": {
          "examples": [
            "blurry, ugly"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the generation",
          "default": " "
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale",
          "type": "number",
          "maximum": 20,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 2.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "negative_prompt",
        "acceleration",
        "loras",
        "use_turbo"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-krea-lora/stream",
    "name": "Flux Krea Lora",
    "description": "Super fast endpoint for the FLUX.1 [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/zebra/6CK9OSIhC3AAEhihyCqsh_9a84ecc9c66343d688ccdd5c9f57c80b.jpg",
    "tags": [
      "lora",
      "personalization"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate. This is always set to 1 for streaming output.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 35,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-krea-lora",
    "name": "FLUX.1 Krea [dev] with LoRAs",
    "description": "Super fast endpoint for the FLUX.1 [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "category": "text-to-image",
    "thumbnail_url": "https://v3.fal.media/files/tiger/fB-RsJ-BW4mrUVAH8oKF2_LOuGVDgg07U8OWbOhhMFt_d6ab08c96ab94da8b6d3e979d634af16.jpg",
    "tags": [
      "lora",
      "personalization"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate. This is always set to 1 for streaming output.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 35,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux/krea",
    "name": "FLUX.1 Krea [dev]",
    "description": "FLUX.1 Krea [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseKreaInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A candid street photo of a woman with a pink bob and bold eyeliner on a graffiti-covered subway platform. She wears a bright yellow patent leather coat over a black-and-white checkered turtleneck and platform boots. Natural subway lighting creates an authentic urban scene with a relaxed, unposed feel."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "none"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 4.5
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-1/krea",
    "name": "FLUX.1 Krea [dev]",
    "description": "FLUX.1 Krea [dev] is a 12 billion parameter flow transformer that generates high-quality images from text with incredible aesthetics. It is suitable for personal and commercial use.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-5.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseKreaFlux1Input",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A candid street photo of a woman with a pink bob and bold eyeliner on a graffiti-covered subway platform. She wears a bright yellow patent leather coat over a black-and-white checkered turtleneck and platform boots. Natural subway lighting creates an authentic urban scene with a relaxed, unposed feel."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 4.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/sky-raccoon",
    "name": "Sky Raccoon",
    "description": "Generate images from a text prompt.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "tags": [
      "text-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SkyRaccoonRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "description": "The text prompt to guide video generation.",
          "type": "string",
          "title": "Prompt"
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image.",
          "title": "Image Size",
          "default": {
            "height": 1024,
            "width": 1024
          }
        },
        "turbo_mode": {
          "title": "Turbo Mode",
          "type": "boolean",
          "description": "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
          "default": false
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "description": "Whether to enable prompt expansion.",
          "type": "boolean",
          "title": "Enable Prompt Expansion",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": false
        },
        "negative_prompt": {
          "examples": [
            "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
          ],
          "description": "Negative prompt for video generation.",
          "type": "string",
          "title": "Negative Prompt",
          "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        },
        "num_inference_steps": {
          "minimum": 2,
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "maximum": 40,
          "title": "Num Inference Steps",
          "default": 30
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "seed",
        "num_inference_steps",
        "image_size",
        "enable_safety_checker",
        "enable_prompt_expansion",
        "turbo_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-kontext-lora/text-to-image",
    "name": "Flux Kontext Lora",
    "description": "Super fast text-to-image endpoint for the FLUX.1 Kontext [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "tags": [
      "text-to-image"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseKontextInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Mount Fuji with cherry blossoms in the foreground, clear sky, peaceful spring day, soft natural light, realistic landscape."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the image with"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "none"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 2.5
        },
        "num_inference_steps": {
          "minimum": 10,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 30
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "loras",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/omnigen-v2",
    "name": "Omnigen V2",
    "description": "OmniGen is a unified image generation model that can generate a wide range of images from multi-modal prompts. It can be used for various tasks such as Image Editing, Personalized Image Generation, Virtual Try-On, Multi Person Generation and more!",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "tags": [
      "multimodal",
      "editing",
      "try-on"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Make the dress blue",
            "Add a fisherman hat to the woman's head",
            "Replace the sword with a hammer.",
            "Change the dress to blue.",
            "Remove the cat"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate or edit an image. Use specific language like 'Add the bird from image 1 to the desk in image 2' for better results."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "scheduler": {
          "enum": [
            "euler",
            "dpmsolver"
          ],
          "title": "Scheduler",
          "type": "string",
          "description": "The scheduler to use for the diffusion process.",
          "default": "euler"
        },
        "cfg_range_end": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Cfg Range End",
          "description": "CFG range end value.",
          "default": 1
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt to guide what should not be in the image.",
          "default": "(((deformed))), blurry, over saturation, bad anatomy, disfigured, poorly drawn face, mutation, mutated, (extra_limb), (ugly), (poorly drawn hands), fused fingers, messy drawing, broken legs censor, censored, censor_bar"
        },
        "text_guidance_scale": {
          "minimum": 1,
          "maximum": 8,
          "type": "number",
          "title": "Text Guidance scale",
          "description": "\n            The Text Guidance scale controls how closely the model follows the text prompt.\n            Higher values make the model stick more closely to the prompt.\n        ",
          "default": 5
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_guidance_scale": {
          "minimum": 1,
          "maximum": 3,
          "type": "number",
          "title": "Image Guidance scale",
          "description": "\n            The Image Guidance scale controls how closely the model follows the input images.\n            For image editing: 1.3-2.0, for in-context generation: 2.0-3.0\n        ",
          "default": 2
        },
        "input_image_urls": {
          "description": "URLs of input images to use for image editing or multi-image generation. Support up to 3 images.",
          "type": "array",
          "items": {
            "type": "string"
          },
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/omnigen/input.png"
            ]
          ],
          "title": "Input Image Urls",
          "default": []
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "cfg_range_start": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Cfg Range Start",
          "description": "CFG range start value.",
          "default": 0
        },
        "num_inference_steps": {
          "minimum": 20,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 50
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "input_image_urls",
        "image_size",
        "num_inference_steps",
        "seed",
        "text_guidance_scale",
        "image_guidance_scale",
        "negative_prompt",
        "cfg_range_start",
        "cfg_range_end",
        "scheduler",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/bytedance/seedream/v3/text-to-image",
    "name": "Bytedance",
    "description": "Seedream 3.0 is a bilingual (Chinese and English) text-to-image model that excels at text-to-image generation.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "guidance_scale",
        "num_images",
        "seed",
        "enable_safety_checker",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Fisheye lens, the head of a cat, the image shows the effect that the facial features of the cat are distorted due to the shooting method."
          ],
          "description": "The text prompt used to generate the image",
          "type": "string",
          "title": "Prompt"
        },
        "num_images": {
          "minimum": 1,
          "description": "Number of images to generate",
          "type": "integer",
          "title": "Num Images",
          "maximum": 4,
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "Use for finer control over the output image size. Will be used over aspect_ratio, if both are provided. Width and height must be between 512 and 2048.",
          "title": "Image Size"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "guidance_scale": {
          "minimum": 1,
          "description": "Controls how closely the output image aligns with the input prompt. Higher values mean stronger prompt correlation.",
          "type": "number",
          "title": "Guidance Scale",
          "maximum": 10,
          "default": 2.5
        },
        "seed": {
          "description": "Random seed to control the stochasticity of image generation.",
          "type": "integer",
          "title": "Seed"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        }
      },
      "title": "SeedDreamInput",
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/flux-1/schnell",
    "name": "FLUX.1 [schnell]",
    "description": "Fastest inference in the world for the 12 billion parameter FLUX.1 [schnell] text-to-image model. ",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SchnellFlux1TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 12,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 4
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 3.5
        }
      },
      "x-fal-order-properties": [
        "num_inference_steps",
        "prompt",
        "image_size",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-1/dev",
    "name": "FLUX.1 [dev]",
    "description": "FLUX.1 [dev] is a 12 billion parameter flow transformer that generates high-quality images from text. It is suitable for personal and commercial use.\n",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-4.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseFlux1Input",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "regular"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 3.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-pro/kontext/max/text-to-image",
    "name": "FLUX.1 Kontext [max]",
    "description": "FLUX.1 Kontext [max] text-to-image is a new premium model brings maximum performance across all aspects \u2013 greatly improved prompt adherence.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-3.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FluxProTextToImageInputWithAR",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "3:2",
            "1:1",
            "2:3",
            "3:4",
            "9:16",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image.",
          "default": "1:1"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6"
          ],
          "title": "Safety Tolerance",
          "type": "string",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "default": "2"
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enhance_prompt": {
          "title": "Enhance Prompt",
          "type": "boolean",
          "description": "Whether to enhance the prompt for better results.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "output_format",
        "safety_tolerance",
        "enhance_prompt",
        "aspect_ratio"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 2,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/flux-pro/kontext/text-to-image",
    "name": "FLUX.1 Kontext [pro]",
    "description": "The FLUX.1 Kontext [pro] text-to-image delivers state-of-the-art image generation results with unprecedented prompt following, photorealistic rendering, and flawless typography.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/zebra/VOrzt92hNVLX9m9jB-7-4_deea28b6b45344d4aa4eb3be14b3478e.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FluxProTextToImageInputWithAR",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "3:2",
            "1:1",
            "2:3",
            "3:4",
            "9:16",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image.",
          "default": "1:1"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6"
          ],
          "title": "Safety Tolerance",
          "type": "string",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "default": "2"
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enhance_prompt": {
          "title": "Enhance Prompt",
          "type": "boolean",
          "description": "Whether to enhance the prompt for better results.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "output_format",
        "safety_tolerance",
        "enhance_prompt",
        "aspect_ratio"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/bagel",
    "name": "Bagel",
    "description": "Bagel is a 7B parameter from Bytedance-Seed multimodal model that can generate both text and images.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/bagel.webp",
    "tags": [
      "text-to-image",
      "multimodal"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageGenInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A luminous ancient temple floating among cosmic clouds, with impossible architecture of twisted spires and inverted arches. The structure is half-built from crystalline white marble and half from living bioluminescent coral in vibrant teal and purple. Ethereal light filters through stained glass windows depicting mythological scenes. Tiny cloaked figures with glowing lanterns traverse impossible staircases. In the foreground, a massive ornate door stands slightly ajar, revealing a glimpse of swirling golden energy within. The scene is lit by two moons of different colors, casting overlapping shadows. Cinematic lighting, hyper-detailed textures, 8K resolution."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for the generation."
        },
        "use_thought": {
          "title": "Use Thought",
          "type": "boolean",
          "description": "Whether to use thought tokens for generation. If set to true, the model will \"think\" to potentially improve generation quality. Increases generation time and increases the cost by 20%.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "use_thought",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 2,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/imagen4/preview/ultra",
    "name": "Imagen 4 Ultra",
    "description": "Google\u2019s highest quality image generation model",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "aspect_ratio",
        "output_format",
        "sync_mode",
        "resolution"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "This four-panel comic strip uses a charming, deliberately pixelated art style reminiscent of classic 8-bit video games, featuring simple shapes and a limited, bright color palette dominated by greens, blues, browns, and the dinosaur's iconic grey/black. The setting is a stylized pixel beach. Panel one shows the familiar Google Chrome T-Rex dinosaur, complete with its characteristic pixelated form, wearing tiny pixel sunglasses and lounging on a pixelated beach towel under a blocky yellow sun. Pixelated palm trees sway gently in the background against a blue pixel sky. A caption box with pixelated font reads, \"Even error messages need a vacation.\" Panel two is a close-up of the T-Rex attempting to build a pixel sandcastle. It awkwardly pats a mound of brown pixels with its tiny pixel arms, looking focused. Small pixelated shells dot the sand around it. Panel three depicts the T-Rex joyfully hopping over a series of pixelated cacti planted near the beach, mimicking its game obstacle avoidance. Small \"Boing! Boing!\" sound effect text appears in a blocky font above each jump. A pixelated crab watches from the side, waving its pixel claw. The final panel shows the T-Rex floating peacefully on its back in the blocky blue pixel water, sunglasses still on, with a contented expression. A small thought bubble above it contains pixelated \"Zzz...\" indicating relaxation."
          ],
          "title": "Prompt",
          "minLength": 3,
          "type": "string",
          "description": "The text prompt to generate an image from.",
          "maxLength": 5000
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "16:9",
            "9:16",
            "4:3",
            "3:4"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image.",
          "default": "1:1"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Number of Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "resolution": {
          "enum": [
            "1K",
            "2K"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated image.",
          "default": "1K"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        }
      },
      "title": "Imagen4TextToImageUltraInput",
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/dreamo",
    "name": "DreamO",
    "description": "DreamO is an image customization framework designed to support a wide range of tasks while facilitating seamless integration of multiple conditions.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-5.jpg",
    "tags": [
      "stylized",
      "realism"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "DreamOInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Two people hugging inside a forest"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "first_image_url": {
          "examples": [
            "https://v3.fal.media/files/rabbit/I3exImt_zOYaiZv8caeGP_Pz4CnQ12tCUuDIhEQkmbD_ae4193792924495e89c516e6b492ed2b_1.jpg"
          ],
          "title": "First Reference Image URL",
          "type": "string",
          "description": "URL of first reference image to use for generation."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "second_image_url": {
          "examples": [
            "https://v3.fal.media/files/penguin/F3Yqprwlv-yaeusxAS0bS_image.webp"
          ],
          "title": "Second Reference Image URL",
          "type": "string",
          "description": "URL of second reference image to use for generation."
        },
        "second_reference_task": {
          "enum": [
            "ip",
            "id",
            "style"
          ],
          "title": "Second Reference Task",
          "type": "string",
          "description": "Task for second reference image (ip/id/style).",
          "default": "ip"
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "first_reference_task": {
          "enum": [
            "ip",
            "id",
            "style"
          ],
          "title": "First Reference Task",
          "type": "string",
          "description": "Task for first reference image (ip/id/style).",
          "default": "ip"
        },
        "negative_prompt": {
          "examples": [
            "bad quality, worst quality, text, signature, watermark, extra limbs"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The prompt to generate an image from.",
          "default": ""
        },
        "ref_resolution": {
          "minimum": 512,
          "maximum": 1024,
          "type": "integer",
          "title": "Ref Resolution",
          "description": "Resolution for reference images.",
          "default": 512
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "true_cfg": {
          "minimum": 1,
          "maximum": 5,
          "type": "number",
          "title": "True Cfg",
          "description": "The weight of the CFG loss.",
          "default": 1
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 12
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "first_image_url",
        "second_image_url",
        "first_reference_task",
        "second_reference_task",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "negative_prompt",
        "sync_mode",
        "ref_resolution",
        "true_cfg",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-lora/stream",
    "name": "Flux Lora",
    "description": "Super fast endpoint for the FLUX.1 [dev] model with LoRA support, enabling rapid and high-quality image generation using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-5.jpeg",
    "tags": [
      "lora",
      "personalization"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "description": "The number of images to generate. This is always set to 1 for streaming output.",
          "title": "Num Images",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 35,
          "type": "number",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "title": "Guidance scale (CFG)",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "description": "The number of inference steps to perform.",
          "title": "Num Inference Steps",
          "default": 28
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "easel-ai/easel-avatar",
    "name": "Easel Avatar",
    "description": "Create scenes with one or two people using just selfies and text prompt (without LoRAs)",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/easel-avatar-2.webp",
    "tags": [
      "avatars",
      "loras",
      "image-generation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AvatarInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "at the Met Gala, dressed in very fancy outfits, captured in a full body shot"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the scene"
        },
        "gender_1": {
          "enum": [
            "male",
            "female",
            "non-binary"
          ],
          "title": "Second user gender",
          "type": "string",
          "description": "The gender of the person in the second face image",
          "default": "female"
        },
        "style": {
          "enum": [
            "hyperrealistic-likeness",
            "hyperrealistic",
            "realistic",
            "stylistic"
          ],
          "description": "The style of the generated image. Hyperrealistic-likeness: preserves more likeness including hair styles; hyperrealistic: ideal for fun and creative scenes; Realistic: photorealistic with good text rendering; Stylistic: softer, more artistic",
          "type": "string",
          "examples": [
            "hyperrealistic-likeness",
            "hyperrealistic",
            "realistic",
            "stylistic"
          ],
          "title": "Output Style",
          "default": "hyperrealistic-likeness"
        },
        "face_image_1": {
          "examples": [
            "https://images.easelai.com/avatar_fal/female/female.png",
            "https://images.easelai.com/avatar_fal/male/male.png"
          ],
          "title": "Second users face image (optional)",
          "description": "(Optional) The second face image used to generate a two-person scene.",
          "allOf": [
            {
              "$ref": "#/components/schemas/Image"
            }
          ]
        },
        "face_image_0": {
          "examples": [
            "https://images.easelai.com/avatar_fal/male/male.png",
            "https://images.easelai.com/avatar_fal/female/female.png"
          ],
          "title": "The face image with which the scene is generated.",
          "description": "The face image with which the scene is generated.",
          "allOf": [
            {
              "$ref": "#/components/schemas/Image"
            }
          ]
        },
        "gender_0": {
          "enum": [
            "male",
            "female",
            "non-binary"
          ],
          "title": "User gender",
          "type": "string",
          "description": "The gender of the person in the face image"
        }
      },
      "x-fal-order-properties": [
        "face_image_0",
        "gender_0",
        "face_image_1",
        "gender_1",
        "prompt",
        "style"
      ],
      "required": [
        "face_image_0",
        "gender_0",
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/minimax/image-01",
    "name": "MiniMax (Hailuo AI) Text to Image",
    "description": "Generate high quality images from text prompts using MiniMax Image-01. Longer text prompts will result in better quality images.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/minimax-image/minimax.webp",
    "tags": [
      "stylized",
      "realism"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MiniMaxTextToImageRequest",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to enable automatic prompt optimization",
          "default": false
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 9,
          "description": "Number of images to generate (1-9)",
          "default": 1
        },
        "prompt": {
          "examples": [
            "Man dressed in white t shirt, full-body stand front view image, outdoor, Venice beach sign, full-body image, Los Angeles, Fashion photography of 90s, documentary, Film grain, photorealistic"
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 1500,
          "description": "Text prompt for image generation (max 1500 characters)",
          "minLength": 1
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "16:9",
            "4:3",
            "3:2",
            "2:3",
            "3:4",
            "9:16",
            "21:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated image",
          "default": "1:1"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "num_images",
        "prompt_optimizer"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/pony-v7",
    "name": "Pony V7",
    "description": "Pony V7 is a finetuned text to image for superior aesthetics and prompt following.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-5.jpg",
    "tags": [
      "diffusion",
      "style"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Input",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Close-up portrait of a majestic iguana with vibrant blue-green scales, piercing amber eyes, and orange spiky crest. Intricate textures and details visible on scaly skin. Wrapped in dark hood, giving regal appearance. Dramatic lighting against black background. Hyper-realistic, high-resolution image showcasing the reptile's expressive features and coloration."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate images from"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 2,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "noise_source": {
          "enum": [
            "gpu",
            "cpu"
          ],
          "title": "Noise Source",
          "type": "string",
          "description": "\n            The source of the noise to use for generating images.\n            If set to 'gpu', the noise will be generated on the GPU.\n            If set to 'cpu', the noise will be generated on the CPU.\n        ",
          "default": "gpu"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "Classifier free guidance scale",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for generating images"
        },
        "num_inference_steps": {
          "minimum": 20,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to take",
          "default": 40
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_images",
        "seed",
        "guidance_scale",
        "num_inference_steps",
        "noise_source",
        "sync_mode",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/ideogram/v3",
    "name": "Ideogram Text to Image",
    "description": "Generate high-quality images, posters, and logos with Ideogram V3. Features exceptional typography handling and realistic outputs optimized for commercial and creative use.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/koala/nTe9hpbTjo8BWgaGYTGzi_7b7c3112872b48b6be63734f9daa3f73.jpg",
    "tags": [
      "realism",
      "typography"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseTextToImageInputV3",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The Bone Forest stretched across the horizon, its trees fashioned from the ossified remains of ancient leviathans that once swam through the sky. Shamans with antlers growing from their shoulders and eyes that revealed the true nature of any being they beheld conducted rituals to commune with the spirits that still inhabited the calcified grove. In sky writes \"Ideogram V3 in fal.ai\""
          ],
          "title": "Prompt",
          "type": "string"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Image Size",
          "description": "The resolution of the generated image",
          "default": "square_hd"
        },
        "style": {
          "anyOf": [
            {
              "enum": [
                "AUTO",
                "GENERAL",
                "REALISTIC",
                "DESIGN"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Style",
          "description": "The style type to generate with. Cannot be used with style_codes."
        },
        "style_preset": {
          "anyOf": [
            {
              "enum": [
                "80S_ILLUSTRATION",
                "90S_NOSTALGIA",
                "ABSTRACT_ORGANIC",
                "ANALOG_NOSTALGIA",
                "ART_BRUT",
                "ART_DECO",
                "ART_POSTER",
                "AURA",
                "AVANT_GARDE",
                "BAUHAUS",
                "BLUEPRINT",
                "BLURRY_MOTION",
                "BRIGHT_ART",
                "C4D_CARTOON",
                "CHILDRENS_BOOK",
                "COLLAGE",
                "COLORING_BOOK_I",
                "COLORING_BOOK_II",
                "CUBISM",
                "DARK_AURA",
                "DOODLE",
                "DOUBLE_EXPOSURE",
                "DRAMATIC_CINEMA",
                "EDITORIAL",
                "EMOTIONAL_MINIMAL",
                "ETHEREAL_PARTY",
                "EXPIRED_FILM",
                "FLAT_ART",
                "FLAT_VECTOR",
                "FOREST_REVERIE",
                "GEO_MINIMALIST",
                "GLASS_PRISM",
                "GOLDEN_HOUR",
                "GRAFFITI_I",
                "GRAFFITI_II",
                "HALFTONE_PRINT",
                "HIGH_CONTRAST",
                "HIPPIE_ERA",
                "ICONIC",
                "JAPANDI_FUSION",
                "JAZZY",
                "LONG_EXPOSURE",
                "MAGAZINE_EDITORIAL",
                "MINIMAL_ILLUSTRATION",
                "MIXED_MEDIA",
                "MONOCHROME",
                "NIGHTLIFE",
                "OIL_PAINTING",
                "OLD_CARTOONS",
                "PAINT_GESTURE",
                "POP_ART",
                "RETRO_ETCHING",
                "RIVIERA_POP",
                "SPOTLIGHT_80S",
                "STYLIZED_RED",
                "SURREAL_COLLAGE",
                "TRAVEL_POSTER",
                "VINTAGE_GEO",
                "VINTAGE_POSTER",
                "WATERCOLOR",
                "WEIRD",
                "WOODBLOCK_PRINT"
              ],
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Style Preset",
          "description": "Style preset for generation. The chosen style preset will guide the generation."
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Determine if MagicPrompt should be used in generating the request or not.",
          "default": true
        },
        "rendering_speed": {
          "enum": [
            "TURBO",
            "BALANCED",
            "QUALITY"
          ],
          "title": "Rendering Speed",
          "type": "string",
          "description": "The rendering speed to use.",
          "default": "BALANCED"
        },
        "style_codes": {
          "anyOf": [
            {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            {
              "type": "null"
            }
          ],
          "title": "Style Codes",
          "description": "A list of 8 character hexadecimal codes representing the style of the image. Cannot be used in conjunction with style_reference_images or style"
        },
        "color_palette": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ColorPalette"
            },
            {
              "type": "null"
            }
          ],
          "description": "A color palette for generation, must EITHER be specified via one of the presets (name) or explicitly via hexadecimal representations of the color with optional weights (members)"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for the random number generator"
        },
        "image_urls": {
          "anyOf": [
            {
              "type": "array",
              "items": {
                "type": "string"
              }
            },
            {
              "type": "null"
            }
          ],
          "title": "Image Urls",
          "description": "A set of images to use as style references (maximum total size 10MB across all style references). The images should be in JPEG, PNG or WebP format"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Description of what to exclude from an image. Descriptions in the prompt take precedence to descriptions in the negative prompt.",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "image_urls",
        "rendering_speed",
        "color_palette",
        "style_codes",
        "style",
        "expand_prompt",
        "num_images",
        "seed",
        "sync_mode",
        "style_preset",
        "prompt",
        "image_size",
        "negative_prompt"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/f-lite/standard",
    "name": "F Lite",
    "description": "F Lite is a 10B parameter diffusion model created by Fal and Freepik, trained exclusively on copyright-safe and SFW content.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-4.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInputStandard",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Mount Fuji at sunset, with the iconic snow-capped peak silhouetted against a vibrant orange and purple sky. A tranquil lake in the foreground perfectly reflects the mountain and colorful sky. A few traditional Japanese cherry blossom trees frame the scene, with their delicate pink petals visible in the foreground."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "maximum": 20,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            "Blurry, out of focus, low resolution, bad anatomy, ugly, deformed, poorly drawn, extra limbs"
          ],
          "title": "Negative prompt",
          "type": "string",
          "description": "Negative Prompt for generation.",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/f-lite/texture",
    "name": "F Lite (texture mode)",
    "description": "F Lite is a 10B parameter diffusion model created by Fal and Freepik, trained exclusively on copyright-safe and SFW content. This is a high texture density variant of the model.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInputTexture",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Mount Fuji at sunset, with the iconic snow-capped peak silhouetted against a vibrant orange and purple sky. A tranquil lake in the foreground perfectly reflects the mountain and colorful sky. A few traditional Japanese cherry blossom trees frame the scene, with their delicate pink petals visible in the foreground."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "maximum": 20,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            "Blurry, out of focus, low resolution, bad anatomy, ugly, deformed, poorly drawn, extra limbs"
          ],
          "title": "Negative prompt",
          "type": "string",
          "description": "Negative Prompt for generation.",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/gpt-image-1/text-to-image",
    "name": "gpt-image-1",
    "description": "OpenAI's latest image generation and editing model: gpt-1-image.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A serene cyberpunk cityscape at twilight, with neon signs glowing in vibrant blues and purples, reflecting on rain-slick streets. Sleek futuristic buildings tower above, connected by glowing skybridges. A lone figure in a hooded jacket stands under a streetlamp, backlit by soft mist. The atmosphere is cinematic, moody"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt for image generation",
          "minLength": 2
        },
        "num_images": {
          "description": "Number of images to generate",
          "type": "integer",
          "examples": [
            1
          ],
          "title": "Number of Images",
          "maximum": 4,
          "minimum": 1,
          "default": 1
        },
        "image_size": {
          "enum": [
            "auto",
            "1024x1024",
            "1536x1024",
            "1024x1536"
          ],
          "title": "Image Size",
          "type": "string",
          "description": "Aspect ratio for the generated image",
          "default": "auto"
        },
        "background": {
          "enum": [
            "auto",
            "transparent",
            "opaque"
          ],
          "title": "Background",
          "type": "string",
          "description": "Background for the generated image",
          "default": "auto"
        },
        "quality": {
          "enum": [
            "auto",
            "low",
            "medium",
            "high"
          ],
          "title": "Quality",
          "type": "string",
          "description": "Quality for the generated image",
          "default": "auto"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "Output format for the images",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "background",
        "quality",
        "num_images",
        "output_format",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "1000 tokens",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/sana/v1.5/1.6b",
    "name": "Sana v1.5 1.6B",
    "description": "Sana v1.5 1.6B is a lightweight text-to-image model that delivers 4K image generation with impressive efficiency.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/sana.webp",
    "tags": [
      "text to image",
      "4k",
      "lightweight"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Underwater coral reef ecosystem during peak bioluminescent activity, multiple layers of marine life - from microscopic plankton to massive coral structures, light refracting through crystal-clear tropical waters, creating prismatic color gradients, hyper-detailed texture of marine organisms"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": {
            "height": 2160,
            "width": 3840
          }
        },
        "style_name": {
          "enum": [
            "(No style)",
            "Cinematic",
            "Photographic",
            "Anime",
            "Manga",
            "Digital Art",
            "Pixel art",
            "Fantasy art",
            "Neonpunk",
            "3D Model"
          ],
          "title": "Style Name",
          "type": "string",
          "description": "The style to generate the image in.",
          "default": "(No style)"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 18
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "style_name"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/sana/v1.5/4.8b",
    "name": "Sana v1.5 4.8B",
    "description": "Sana v1.5 4.8B is a powerful text-to-image model that generates ultra-high quality 4K images with remarkable detail.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/sana.webp",
    "tags": [
      "text to image",
      "4k",
      "high-quality"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Underwater coral reef ecosystem during peak bioluminescent activity, multiple layers of marine life - from microscopic plankton to massive coral structures, light refracting through crystal-clear tropical waters, creating prismatic color gradients, hyper-detailed texture of marine organisms"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": {
            "height": 2160,
            "width": 3840
          }
        },
        "style_name": {
          "enum": [
            "(No style)",
            "Cinematic",
            "Photographic",
            "Anime",
            "Manga",
            "Digital Art",
            "Pixel art",
            "Fantasy art",
            "Neonpunk",
            "3D Model"
          ],
          "title": "Style Name",
          "type": "string",
          "description": "The style to generate the image in.",
          "default": "(No style)"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 18
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "style_name"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/sana/sprint",
    "name": "Sana Sprint",
    "description": "Sana Sprint is a text-to-image model capable of generating 4K images with exceptional speed.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-6.jpeg",
    "tags": [
      "text to image",
      "4k",
      "high-speed"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SprintInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Underwater coral reef ecosystem during peak bioluminescent activity, multiple layers of marine life - from microscopic plankton to massive coral structures, light refracting through crystal-clear tropical waters, creating prismatic color gradients, hyper-detailed texture of marine organisms"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": {
            "height": 2160,
            "width": 3840
          }
        },
        "style_name": {
          "enum": [
            "(No style)",
            "Cinematic",
            "Photographic",
            "Anime",
            "Manga",
            "Digital Art",
            "Pixel art",
            "Fantasy art",
            "Neonpunk",
            "3D Model"
          ],
          "title": "Style Name",
          "type": "string",
          "description": "The style to generate the image in.",
          "default": "(No style)"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 20,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 2
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "style_name"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux/lightning",
    "name": "Juggernaut Flux Lightning",
    "description": "Juggernaut Lightning Flux by RunDiffusion provides blazing-fast, high-quality images rendered at five times the speed of Flux. Perfect for mood boards and mass ideation, this model excels in both realism and prompt adherence.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-lightning.webp",
    "tags": [
      "image generation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SchnellTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 12,
          "description": "The number of inference steps to perform.",
          "default": 4
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "rundiffusion-fal/rundiffusion-photo-flux",
    "name": "Rundiffusion Photo Flux",
    "description": "RunDiffusion Photo Flux provides insane realism. With this enhancer, textures and skin details burst to life, turning your favorite prompts into vivid, lifelike creations. Recommended to keep it at 0.65 to 0.80 weight. Supports resolutions up to 1536x1536.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/rundiffusion-photo-flux.webp",
    "tags": [
      "image generation",
      "lora"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "PhotoLoraT2IInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 35,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "photo_lora_scale": {
          "title": "Photo Lora Scale",
          "type": "number",
          "description": "LoRA Scale of the photo lora model",
          "default": 0.75
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "photo_lora_scale",
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux-lora",
    "name": "Juggernaut Flux Base LoRA",
    "description": "Juggernaut Base Flux LoRA by RunDiffusion is a drop-in replacement for Flux [Dev] that delivers sharper details, richer colors, and enhanced realism to all your LoRAs and LyCORIS with full compatibility.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-lora.webp",
    "tags": [
      "image generation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 35,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux/pro",
    "name": "Juggernaut Flux Pro",
    "description": "Juggernaut Pro Flux by RunDiffusion is the flagship Juggernaut model rivaling some of the most advanced image models available, often surpassing them in realism. It combines Juggernaut Base with RunDiffusion Photo and features enhancements like reduced background blurriness.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-pro.webp",
    "tags": [
      "image generation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "DevTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "maximum": 20,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "rundiffusion-fal/juggernaut-flux/base",
    "name": "Juggernaut Flux Base",
    "description": "Juggernaut Base Flux by RunDiffusion is a drop-in replacement for Flux [Dev] that delivers sharper details, richer colors, and enhanced realism, while instantly boosting LoRAs and LyCORIS with full compatibility.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/juggernaut-flux-base.webp",
    "tags": [
      "image generation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "DevTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "maximum": 20,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/cogview4",
    "name": "CogView",
    "description": "Generate high quality images from text prompts using CogView4. Longer text prompts will result in better quality images.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/CogView4/CogView4.webp",
    "tags": [
      "stylized"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A vibrant and artistic digital composition featuring colorful splashes of paint in the background, creating an energetic and dynamic effect. The text 'CogView4 on Fal' is elegantly integrated into the scene, standing out with a modern, bold, and slightly futuristic font. The colors are bright and varied, including neon blues, purples, pinks, and oranges, blending seamlessly in a fluid, abstract style. The text appears slightly illuminated, complementing the vivid splashes around it."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 50
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "negative_prompt",
        "seed",
        "guidance_scale",
        "num_inference_steps",
        "num_images",
        "sync_mode",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/ideogram/v2a/turbo",
    "name": "Ideogram V2A Turbo",
    "description": "Accelerated image generation with Ideogram V2A Turbo. Create high-quality visuals, posters, and logos with enhanced speed while maintaining Ideogram's signature quality.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/zebra/G9QL1XoVt8ZMvbYwA3Zrw_15ff55eb74a0429eaeb9a288e71763ef.jpg",
    "tags": [
      "realism",
      "typography"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A comic style illustration of a skeleton sitting on a toilet in a bathroom. The bathroom has a Halloween decoration with a pumpkin jack-o-lantern and bats flying around. There is a text above the skeleton that says \"Just Waiting for Halloween with Ideogram 2.0 at fal.ai\""
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "10:16",
            "16:10",
            "9:16",
            "16:9",
            "4:3",
            "3:4",
            "1:1",
            "1:3",
            "3:1",
            "3:2",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image",
          "default": "1:1"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "style": {
          "enum": [
            "auto",
            "general",
            "realistic",
            "design",
            "render_3D",
            "anime"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style of the generated image",
          "default": "auto"
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for the random number generator"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt with MagicPrompt functionality.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "expand_prompt",
        "seed",
        "style",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/ideogram/v2a",
    "name": "Ideogram V2A",
    "description": "Generate high-quality images, posters, and logos with Ideogram V2A. Features exceptional typography handling and realistic outputs optimized for commercial and creative use.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/monkey/mYGi5w1eEI_yIOrXfqMPk_e233dd6442da4904b2bc2fd83f8915f8.jpg",
    "tags": [
      "realism",
      "typography"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A comic style illustration of a skeleton sitting on a toilet in a bathroom. The bathroom has a Halloween decoration with a pumpkin jack-o-lantern and bats flying around. There is a text above the skeleton that says \"Just Waiting for Halloween with Ideogram 2.0 at fal.ai\""
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "10:16",
            "16:10",
            "9:16",
            "16:9",
            "4:3",
            "3:4",
            "1:1",
            "1:3",
            "3:1",
            "3:2",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image",
          "default": "1:1"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "style": {
          "enum": [
            "auto",
            "general",
            "realistic",
            "design",
            "render_3D",
            "anime"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style of the generated image",
          "default": "auto"
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for the random number generator"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt with MagicPrompt functionality.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "expand_prompt",
        "seed",
        "style",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/flux-control-lora-canny",
    "name": "FLUX.1 [dev] Control LoRA Canny",
    "description": "FLUX Control LoRA Canny is a high-performance endpoint that uses a control image to transfer structure to the generated image, using a Canny edge map.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/control-lora-canny.jpeg",
    "tags": [
      "lora",
      "style transfer"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "control_lora_strength": {
          "minimum": 0,
          "title": "Control Lora Strength",
          "type": "number",
          "maximum": 2,
          "description": "The strength of the control lora.",
          "default": 1
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "maximum": 35,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "control_lora_image_url": {
          "title": "Control Lora Image Url",
          "type": "string",
          "description": "\n            The image to use for control lora. This is used to control the style of the generated image.\n        "
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "control_lora_image_url",
        "control_lora_strength"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-control-lora-depth",
    "name": "FLUX.1 [dev] Control LoRA Depth",
    "description": "FLUX Control LoRA Depth is a high-performance endpoint that uses a control image to transfer structure to the generated image, using a depth map.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/control-lora-depth.jpeg",
    "tags": [
      "lora",
      "style transfer"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "DepthLoraInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "control_lora_strength": {
          "minimum": 0,
          "maximum": 2,
          "type": "number",
          "title": "Control Lora Strength",
          "description": "The strength of the control lora.",
          "default": 1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "preprocess_depth": {
          "title": "Preprocess Depth",
          "type": "boolean",
          "description": "\n            If set to true, the input image will be preprocessed to extract depth information.\n            This is useful for generating depth maps from images.\n        ",
          "default": true
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "control_lora_image_url": {
          "title": "Control Lora Image Url",
          "type": "string",
          "description": "\n            The image to use for control lora. This is used to control the style of the generated image.\n        "
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 35,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "control_lora_image_url",
        "control_lora_strength",
        "preprocess_depth"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/imagen3",
    "name": "Imagen3",
    "description": "Imagen3 is a high-quality text-to-image model that generates realistic images from text prompts.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/imagen3/imagen.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A serene landscape with mountains reflected in a crystal clear lake at sunset"
          ],
          "description": "The text prompt describing what you want to see",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "16:9",
            "9:16",
            "3:4",
            "4:3"
          ],
          "description": "The aspect ratio of the generated image",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "1:1"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate (1-4)",
          "default": 1
        },
        "seed": {
          "description": "Random seed for reproducible generation",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "description": "A description of what to discourage in the generated images",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "aspect_ratio",
        "num_images",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/imagen3/fast",
    "name": "Imagen3 Fast",
    "description": "Imagen3 Fast is a high-quality text-to-image model that generates realistic images from text prompts.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/imagen3/imagen.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A serene landscape with mountains reflected in a crystal clear lake at sunset"
          ],
          "description": "The text prompt describing what you want to see",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "16:9",
            "9:16",
            "3:4",
            "4:3"
          ],
          "description": "The aspect ratio of the generated image",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "1:1"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate (1-4)",
          "default": 1
        },
        "seed": {
          "description": "Random seed for reproducible generation",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "description": "A description of what to discourage in the generated images",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "aspect_ratio",
        "num_images",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/lumina-image/v2",
    "name": "Lumina Image 2",
    "description": "Lumina-Image-2.0 is a 2 billion parameter flow-based diffusion transforer which features improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/lumina-image-v2.webp",
    "tags": [
      "diffusion",
      "typography",
      "style"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A vibrant and artistic digital composition featuring colorful splashes of paint in the background, creating an energetic and dynamic effect. The text 'Lumina on Fal' is elegantly integrated into the scene, standing out with a modern, bold, and slightly futuristic font. The colors are bright and varied, including neon blues, purples, pinks, and oranges, blending seamlessly in a fluid, abstract style. The text appears slightly illuminated, complementing the vivid splashes around it."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "cfg_trunc_ratio": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Cfg Trunc Ratio",
          "description": "The ratio of the timestep interval to apply normalization-based guidance scale.",
          "default": 1
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "system_prompt": {
          "title": "System Prompt",
          "type": "string",
          "description": "The system prompt to use.",
          "default": "You are an assistant designed to generate superior images with the superior degree of image-text alignment based on textual prompts or user prompts."
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 30
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "cfg_normalization": {
          "title": "Cfg Normalization",
          "type": "boolean",
          "description": "Whether to apply normalization-based guidance scale.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "negative_prompt",
        "system_prompt",
        "seed",
        "guidance_scale",
        "num_inference_steps",
        "cfg_normalization",
        "cfg_trunc_ratio",
        "num_images",
        "sync_mode",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/janus",
    "name": "DeepSeek Janus-Pro",
    "description": "DeepSeek Janus-Pro is a novel text-to-image model that unifies multimodal understanding and generation through an autoregressive framework",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/janus/januspro.webp",
    "tags": [
      "stylized"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "JanusInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "beautiful girl, inside a house"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 16,
          "type": "integer",
          "title": "Num Images",
          "description": "Number of images to generate in parallel.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square"
        },
        "cfg_weight": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Cfg Weight",
          "description": "Classifier Free Guidance scale - how closely to follow the prompt.",
          "default": 5
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "temperature": {
          "minimum": 0.1,
          "maximum": 2,
          "type": "number",
          "title": "Temperature",
          "description": "Controls randomness in the generation. Higher values make output more random.",
          "default": 1
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Random seed for reproducible generation."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "temperature",
        "cfg_weight",
        "num_images",
        "seed",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-pro/v1.1",
    "name": "FLUX1.1 [pro]",
    "description": "FLUX1.1 [pro] is an enhanced version of FLUX.1 [pro], improved image generation capabilities, delivering superior composition, detail, and artistic fidelity compared to its predecessor.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/turbo_thumbnail.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FluxProPlusTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6"
          ],
          "title": "Safety Tolerance",
          "type": "string",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "default": "2"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enhance_prompt": {
          "title": "Enhance Prompt",
          "type": "boolean",
          "description": "Whether to enhance the prompt for better results.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "seed",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "safety_tolerance",
        "enhance_prompt"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-pro/v1.1-ultra-finetuned",
    "name": "FLUX1.1 [pro] ultra Fine-tuned",
    "description": "FLUX1.1 [pro] ultra fine-tuned is the newest version of FLUX1.1 [pro] with a fine-tuned LoRA, maintaining professional-grade image quality while delivering up to 2K resolution with improved photo realism.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/flux-pro-11-ultra.webp",
    "tags": [
      "high-res",
      "realism"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FluxProUltraTextToImageFinetunedInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "finetune_id": {
          "title": "Fine-tune ID",
          "type": "string",
          "description": "References your specific model"
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6"
          ],
          "title": "Safety Tolerance",
          "type": "string",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "default": "2"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "image_prompt_strength": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Image Prompt Strength",
          "description": "The strength of the image prompt, between 0 and 1.",
          "default": 0.1
        },
        "enhance_prompt": {
          "title": "Enhance Prompt",
          "type": "boolean",
          "description": "Whether to enhance the prompt for better results.",
          "default": false
        },
        "raw": {
          "title": "Raw",
          "type": "boolean",
          "description": "Generate less processed, more natural-looking images.",
          "default": false
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "aspect_ratio": {
          "anyOf": [
            {
              "enum": [
                "21:9",
                "16:9",
                "4:3",
                "3:2",
                "1:1",
                "2:3",
                "3:4",
                "9:16",
                "9:21"
              ],
              "type": "string"
            },
            {
              "type": "string"
            }
          ],
          "title": "Aspect Ratio",
          "description": "The aspect ratio of the generated image.",
          "default": "16:9"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "title": "Image URL",
          "type": "string",
          "description": "The image URL to generate an image from."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "finetune_strength": {
          "minimum": 0,
          "maximum": 2,
          "type": "number",
          "title": "Fine-tune Strength",
          "description": "\n        Controls finetune influence.\n        Increase this value if your target concept isn't showing up strongly enough.\n        The optimal setting depends on your finetune and prompt\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "safety_tolerance",
        "enhance_prompt",
        "image_url",
        "image_prompt_strength",
        "aspect_ratio",
        "raw",
        "finetune_id",
        "finetune_strength"
      ],
      "required": [
        "prompt",
        "finetune_id",
        "finetune_strength"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/switti",
    "name": "Switti 1024",
    "description": "Switti is a scale-wise transformer for fast text-to-image generation that outperforms existing T2I AR models and competes with state-of-the-art T2I diffusion models while being faster than distilled diffusion models.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/switti.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cat wearing a hoodie with 'FAL' written on it."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "sampling_top_k": {
          "minimum": 10,
          "maximum": 1000,
          "type": "integer",
          "title": "Sampling Top-k",
          "description": "The number of top-k tokens to sample from.",
          "default": 400
        },
        "turn_off_cfg_start_si": {
          "minimum": 0,
          "maximum": 10,
          "type": "integer",
          "title": "Disable CFG starting scale",
          "description": "Disable CFG starting scale",
          "default": 8
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 6
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "smooth_start_si": {
          "minimum": 0,
          "maximum": 10,
          "type": "integer",
          "title": "Smoothing starting scale",
          "description": "Smoothing starting scale",
          "default": 2
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "last_scale_temp": {
          "minimum": 0.1,
          "maximum": 10,
          "type": "number",
          "title": "Temperature after disabling CFG",
          "description": "Temperature after disabling CFG",
          "default": 0.1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "more_diverse": {
          "title": "More Diverse",
          "type": "boolean",
          "description": "More diverse sampling",
          "default": false
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "more_smooth": {
          "title": "More Smooth",
          "type": "boolean",
          "description": "Smoothing with Gumbel softmax sampling",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "sampling_top_p": {
          "minimum": 0.1,
          "maximum": 1,
          "type": "number",
          "title": "Sampling Top-p",
          "description": "The top-p probability to sample from.",
          "default": 0.95
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "sampling_top_k",
        "sampling_top_p",
        "more_smooth",
        "more_diverse",
        "smooth_start_si",
        "turn_off_cfg_start_si",
        "last_scale_temp",
        "seed",
        "guidance_scale",
        "sync_mode",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/switti/512",
    "name": "Switti 512",
    "description": "Switti is a scale-wise transformer for fast text-to-image generation that outperforms existing T2I AR models and competes with state-of-the-art T2I diffusion models while being faster than distilled diffusion models.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/switti.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cat wearing a hoodie with 'FAL' written on it."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "sampling_top_k": {
          "minimum": 10,
          "maximum": 1000,
          "type": "integer",
          "title": "Sampling Top-k",
          "description": "The number of top-k tokens to sample from.",
          "default": 400
        },
        "turn_off_cfg_start_si": {
          "minimum": 0,
          "maximum": 10,
          "type": "integer",
          "title": "Disable CFG starting scale",
          "description": "Disable CFG starting scale",
          "default": 8
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 6
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "smooth_start_si": {
          "minimum": 0,
          "maximum": 10,
          "type": "integer",
          "title": "Smoothing starting scale",
          "description": "Smoothing starting scale",
          "default": 2
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "last_scale_temp": {
          "minimum": 0.1,
          "maximum": 10,
          "type": "number",
          "title": "Temperature after disabling CFG",
          "description": "Temperature after disabling CFG",
          "default": 0.1
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "more_diverse": {
          "title": "More Diverse",
          "type": "boolean",
          "description": "More diverse sampling",
          "default": false
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "more_smooth": {
          "title": "More Smooth",
          "type": "boolean",
          "description": "Smoothing with Gumbel softmax sampling",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "sampling_top_p": {
          "minimum": 0.1,
          "maximum": 1,
          "type": "number",
          "title": "Sampling Top-p",
          "description": "The top-p probability to sample from.",
          "default": 0.95
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "sampling_top_k",
        "sampling_top_p",
        "more_smooth",
        "more_diverse",
        "smooth_start_si",
        "turn_off_cfg_start_si",
        "last_scale_temp",
        "seed",
        "guidance_scale",
        "sync_mode",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/bria/text-to-image/fast",
    "name": "Bria Text-to-Image Fast",
    "description": "Bria's Text-to-Image model with perfect harmony of latency and quality. Trained exclusively on licensed data for safe and risk-free commercial use. Available also as source code and weights. For access to weights: https://bria.ai/contact-us",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "tags": [
      "image generation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastTextToImageRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A lone figure stands on the edge of a serene cliff at sunset, gazing out over a vast, mystical valley. The figure is clad in flowing robes that ripple in the gentle breeze, silhouetted against the golden and lavender hues of the sky. Below, a cascading waterfall pours into a sparkling river winding through a forest of bioluminescent trees. The scene blends the awe of nature with a touch of otherworldly wonder, inviting reflection and imagination."
          ],
          "description": "The prompt you would like to use to generate images.",
          "minLength": 1,
          "title": "Prompt",
          "type": "string"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "How many images you would like to generate. When using any Guidance Method, Value is set to 1.",
          "default": 4
        },
        "prompt_enhancement": {
          "description": "When set to true, enhances the provided prompt by generating additional, more descriptive variations, resulting in more diverse and creative output images.",
          "type": "boolean",
          "title": "Prompt Enhancement",
          "default": false
        },
        "guidance": {
          "description": "Guidance images to use for the generation. Up to 4 guidance methods can be combined during a single inference.",
          "type": "array",
          "title": "Guidance",
          "items": {
            "$ref": "#/components/schemas/GuidanceInput"
          },
          "default": []
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "2:3",
            "3:2",
            "3:4",
            "4:3",
            "4:5",
            "5:4",
            "9:16",
            "16:9"
          ],
          "description": "The aspect ratio of the image. When a guidance method is being used, the aspect ratio is defined by the guidance image and this parameter is ignored.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "1:1"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 4,
          "maximum": 10,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of iterations the model goes through to refine the generated image. This parameter is optional.",
          "default": 8
        },
        "seed": {
          "minimum": 0,
          "maximum": 2147483647,
          "type": "integer",
          "title": "Seed",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "description": "The negative prompt you would like to use to generate images.",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        },
        "medium": {
          "enum": [
            "photography",
            "art"
          ],
          "description": "Which medium should be included in your generated images. This parameter is optional.",
          "type": "string",
          "title": "Medium"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_images",
        "aspect_ratio",
        "seed",
        "num_inference_steps",
        "guidance_scale",
        "prompt_enhancement",
        "medium",
        "guidance",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "generations"
  },
  {
    "id": "fal-ai/bria/text-to-image/base",
    "name": "Bria Text-to-Image Base",
    "description": "Bria's Text-to-Image model, trained exclusively on licensed data for safe and risk-free commercial use. Available also as source code and weights. For access to weights: https://bria.ai/contact-us",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "tags": [
      "image generation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A lone figure stands on the edge of a serene cliff at sunset, gazing out over a vast, mystical valley. The figure is clad in flowing robes that ripple in the gentle breeze, silhouetted against the golden and lavender hues of the sky. Below, a cascading waterfall pours into a sparkling river winding through a forest of bioluminescent trees. The scene blends the awe of nature with a touch of otherworldly wonder, inviting reflection and imagination."
          ],
          "description": "The prompt you would like to use to generate images.",
          "minLength": 1,
          "title": "Prompt",
          "type": "string"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "How many images you would like to generate. When using any Guidance Method, Value is set to 1.",
          "default": 4
        },
        "prompt_enhancement": {
          "description": "When set to true, enhances the provided prompt by generating additional, more descriptive variations, resulting in more diverse and creative output images.",
          "type": "boolean",
          "title": "Prompt Enhancement",
          "default": false
        },
        "guidance": {
          "description": "Guidance images to use for the generation. Up to 4 guidance methods can be combined during a single inference.",
          "type": "array",
          "title": "Guidance",
          "items": {
            "$ref": "#/components/schemas/GuidanceInput"
          },
          "default": []
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "2:3",
            "3:2",
            "3:4",
            "4:3",
            "4:5",
            "5:4",
            "9:16",
            "16:9"
          ],
          "description": "The aspect ratio of the image. When a guidance method is being used, the aspect ratio is defined by the guidance image and this parameter is ignored.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "1:1"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 20,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of iterations the model goes through to refine the generated image. This parameter is optional.",
          "default": 30
        },
        "seed": {
          "minimum": 0,
          "maximum": 2147483647,
          "type": "integer",
          "title": "Seed",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "description": "The negative prompt you would like to use to generate images.",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        },
        "medium": {
          "enum": [
            "photography",
            "art"
          ],
          "description": "Which medium should be included in your generated images. This parameter is optional.",
          "type": "string",
          "title": "Medium"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_images",
        "aspect_ratio",
        "seed",
        "num_inference_steps",
        "guidance_scale",
        "prompt_enhancement",
        "medium",
        "guidance",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "generations"
  },
  {
    "id": "fal-ai/bria/text-to-image/hd",
    "name": "Bria Text-to-Image HD",
    "description": "Bria's Text-to-Image model for HD images. Trained exclusively on licensed data for safe and risk-free commercial use. Available also as source code and weights. For access to weights: https://bria.ai/contact-us",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/bria.webp",
    "tags": [
      "image generation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A lone figure stands on the edge of a serene cliff at sunset, gazing out over a vast, mystical valley. The figure is clad in flowing robes that ripple in the gentle breeze, silhouetted against the golden and lavender hues of the sky. Below, a cascading waterfall pours into a sparkling river winding through a forest of bioluminescent trees. The scene blends the awe of nature with a touch of otherworldly wonder, inviting reflection and imagination."
          ],
          "description": "The prompt you would like to use to generate images.",
          "minLength": 1,
          "title": "Prompt",
          "type": "string"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "How many images you would like to generate. When using any Guidance Method, Value is set to 1.",
          "default": 4
        },
        "prompt_enhancement": {
          "description": "When set to true, enhances the provided prompt by generating additional, more descriptive variations, resulting in more diverse and creative output images.",
          "type": "boolean",
          "title": "Prompt Enhancement",
          "default": false
        },
        "guidance": {
          "description": "Guidance images to use for the generation. Up to 4 guidance methods can be combined during a single inference.",
          "type": "array",
          "title": "Guidance",
          "items": {
            "$ref": "#/components/schemas/GuidanceInput"
          },
          "default": []
        },
        "aspect_ratio": {
          "enum": [
            "1:1",
            "2:3",
            "3:2",
            "3:4",
            "4:3",
            "4:5",
            "5:4",
            "9:16",
            "16:9"
          ],
          "description": "The aspect ratio of the image. When a guidance method is being used, the aspect ratio is defined by the guidance image and this parameter is ignored.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "1:1"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 20,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of iterations the model goes through to refine the generated image. This parameter is optional.",
          "default": 30
        },
        "seed": {
          "minimum": 0,
          "maximum": 2147483647,
          "type": "integer",
          "title": "Seed",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "description": "The negative prompt you would like to use to generate images.",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        },
        "medium": {
          "enum": [
            "photography",
            "art"
          ],
          "description": "Which medium should be included in your generated images. This parameter is optional.",
          "type": "string",
          "title": "Medium"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_images",
        "aspect_ratio",
        "seed",
        "num_inference_steps",
        "guidance_scale",
        "prompt_enhancement",
        "medium",
        "guidance",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "generations"
  },
  {
    "id": "fal-ai/recraft-20b",
    "name": "Recraft 20b",
    "description": "Recraft 20b is a new and affordable text-to-image model.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_011.jpg",
    "tags": [
      "image generation",
      "vector art",
      "typograph",
      "style"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Recraft20BTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "a red panda in Kyoto"
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 1000,
          "minLength": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "default": "square_hd"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "colors": {
          "title": "Colors",
          "type": "array",
          "description": "An array of preferable colors",
          "items": {
            "$ref": "#/components/schemas/RGBColor"
          },
          "default": []
        },
        "style": {
          "enum": [
            "any",
            "realistic_image",
            "digital_illustration",
            "vector_illustration",
            "realistic_image/b_and_w",
            "realistic_image/enterprise",
            "realistic_image/hard_flash",
            "realistic_image/hdr",
            "realistic_image/motion_blur",
            "realistic_image/natural_light",
            "realistic_image/studio_portrait",
            "digital_illustration/2d_art_poster",
            "digital_illustration/2d_art_poster_2",
            "digital_illustration/3d",
            "digital_illustration/80s",
            "digital_illustration/engraving_color",
            "digital_illustration/glow",
            "digital_illustration/grain",
            "digital_illustration/hand_drawn",
            "digital_illustration/hand_drawn_outline",
            "digital_illustration/handmade_3d",
            "digital_illustration/infantile_sketch",
            "digital_illustration/kawaii",
            "digital_illustration/pixel_art",
            "digital_illustration/psychedelic",
            "digital_illustration/seamless",
            "digital_illustration/voxel",
            "digital_illustration/watercolor",
            "vector_illustration/cartoon",
            "vector_illustration/doodle_line_art",
            "vector_illustration/engraving",
            "vector_illustration/flat_2",
            "vector_illustration/kawaii",
            "vector_illustration/line_art",
            "vector_illustration/line_circuit",
            "vector_illustration/linocut",
            "vector_illustration/seamless",
            "icon/broken_line",
            "icon/colored_outline",
            "icon/colored_shapes",
            "icon/colored_shapes_gradient",
            "icon/doodle_fill",
            "icon/doodle_offset_fill",
            "icon/offset_fill",
            "icon/outline",
            "icon/outline_gradient",
            "icon/uneven_fill"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style of the generated images. Vector images cost 2X as much.",
          "default": "realistic_image"
        },
        "style_id": {
          "format": "uuid4",
          "title": "Style Id",
          "type": "string",
          "description": "The ID of the custom style reference (optional)"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "style",
        "colors",
        "style_id",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/ideogram/v2/turbo",
    "name": "Ideogram V2 Turbo",
    "description": "Accelerated image generation with Ideogram V2 Turbo. Create high-quality visuals, posters, and logos with enhanced speed while maintaining Ideogram's signature quality.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/ideogram.webp",
    "tags": [
      "realism",
      "typography"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A comic style illustration of a skeleton sitting on a toilet in a bathroom. The bathroom has a Halloween decoration with a pumpkin jack-o-lantern and bats flying around. There is a text above the skeleton that says \"Just Waiting for Halloween with Ideogram 2.0 at fal.ai\""
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "10:16",
            "16:10",
            "9:16",
            "16:9",
            "4:3",
            "3:4",
            "1:1",
            "1:3",
            "3:1",
            "3:2",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated image",
          "default": "1:1"
        },
        "style": {
          "enum": [
            "auto",
            "general",
            "realistic",
            "design",
            "render_3D",
            "anime"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style of the generated image",
          "default": "auto"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt with MagicPrompt functionality.",
          "default": true
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for the random number generator"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "A negative prompt to avoid in the generated image",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "expand_prompt",
        "seed",
        "style",
        "sync_mode",
        "negative_prompt"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/luma-photon/flash",
    "name": "Luma Photon Flash",
    "description": "Generate images from your prompts using Luma Photon Flash. Photon Flash is the most creative, personalizable, and intelligent visual models for creatives, bringing a step-function change in the cost of high-quality image generation.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/luma-photon.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A teddy bear in sunglasses playing electric guitar and dancing"
          ],
          "maxLength": 5000,
          "type": "string",
          "minLength": 3,
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1",
            "4:3",
            "3:4",
            "21:9",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "1:1"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/aura-flow",
    "name": "AuraFlow",
    "description": "AuraFlow v0.3 is an open-source flow-based text-to-image generation model that achieves state-of-the-art results on GenEval. The model is currently in beta.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/aura-flow.webp",
    "tags": [
      "typography",
      "style"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Input",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Close-up portrait of a majestic iguana with vibrant blue-green scales, piercing amber eyes, and orange spiky crest. Intricate textures and details visible on scaly skin. Wrapped in dark hood, giving regal appearance. Dramatic lighting against black background. Hyper-realistic, high-resolution image showcasing the reptile's expressive features and coloration."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate images from"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 2,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate",
          "default": 1
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to perform prompt expansion (recommended)",
          "default": true
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "Classifier free guidance scale",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 20,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to take",
          "default": 50
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for generating images"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_images",
        "seed",
        "guidance_scale",
        "num_inference_steps",
        "expand_prompt",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/omnigen-v1",
    "name": "OmniGen v1",
    "description": "OmniGen is a unified image generation model that can generate a wide range of images from multi-modal prompts. It can be used for various tasks such as Image Editing, Personalized Image Generation, Virtual Try-On, Multi Person Generation and more!",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/omnigen-v1.webp",
    "tags": [
      "multimodal",
      "editing",
      "try-on"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Neon words \"Omni Gen\" are flashing in the prosperous future city, the sense of science and technology, quality details, hyper realistic, high definition, 8K, photo, best quality, high quality."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "img_guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Image Guidance scale",
          "description": "\n            The Image Guidance scale is a measure of how close you want\n            the model to stick to your input image when looking for a related image to show you.\n        ",
          "default": 1.6
        },
        "input_image_urls": {
          "description": "URL of images to use while generating the image, Use <img><|image_1|></img> for the first image and so on.",
          "type": "array",
          "items": {
            "type": "string"
          },
          "examples": [],
          "title": "Input Image Urls",
          "default": []
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 50
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "input_image_urls",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "img_guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "processed megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux/schnell",
    "name": "FLUX.1 [schnell]",
    "description": "FLUX.1 [schnell] is a 12 billion parameter flow transformer that generates high-quality images from text in 1 to 4 steps, suitable for personal and commercial use.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/flux-schnell-thumb.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SchnellTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The speed of the generation. The higher the speed, the faster the generation.",
          "default": "none"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 12,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 4
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n        The CFG (Classifier Free Guidance) scale is a measure of how close you want\n        the model to stick to your prompt when looking for a related image to show you.\n    ",
          "default": 3.5
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n        The same seed and the same prompt given to the same version of the model\n        will output the same image every time.\n    "
        }
      },
      "x-fal-order-properties": [
        "num_inference_steps",
        "prompt",
        "image_size",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/stable-diffusion-v35-medium",
    "name": "Stable Diffusion 3.5 Medium",
    "description": "Stable Diffusion 3.5 Medium is a Multimodal Diffusion Transformer (MMDiT) text-to-image model that features improved performance in image quality, typography, complex prompt understanding, and resource-efficiency.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/stable-diffusion-v35-medium.webp",
    "tags": [
      "diffusion",
      "typography",
      "style"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A dreamlike Japanese garden in perpetual twilight, bathed in bioluminescent cherry blossoms that emit a soft pink-purple glow. Floating paper lanterns drift lazily through the scene, their warm light creating dancing reflections in a mirror-like koi pond. Ethereal mist weaves between ancient stone pathways lined with glowing mushrooms in pastel blues and purples. A traditional wooden bridge arches gracefully over the water, dusted with fallen petals that sparkle like stardust. The scene is captured through a cinematic lens with perfect bokeh, creating an otherworldly atmosphere. In the background, a crescent moon hangs impossibly large in the sky, surrounded by a sea of stars and auroral wisps in teal and violet. Crystal formations emerge from the ground, refracting the ambient light into rainbow prisms. The entire composition follows the golden ratio, with moody film-like color grading reminiscent of Studio Ghibli, enhanced by volumetric god rays filtering through the luminous foliage. 8K resolution, masterful photography, hyperdetailed, magical realism."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 40
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-pro/new",
    "name": "FLUX.1 [pro]",
    "description": "FLUX.1 [pro] new is an accelerated version of FLUX.1 [pro], maintaining professional-grade image quality while delivering significantly faster generation speeds.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/flux-pro-thumb.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FluxProTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Extreme close-up of a single tiger eye, direct frontal view. Detailed iris and pupil. Sharp focus on eye texture and color. Natural lighting to capture authentic eye shine and depth. The word \"FLUX\" is painted over it in big, white brush strokes with visible texture."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "landscape_4_3"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "safety_tolerance": {
          "enum": [
            "1",
            "2",
            "3",
            "4",
            "5",
            "6"
          ],
          "title": "Safety Tolerance",
          "type": "string",
          "description": "The safety tolerance level for the generated image. 1 being the most strict and 5 being the most permissive.",
          "default": "2"
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enhance_prompt": {
          "title": "Enhance Prompt",
          "type": "boolean",
          "description": "Whether to enhance the prompt for better results.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "output_format",
        "safety_tolerance",
        "enhance_prompt"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/flux-lora/inpainting",
    "name": "FLUX.1 [dev] Inpainting with LoRAs",
    "description": "Super fast endpoint for the FLUX.1 [dev] inpainting model with LoRA support, enabling rapid and high-quality image inpaingting using pre-trained LoRA adaptations for personalization, specific styles, brand identities, and product-specific outputs.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/flux_lora.jpg",
    "tags": [
      "lora",
      "personalization"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "InpaintInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A photo of a lion sitting on a stone bench"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "description": "The number of images to generate. This is always set to 1 for streaming output.",
          "title": "Num Images",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image."
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/dog.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of image to use for inpainting. or img2img"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "strength": {
          "minimum": 0.01,
          "maximum": 1,
          "type": "number",
          "description": "The strength to use for inpainting/image-to-image. Only used if the image_url is provided. 1.0 is completely remakes the image while 0.0 preserves the original.",
          "title": "Strength",
          "default": 0.85
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 35,
          "type": "number",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "title": "Guidance scale (CFG)",
          "default": 3.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "mask_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/example_inputs/dog_mask.png"
          ],
          "title": "Mask Url",
          "type": "string",
          "description": "\n            The mask to area to Inpaint in.\n        "
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "description": "The number of inference steps to perform.",
          "title": "Num Inference Steps",
          "default": 28
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "loras",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "image_url",
        "strength",
        "mask_url"
      ],
      "required": [
        "prompt",
        "image_url",
        "mask_url"
      ]
    }
  },
  {
    "id": "fal-ai/stable-diffusion-v3-medium",
    "name": "Stable Diffusion V3",
    "description": "Stable Diffusion 3 Medium (Text to Image) is a Multimodal Diffusion Transformer (MMDiT) model that improves image quality, typography, prompt understanding, and efficiency.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/landing/sd3-sample-03.webp",
    "tags": [
      "diffusion",
      "style"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt_expansion": {
          "title": "Enhance Prompt",
          "type": "boolean",
          "description": "If set to true, prompt will be upsampled with more details.",
          "default": false
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "prompt": {
          "examples": [
            "Digital art, portrait of an anthropomorphic roaring Tiger warrior with full armor, close up in the middle of a battle, behind him there is a banner with the text \"Open Source\""
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "maximum": 20,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to generate an image from.",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "prompt_expansion",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "images"
  },
  {
    "id": "fal-ai/fooocus/upscale-or-vary",
    "name": "Fooocus Upscale or Vary",
    "description": "Default parameters with automated optimizations and quality improvements.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "tags": [
      "upscaling",
      "vary",
      "stylized"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FooocusUpscaleOrVaryInput",
      "type": "object",
      "properties": {
        "styles": {
          "title": "Styles",
          "type": "array",
          "description": "\n            The style to use.\n        ",
          "uniqueItems": true,
          "items": {
            "enum": [
              "Fooocus V2",
              "Fooocus Enhance",
              "Fooocus Sharp",
              "Fooocus Semi Realistic",
              "Fooocus Masterpiece",
              "Fooocus Photograph",
              "Fooocus Negative",
              "Fooocus Cinematic",
              "SAI 3D Model",
              "SAI Analog Film",
              "SAI Anime",
              "SAI Cinematic",
              "SAI Comic Book",
              "SAI Craft Clay",
              "SAI Digital Art",
              "SAI Enhance",
              "SAI Fantasy Art",
              "SAI Isometric",
              "SAI Line Art",
              "SAI Lowpoly",
              "SAI Neonpunk",
              "SAI Origami",
              "SAI Photographic",
              "SAI Pixel Art",
              "SAI Texture",
              "MRE Cinematic Dynamic",
              "MRE Spontaneous Picture",
              "MRE Artistic Vision",
              "MRE Dark Dream",
              "MRE Gloomy Art",
              "MRE Bad Dream",
              "MRE Underground",
              "MRE Surreal Painting",
              "MRE Dynamic Illustration",
              "MRE Undead Art",
              "MRE Elemental Art",
              "MRE Space Art",
              "MRE Ancient Illustration",
              "MRE Brave Art",
              "MRE Heroic Fantasy",
              "MRE Dark Cyberpunk",
              "MRE Lyrical Geometry",
              "MRE Sumi E Symbolic",
              "MRE Sumi E Detailed",
              "MRE Manga",
              "MRE Anime",
              "MRE Comic",
              "Ads Advertising",
              "Ads Automotive",
              "Ads Corporate",
              "Ads Fashion Editorial",
              "Ads Food Photography",
              "Ads Gourmet Food Photography",
              "Ads Luxury",
              "Ads Real Estate",
              "Ads Retail",
              "Artstyle Abstract",
              "Artstyle Abstract Expressionism",
              "Artstyle Art Deco",
              "Artstyle Art Nouveau",
              "Artstyle Constructivist",
              "Artstyle Cubist",
              "Artstyle Expressionist",
              "Artstyle Graffiti",
              "Artstyle Hyperrealism",
              "Artstyle Impressionist",
              "Artstyle Pointillism",
              "Artstyle Pop Art",
              "Artstyle Psychedelic",
              "Artstyle Renaissance",
              "Artstyle Steampunk",
              "Artstyle Surrealist",
              "Artstyle Typography",
              "Artstyle Watercolor",
              "Futuristic Biomechanical",
              "Futuristic Biomechanical Cyberpunk",
              "Futuristic Cybernetic",
              "Futuristic Cybernetic Robot",
              "Futuristic Cyberpunk Cityscape",
              "Futuristic Futuristic",
              "Futuristic Retro Cyberpunk",
              "Futuristic Retro Futurism",
              "Futuristic Sci Fi",
              "Futuristic Vaporwave",
              "Game Bubble Bobble",
              "Game Cyberpunk Game",
              "Game Fighting Game",
              "Game Gta",
              "Game Mario",
              "Game Minecraft",
              "Game Pokemon",
              "Game Retro Arcade",
              "Game Retro Game",
              "Game Rpg Fantasy Game",
              "Game Strategy Game",
              "Game Streetfighter",
              "Game Zelda",
              "Misc Architectural",
              "Misc Disco",
              "Misc Dreamscape",
              "Misc Dystopian",
              "Misc Fairy Tale",
              "Misc Gothic",
              "Misc Grunge",
              "Misc Horror",
              "Misc Kawaii",
              "Misc Lovecraftian",
              "Misc Macabre",
              "Misc Manga",
              "Misc Metropolis",
              "Misc Minimalist",
              "Misc Monochrome",
              "Misc Nautical",
              "Misc Space",
              "Misc Stained Glass",
              "Misc Techwear Fashion",
              "Misc Tribal",
              "Misc Zentangle",
              "Papercraft Collage",
              "Papercraft Flat Papercut",
              "Papercraft Kirigami",
              "Papercraft Paper Mache",
              "Papercraft Paper Quilling",
              "Papercraft Papercut Collage",
              "Papercraft Papercut Shadow Box",
              "Papercraft Stacked Papercut",
              "Papercraft Thick Layered Papercut",
              "Photo Alien",
              "Photo Film Noir",
              "Photo Glamour",
              "Photo Hdr",
              "Photo Iphone Photographic",
              "Photo Long Exposure",
              "Photo Neon Noir",
              "Photo Silhouette",
              "Photo Tilt Shift",
              "Cinematic Diva",
              "Abstract Expressionism",
              "Academia",
              "Action Figure",
              "Adorable 3D Character",
              "Adorable Kawaii",
              "Art Deco",
              "Art Nouveau",
              "Astral Aura",
              "Avant Garde",
              "Baroque",
              "Bauhaus Style Poster",
              "Blueprint Schematic Drawing",
              "Caricature",
              "Cel Shaded Art",
              "Character Design Sheet",
              "Classicism Art",
              "Color Field Painting",
              "Colored Pencil Art",
              "Conceptual Art",
              "Constructivism",
              "Cubism",
              "Dadaism",
              "Dark Fantasy",
              "Dark Moody Atmosphere",
              "Dmt Art Style",
              "Doodle Art",
              "Double Exposure",
              "Dripping Paint Splatter Art",
              "Expressionism",
              "Faded Polaroid Photo",
              "Fauvism",
              "Flat 2d Art",
              "Fortnite Art Style",
              "Futurism",
              "Glitchcore",
              "Glo Fi",
              "Googie Art Style",
              "Graffiti Art",
              "Harlem Renaissance Art",
              "High Fashion",
              "Idyllic",
              "Impressionism",
              "Infographic Drawing",
              "Ink Dripping Drawing",
              "Japanese Ink Drawing",
              "Knolling Photography",
              "Light Cheery Atmosphere",
              "Logo Design",
              "Luxurious Elegance",
              "Macro Photography",
              "Mandola Art",
              "Marker Drawing",
              "Medievalism",
              "Minimalism",
              "Neo Baroque",
              "Neo Byzantine",
              "Neo Futurism",
              "Neo Impressionism",
              "Neo Rococo",
              "Neoclassicism",
              "Op Art",
              "Ornate And Intricate",
              "Pencil Sketch Drawing",
              "Pop Art 2",
              "Rococo",
              "Silhouette Art",
              "Simple Vector Art",
              "Sketchup",
              "Steampunk 2",
              "Surrealism",
              "Suprematism",
              "Terragen",
              "Tranquil Relaxing Atmosphere",
              "Sticker Designs",
              "Vibrant Rim Light",
              "Volumetric Lighting",
              "Watercolor 2",
              "Whimsical And Playful",
              "Mk Chromolithography",
              "Mk Cross Processing Print",
              "Mk Dufaycolor Photograph",
              "Mk Herbarium",
              "Mk Punk Collage",
              "Mk Mosaic",
              "Mk Van Gogh",
              "Mk Coloring Book",
              "Mk Singer Sargent",
              "Mk Pollock",
              "Mk Basquiat",
              "Mk Andy Warhol",
              "Mk Halftone Print",
              "Mk Gond Painting",
              "Mk Albumen Print",
              "Mk Aquatint Print",
              "Mk Anthotype Print",
              "Mk Inuit Carving",
              "Mk Bromoil Print",
              "Mk Calotype Print",
              "Mk Color Sketchnote",
              "Mk Cibulak Porcelain",
              "Mk Alcohol Ink Art",
              "Mk One Line Art",
              "Mk Blacklight Paint",
              "Mk Carnival Glass",
              "Mk Cyanotype Print",
              "Mk Cross Stitching",
              "Mk Encaustic Paint",
              "Mk Embroidery",
              "Mk Gyotaku",
              "Mk Luminogram",
              "Mk Lite Brite Art",
              "Mk Mokume Gane",
              "Pebble Art",
              "Mk Palekh",
              "Mk Suminagashi",
              "Mk Scrimshaw",
              "Mk Shibori",
              "Mk Vitreous Enamel",
              "Mk Ukiyo E",
              "Mk Vintage Airline Poster",
              "Mk Vintage Travel Poster",
              "Mk Bauhaus Style",
              "Mk Afrofuturism",
              "Mk Atompunk",
              "Mk Constructivism",
              "Mk Chicano Art",
              "Mk De Stijl",
              "Mk Dayak Art",
              "Mk Fayum Portrait",
              "Mk Illuminated Manuscript",
              "Mk Kalighat Painting",
              "Mk Madhubani Painting",
              "Mk Pictorialism",
              "Mk Pichwai Painting",
              "Mk Patachitra Painting",
              "Mk Samoan Art Inspired",
              "Mk Tlingit Art",
              "Mk Adnate Style",
              "Mk Ron English Style",
              "Mk Shepard Fairey Style"
            ],
            "type": "string"
          },
          "default": [
            "Fooocus Enhance",
            "Fooocus V2",
            "Fooocus Sharp"
          ]
        },
        "uov_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/fooocus/fruit_basket.jpeg"
          ],
          "title": "UOV Image URL",
          "type": "string",
          "description": "The image to upscale or vary."
        },
        "performance": {
          "enum": [
            "Speed",
            "Quality",
            "Extreme Speed",
            "Lightning"
          ],
          "title": "Performance",
          "type": "string",
          "description": "\n            You can choose Speed or Quality\n        ",
          "default": "Extreme Speed"
        },
        "mixing_image_prompt_and_vary_upscale": {
          "title": "Mixing Image Prompt and Vary/Upscale",
          "type": "boolean",
          "description": "Mixing Image Prompt and Vary/Upscale",
          "default": false
        },
        "image_prompt_3": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "prompt": {
          "examples": [
            "a basket of various fruits, bokeh, realistic, masterpiece"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
          "default": ""
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": [
            {
              "path": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors",
              "scale": 0.1
            }
          ]
        },
        "image_prompt_4": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "image_prompt_1": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to false, the safety checker will be disabled.",
          "default": true
        },
        "sharpness": {
          "minimum": 0,
          "title": "Sharpness",
          "type": "number",
          "maximum": 30,
          "description": "\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ",
          "default": 2
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 30,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "negative_prompt": {
          "examples": [
            "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "aspect_ratio": {
          "title": "Aspect Ratio",
          "type": "string",
          "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ",
          "default": "1024x1024"
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "\n            Number of images to generate in one request\n        ",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "refiner_model": {
          "enum": [
            "None",
            "realisticVisionV60B1_v51VAE.safetensors"
          ],
          "title": "Refiner Model",
          "type": "string",
          "description": "Refiner (SDXL or SD 1.5)",
          "default": "None"
        },
        "image_prompt_2": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "uov_method": {
          "enum": [
            "Disabled",
            "Vary (Subtle)",
            "Vary (Strong)",
            "Upscale (1.5x)",
            "Upscale (2x)",
            "Upscale (Fast 2x)"
          ],
          "title": "UOV Method",
          "type": "string",
          "description": "The method to use for upscaling or varying.",
          "default": "Vary (Strong)"
        },
        "seed": {
          "examples": [
            176400
          ],
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
          "nullable": true
        },
        "refiner_switch": {
          "description": "\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ",
          "type": "number",
          "minimum": 0,
          "title": "Refiner Switch At",
          "maximum": 1,
          "multipleOf": 0.0001,
          "default": 0.8
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "styles",
        "performance",
        "guidance_scale",
        "sharpness",
        "aspect_ratio",
        "num_images",
        "loras",
        "refiner_model",
        "refiner_switch",
        "output_format",
        "sync_mode",
        "seed",
        "uov_image_url",
        "uov_method",
        "image_prompt_1",
        "image_prompt_2",
        "image_prompt_3",
        "image_prompt_4",
        "mixing_image_prompt_and_vary_upscale",
        "enable_safety_checker"
      ],
      "required": [
        "uov_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/flux-subject",
    "name": "FLUX.1 Subject",
    "description": "Super fast endpoint for the FLUX.1 [schnell] model with subject input capabilities, enabling rapid and high-quality image generation for personalization, specific styles, brand identities, and product-specific outputs.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/flux-subject.webp",
    "tags": [
      "personalization",
      "customization"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FluxSubjectInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "On the beach, a lady sits under a beach umbrella with 'Omini' written on it. She's wearing this shirt and has a big smile on her face, with her surfboard hehind her. The sun is setting in the background. The sky is a beautiful shade of orange and purple."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/ominicontrol/ominishirt.jpg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "URL of image of the subject"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 8
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_url",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format"
      ],
      "required": [
        "prompt",
        "image_url"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/sana",
    "name": "Sana",
    "description": "Sana can synthesize high-resolution, high-quality images with strong text-image alignment at a remarkably fast speed, with the ability to generate 4K images in less than a second.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/sana.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Underwater coral reef ecosystem during peak bioluminescent activity, multiple layers of marine life - from microscopic plankton to massive coral structures, light refracting through crystal-clear tropical waters, creating prismatic color gradients, hyper-detailed texture of marine organisms"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate an image from."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": {
            "height": 2160,
            "width": 3840
          }
        },
        "style_name": {
          "enum": [
            "(No style)",
            "Cinematic",
            "Photographic",
            "Anime",
            "Manga",
            "Digital Art",
            "Pixel art",
            "Fantasy art",
            "Neonpunk",
            "3D Model"
          ],
          "title": "Style Name",
          "type": "string",
          "description": "The style to generate the image in.",
          "default": "(No style)"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 18
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            ""
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "output_format",
        "style_name"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/pixart-sigma",
    "name": "PixArt-\u03a3",
    "description": "Weak-to-Strong Training of Diffusion Transformer for 4K Text-to-Image Generation",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixart-sigma.jpeg",
    "tags": [
      "diffusion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "PixArtSigmaInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Photorealistic closeup video of two pirate ships battling each other as they sail inside a cup of coffee.",
            "an astronaut sitting in a diner, eating fries, cinematic, analog film",
            "Pirate ship trapped in a cosmic maelstrom nebula, rendered in cosmic beach whirlpool engine, volumetric lighting, spectacular, ambient lights, light pollution, cinematic atmosphere, art nouveau style, illustration art artwork by SenseiJaye, intricate detail.",
            "stars, water, brilliantly, gorgeous large scale scene, a little girl, in the style of dreamy realism, light gold and amber, blue and pink, brilliantly illuminated in the background.",
            "professional portrait photo of an anthropomorphic cat wearing fancy gentleman hat and jacket walking in autumn forest.",
            "beautiful lady, freckles, big smile, blue eyes, short ginger hair, dark makeup, wearing a floral blue vest top, soft light, dark grey background",
            "Spectacular Tiny World in the Transparent Jar On the Table, interior of the Great Hall, Elaborate, Carved Architecture, Anatomy, Symmetrical, Geometric and Parameteric Details, Precision Flat line Details, Pattern, Dark fantasy, Dark errie mood and ineffably mysterious mood, Technical design, Intricate Ultra Detail, Ornate Detail, Stylized and Futuristic and Biomorphic Details, Architectural Concept, Low contrast Details, Cinematic Lighting, 8k, by moebius, Fullshot, Epic, Fullshot, Octane render, Unreal ,Photorealistic, Hyperrealism",
            "anthropomorphic profile of the white snow owl Crystal priestess , art deco painting, pretty and expressive eyes, ornate costume, mythical, ethereal, intricate, elaborate, hyperrealism, hyper detailed, 3D, 8K, Ultra Realistic, high octane, ultra resolution, amazing detail, perfection, In frame, photorealistic, cinematic lighting, visual clarity, shading , Lumen Reflections, Super-Resolution, gigapixel, color grading, retouch, enhanced, PBR, Blender, V-ray, Procreate, zBrush, Unreal Engine 5, cinematic, volumetric, dramatic, neon lighting, wide angle lens ,no digital painting blur",
            "The parametric hotel lobby is a sleek and modern space with plenty of natural light. The lobby is spacious and open with a variety of seating options. The front desk is a sleek white counter with a parametric design. The walls are a light blue color with parametric patterns. The floor is a light wood color with a parametric design. There are plenty of plants and flowers throughout the space. The overall effect is a calm and relaxing space. occlusion, moody, sunset, concept art, octane rendering, 8k, highly detailed, concept art, highly detailed, beautiful scenery, cinematic, beautiful light, hyperreal, octane render, hdr, long exposure, 8K, realistic, fog, moody, fire and explosions, smoke, 50mm f2.8"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "style": {
          "enum": [
            "(No style)",
            "Cinematic",
            "Photographic",
            "Anime",
            "Manga",
            "Digital Art",
            "Pixel art",
            "Fantasy art",
            "Neonpunk",
            "3D Model"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style to apply to the image.",
          "default": "(No style)"
        },
        "scheduler": {
          "enum": [
            "DPM-SOLVER",
            "SA-SOLVER"
          ],
          "title": "Scheduler",
          "type": "string",
          "description": "The scheduler to use for the model.",
          "default": "DPM-SOLVER"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 10,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4.5
        },
        "num_inference_steps": {
          "minimum": 5,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 35
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            "cartoon, illustration, animation. face. male, female",
            "ugly, deformed"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "style",
        "image_size",
        "num_inference_steps",
        "scheduler",
        "guidance_scale",
        "seed",
        "sync_mode",
        "num_images",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/sdxl-controlnet-union",
    "name": "SDXL ControlNet Union",
    "description": "An efficent SDXL multi-controlnet text-to-image model.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/controlnet-union/000004_openpose_scribble_concat.jpg",
    "tags": [
      "diffusion",
      "controlnet",
      "composition"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageControlNetUnionInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Ice fortress, aurora skies, polar wildlife, twilight"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "depth_preprocess": {
          "title": "Depth Preprocess",
          "type": "boolean",
          "description": "Whether to preprocess the depth image.",
          "default": true
        },
        "image_size": {
          "examples": [
            null
          ],
          "title": "Image Size",
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "description": "The size of the generated image. Leave it none to automatically infer from the control image.",
          "nullable": true
        },
        "normal_image_url": {
          "examples": [
            "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
          ],
          "title": "Normal Image Url",
          "type": "string",
          "description": "The URL of the control image."
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "The list of embeddings to use.",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "teed_image_url": {
          "examples": [
            "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
          ],
          "title": "Teed Image Url",
          "type": "string",
          "description": "The URL of the control image."
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "The list of LoRA weights to use.",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "maximum": 20,
          "default": 7.5
        },
        "canny_image_url": {
          "examples": [
            "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
          ],
          "title": "Canny Image Url",
          "type": "string",
          "description": "The URL of the control image."
        },
        "segmentation_preprocess": {
          "title": "Segmentation Preprocess",
          "type": "boolean",
          "description": "Whether to preprocess the segmentation image.",
          "default": true
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "request_id": {
          "title": "Request Id",
          "type": "string",
          "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
          "default": ""
        },
        "segmentation_image_url": {
          "examples": [
            "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
          ],
          "title": "Segmentation Image Url",
          "type": "string",
          "description": "The URL of the control image."
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "openpose_image_url": {
          "examples": [
            "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
          ],
          "title": "Openpose Image Url",
          "type": "string",
          "description": "The URL of the control image."
        },
        "canny_preprocess": {
          "title": "Canny Preprocess",
          "type": "boolean",
          "description": "Whether to preprocess the canny image.",
          "default": true
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": false
        },
        "depth_image_url": {
          "examples": [
            "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/MiN_j3St9B8esJleCZKMU.jpeg"
          ],
          "title": "Depth Image Url",
          "type": "string",
          "description": "The URL of the control image."
        },
        "normal_preprocess": {
          "title": "Normal Preprocess",
          "type": "boolean",
          "description": "Whether to preprocess the normal image.",
          "default": true
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "cartoon, illustration, animation. face. male, female",
            "ugly, deformed"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "teed_preprocess": {
          "title": "Teed Preprocess",
          "type": "boolean",
          "description": "Whether to preprocess the teed image.",
          "default": true
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "description": "The number of images to generate.",
          "maximum": 8,
          "default": 1
        },
        "controlnet_conditioning_scale": {
          "minimum": 0,
          "title": "Controlnet Conditioning Scale",
          "type": "number",
          "description": "The scale of the controlnet conditioning.",
          "maximum": 1,
          "default": 0.5
        },
        "openpose_preprocess": {
          "title": "Openpose Preprocess",
          "type": "boolean",
          "description": "Whether to preprocess the openpose image.",
          "default": true
        },
        "safety_checker_version": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Safety Checker Version",
          "type": "string",
          "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
          "default": "v1"
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to perform.",
          "maximum": 70,
          "default": 35
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "controlnet_conditioning_scale",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "loras",
        "embeddings",
        "enable_safety_checker",
        "safety_checker_version",
        "expand_prompt",
        "format",
        "request_id",
        "openpose_image_url",
        "openpose_preprocess",
        "depth_image_url",
        "depth_preprocess",
        "teed_image_url",
        "teed_preprocess",
        "canny_image_url",
        "canny_preprocess",
        "normal_image_url",
        "normal_preprocess",
        "segmentation_image_url",
        "segmentation_preprocess"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/kolors",
    "name": "Kolors",
    "description": "Photorealistic Text-to-Image",
    "category": "text-to-image",
    "thumbnail_url": "https://v2.fal.media/files/bdcf6a7a3f4146c39555e0c195715e65_73e054513f15488f93248ae10d67ece5.png",
    "tags": [
      "realism",
      "diffusion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "KolorsInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A young Chinese couple with fair skin, dressed in stylish sportswear, with the modern Beijing city skyline in the background. Facial details, clear pores, captured using the latest camera model, close-up shot, ultra-high quality, 8K, visual feast.",
            "The image features four mythical beasts: Vermilion Bird, Black Tortoise, Azure Dragon, and White Tiger. The Vermilion Bird is at the top of the image, with feathers as red as fire and a tail as magnificent as a phoenix, its wings spreading like burning flames. The Black Tortoise is at the bottom, depicted as a giant turtle intertwined with a snake. Ancient runes adorn the turtle's shell, and the snake's eyes are cold and sharp. The Azure Dragon is on the right, its long body coiling in the sky, with jade-green scales, flowing whiskers, deer-like horns, and exhaling clouds and mist. The White Tiger is on the left, with a majestic posture, white fur with black stripes, piercing eyes, sharp teeth and claws, surrounded by vast mountains and grasslands."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "\n            The prompt to use for generating the image. Be as descriptive as possible\n            for best results.\n        "
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "output_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "png"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and\n            uploaded before returning the response. This will increase the latency of\n            the function but it allows you to get the image directly in the response\n            without going through the CDN.\n        ",
          "default": false
        },
        "scheduler": {
          "enum": [
            "EulerDiscreteScheduler",
            "EulerAncestralDiscreteScheduler",
            "DPMSolverMultistepScheduler",
            "DPMSolverMultistepScheduler_SDE_karras",
            "UniPCMultistepScheduler",
            "DEISMultistepScheduler"
          ],
          "title": "Scheduler",
          "type": "string",
          "description": "The scheduler to use for the model.",
          "default": "EulerDiscreteScheduler"
        },
        "guidance_scale": {
          "minimum": 1,
          "maximum": 10,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show\n            you.\n        ",
          "default": 5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 150,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 50
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "ugly, deformed, blurry"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small\n            details (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Enable safety checker.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "guidance_scale",
        "num_inference_steps",
        "seed",
        "sync_mode",
        "enable_safety_checker",
        "num_images",
        "image_size",
        "scheduler",
        "output_format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/stable-cascade",
    "name": "Stable Cascade",
    "description": "Stable Cascade: Image generation on a smaller & cheaper latent space.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/stable-cascade.jpeg",
    "tags": [
      "diffusion",
      "lcm"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "StableCascadeInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "An image of a shiba inu, donning a spacesuit and helmet"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "second_stage_guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Decoder Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 0
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the image will be returned as base64 encoded string.\n        ",
          "default": false
        },
        "first_stage_steps": {
          "minimum": 4,
          "maximum": 40,
          "type": "integer",
          "title": "First Stage Steps",
          "description": "Number of steps to run the first stage for.",
          "default": 20
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Cascade\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to false, the safety checker will be disabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "ugly, deformed"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "second_stage_steps": {
          "minimum": 4,
          "maximum": 24,
          "type": "integer",
          "title": "Second Stage Steps",
          "description": "Number of steps to run the second stage for.",
          "default": 10
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "first_stage_steps",
        "second_stage_steps",
        "guidance_scale",
        "second_stage_guidance_scale",
        "image_size",
        "seed",
        "enable_safety_checker",
        "num_images",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/fast-sdxl",
    "name": "Stable Diffusion XL",
    "description": "Run SDXL at the speed of light",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/fast-sdxl.jpeg",
    "tags": [
      "diffusion",
      "lora",
      "embeddings",
      "high-res",
      "style"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "photo of a rhino dressed suit and tie sitting at a table in a bar with a bar stools, award winning photography, Elke vogelsang",
            "Photo of a classic red mustang car parked in las vegas strip at night"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "The list of embeddings to use.",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "The list of LoRA weights to use.",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 7.5
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "cartoon, illustration, animation. face. male, female",
            "ugly, deformed"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "safety_checker_version": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Safety Checker Version",
          "type": "string",
          "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
          "default": "v1"
        },
        "request_id": {
          "title": "Request Id",
          "type": "string",
          "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
          "default": ""
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 25
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "loras",
        "embeddings",
        "enable_safety_checker",
        "safety_checker_version",
        "expand_prompt",
        "format",
        "request_id"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/stable-cascade/sote-diffusion",
    "name": "SoteDiffusion",
    "description": "Anime finetune of W\u00fcrstchen V3.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/sotediffusion.jpeg",
    "tags": [
      "lcm",
      "stylized"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SoteDiffusionInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "newest, extremely aesthetic, best quality, 1girl, solo, pink hair, blue eyes, long hair, looking at viewer, smile, black background, holding a sign, the text on the sign says \"Hello\""
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 4,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": {
            "height": 1536,
            "width": 1024
          }
        },
        "second_stage_guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Decoder Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 2
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the image will be returned as base64 encoded string.\n        ",
          "default": false
        },
        "first_stage_steps": {
          "minimum": 4,
          "maximum": 50,
          "type": "integer",
          "title": "First Stage Steps",
          "description": "Number of steps to run the first stage for.",
          "default": 25
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 8
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Cascade\n            will output the same image every time.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to false, the safety checker will be disabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "very displeasing, worst quality, monochrome, realistic, oldest"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "second_stage_steps": {
          "minimum": 4,
          "maximum": 24,
          "type": "integer",
          "title": "Second Stage Steps",
          "description": "Number of steps to run the second stage for.",
          "default": 10
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "first_stage_steps",
        "second_stage_steps",
        "guidance_scale",
        "second_stage_guidance_scale",
        "image_size",
        "seed",
        "enable_safety_checker",
        "num_images",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/luma-photon",
    "name": "Luma Photon",
    "description": "Generate images from your prompts using Luma Photon. Photon is the most creative, personalizable, and intelligent visual models for creatives, bringing a step-function change in the cost of high-quality image generation.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/luma-photon.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A teddy bear in sunglasses playing electric guitar and dancing"
          ],
          "maxLength": 5000,
          "type": "string",
          "minLength": 3,
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1",
            "4:3",
            "3:4",
            "21:9",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "1:1"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "megapixels",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/lightning-models",
    "name": "Lightning Models",
    "description": "Collection of SDXL Lightning models.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/lightning-models.jpeg",
    "tags": [
      "diffusion",
      "lightning"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LightningModelsTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A hyperdetailed photograph of a Cat dressed as a mafia boss holding a fish walking down a Japanese fish market with an angry face, 8k resolution, best quality, beautiful photograph, dynamic lighting,"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "default": {
            "height": 1024,
            "width": 1024
          }
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "The list of embeddings to use.",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "The list of LoRA weights to use.",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "scheduler": {
          "enum": [
            "DPM++ 2M",
            "DPM++ 2M Karras",
            "DPM++ 2M SDE",
            "DPM++ 2M SDE Karras",
            "DPM++ SDE",
            "DPM++ SDE Karras",
            "KDPM 2A",
            "Euler",
            "Euler (trailing timesteps)",
            "Euler A",
            "LCM",
            "EDMDPMSolverMultistepScheduler",
            "TCDScheduler"
          ],
          "title": "Scheduler",
          "type": "string",
          "description": "Scheduler / sampler to use for the image denoising process."
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 2,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 2
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use. Use it to address details that you don't want in the image.",
          "default": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "model_name": {
          "examples": [
            "Lykon/dreamshaper-xl-lightning",
            "SG161222/RealVisXL_V4.0_Lightning"
          ],
          "title": "Model Name",
          "type": "string",
          "description": "The Lightning model to use."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "safety_checker_version": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Safety Checker Version",
          "type": "string",
          "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
          "default": "v1"
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 12,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "model_name",
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "guidance_scale",
        "loras",
        "embeddings",
        "scheduler",
        "expand_prompt",
        "num_images",
        "seed",
        "enable_safety_checker",
        "sync_mode",
        "format",
        "safety_checker_version"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/playground-v25",
    "name": "Playground v2.5",
    "description": "State-of-the-art open-source model in aesthetic quality",
    "category": "text-to-image",
    "thumbnail_url": "https://fal-cdn.batuhan-941.workers.dev/files/monkey/8WXjrk5HEam79CPlQlo5T.jpeg",
    "tags": [
      "artistic",
      "style"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImagePlaygroundv25Input",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Masterpiece (wide angle shot) , Easterbunny crafting an incantation, (creating a little colorful magic egg in a nest:1.6), standing on an old carved table in a colorful factory laboratory. fantastic view"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "The list of embeddings to use.",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": false
        },
        "guidance_rescale": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Guidance Rescale",
          "description": "The rescale factor for the CFG.",
          "default": 0
        },
        "safety_checker_version": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Safety Checker Version",
          "type": "string",
          "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
          "default": "v1"
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 3
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 25
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            "cartoon, illustration, animation. face. male, female",
            "ugly, deformed"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "num_images",
        "embeddings",
        "enable_safety_checker",
        "safety_checker_version",
        "expand_prompt",
        "format",
        "guidance_rescale"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/realistic-vision",
    "name": "Realistic Vision",
    "description": "Generate realistic images.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/realistic-vision.jpeg",
    "tags": [
      "realism",
      "diffusion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "RealisticVisionTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A hyperdetailed photograph of a Cat dressed as a mafia boss holding a fish walking down a Japanese fish market with an angry face, 8k resolution, best quality, beautiful photograph, dynamic lighting,"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "default": {
            "height": 1024,
            "width": 1024
          }
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "The list of embeddings to use.",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "The list of LoRA weights to use.",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "default": 5
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use. Use it to address details that you don't want in the image.",
          "default": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "model_name": {
          "examples": [
            "SG161222/Realistic_Vision_V6.0_B1_noVAE",
            "SG161222/RealVisXL_V4.0"
          ],
          "title": "Model Name",
          "type": "string",
          "description": "The Realistic Vision model to use."
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "safety_checker_version": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Safety Checker Version",
          "type": "string",
          "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
          "default": "v1"
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 70,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 35
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "model_name",
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "guidance_scale",
        "loras",
        "embeddings",
        "expand_prompt",
        "num_images",
        "seed",
        "enable_safety_checker",
        "sync_mode",
        "format",
        "safety_checker_version"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/dreamshaper",
    "name": "Dreamshaper",
    "description": "Dreamshaper model.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/dreamshaper.jpeg",
    "tags": [
      "stylized",
      "diffusion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "DreamshaperTextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A hyperdetailed photograph of a Cat dressed as a mafia boss holding a fish walking down a Japanese fish market with an angry face, 8k resolution, best quality, beautiful photograph, dynamic lighting,"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "default": {
            "height": 1024,
            "width": 1024
          }
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "The list of embeddings to use.",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "The list of LoRA weights to use.",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "default": 5
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use. Use it to address details that you don't want in the image.",
          "default": "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "model_name": {
          "enum": [
            "Lykon/dreamshaper-xl-1-0",
            "Lykon/dreamshaper-xl-v2-turbo",
            "Lykon/dreamshaper-8"
          ],
          "title": "Model Name",
          "type": "string",
          "description": "The Dreamshaper model to use.",
          "examples": [
            "Lykon/dreamshaper-8",
            "Lykon/dreamshaper-xl-1-0",
            "Lykon/dreamshaper-xl-v2-turbo"
          ]
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "safety_checker_version": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Safety Checker Version",
          "type": "string",
          "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
          "default": "v1"
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 70,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 35
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "model_name",
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "guidance_scale",
        "loras",
        "embeddings",
        "expand_prompt",
        "num_images",
        "seed",
        "enable_safety_checker",
        "sync_mode",
        "format",
        "safety_checker_version"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/stable-diffusion-v15",
    "name": "Stable Diffusion v1.5",
    "description": "Stable Diffusion v1.5",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/sd-loras.jpeg",
    "tags": [
      "diffusion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageSD15Input",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "photo of a rhino dressed suit and tie sitting at a table in a bar with a bar stools, award winning photography, Elke vogelsang",
            "Photo of a classic red mustang car parked in las vegas strip at night"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square"
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "The list of embeddings to use.",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": false
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "The list of LoRA weights to use.",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 7.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 25
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "examples": [
            "cartoon, illustration, animation. face. male, female",
            "ugly, deformed"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "loras",
        "embeddings",
        "enable_safety_checker",
        "expand_prompt",
        "format"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/layer-diffusion",
    "name": "Layer Diffusion XL",
    "description": "SDXL with an alpha channel.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/model_tests/layer_diffusion/309211077-38ace070-6530-43c9-9ca1-c98aa5b7a0ed.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Input",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "a male army soldier holding a gun"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
          "default": ""
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The guidance scale for the model.",
          "default": 8
        },
        "num_inference_steps": {
          "minimum": 10,
          "maximum": 40,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps for the model.",
          "default": 20
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The prompt to use for generating the negative image. Be as descriptive as possible for best results.",
          "default": "text, watermark"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to false, the safety checker will be disabled.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "guidance_scale",
        "num_inference_steps",
        "seed",
        "enable_safety_checker"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/fast-lightning-sdxl",
    "name": "Stable Diffusion XL Lightning",
    "description": "Run SDXL at the speed of light",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/stable-diffusion-xl-lightning.webp",
    "tags": [
      "diffusion",
      "lightning",
      "real-time"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageLightningInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "photo of a girl smiling during a sunset, with lightnings in the background"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "The list of embeddings to use.",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": false
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "guidance_rescale": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Guidance Rescale",
          "description": "The rescale factor for the CFG.",
          "default": 0
        },
        "safety_checker_version": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Safety Checker Version",
          "type": "string",
          "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
          "default": "v1"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "enum": [
            "1",
            "2",
            "4",
            "8"
          ],
          "title": "Num Inference Steps",
          "type": "string",
          "description": "The number of inference steps to perform.",
          "default": 4
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "request_id": {
          "title": "Request Id",
          "type": "string",
          "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "sync_mode",
        "num_images",
        "embeddings",
        "enable_safety_checker",
        "safety_checker_version",
        "expand_prompt",
        "format",
        "guidance_rescale",
        "request_id"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/fast-fooocus-sdxl/image-to-image",
    "name": "Fooocus",
    "description": "Fooocus extreme speed mode as a standalone app.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "tags": [
      "stylized"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ImageToImageFooocusInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "enable_refiner": {
          "title": "Enable Refiner",
          "type": "boolean",
          "description": "If set to true, a smaller model will try to refine the output after it was processed.",
          "default": true
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. Leave it none to automatically infer from the prompt image.",
          "examples": [
            null
          ],
          "nullable": true
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "The list of embeddings to use.",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": true
        },
        "guidance_rescale": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Guidance Rescale",
          "description": "The rescale factor for the CFG.",
          "default": 0
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 2
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "cartoon, illustration, animation. face. male, female"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "image_url": {
          "examples": [
            "https://fal-cdn.batuhan-941.workers.dev/files/tiger/IExuP-WICqaIesLZAZPur.jpeg"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The URL of the image to use as a starting point for the generation."
        },
        "strength": {
          "minimum": 0.05,
          "maximum": 1,
          "type": "number",
          "title": "Strength",
          "description": "determines how much the generated image resembles the initial image",
          "default": 0.95
        },
        "safety_checker_version": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Safety Checker Version",
          "type": "string",
          "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
          "default": "v1"
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 24,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 8
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "guidance_scale",
        "strength",
        "seed",
        "num_images",
        "embeddings",
        "enable_safety_checker",
        "safety_checker_version",
        "expand_prompt",
        "format",
        "guidance_rescale",
        "enable_refiner"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/fast-sdxl-controlnet-canny",
    "name": "ControlNet SDXL",
    "description": "Generate Images with ControlNet.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/ynzNm1f0ZoDCuOvAE9tKR.jpeg",
    "tags": [
      "diffusion",
      "controlnet",
      "manipulation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageControlNetInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Ice fortress, aurora skies, polar wildlife, twilight"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image. Leave it none to automatically infer from the control image.",
          "nullable": true
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "The list of LoRA weights to use.",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "maximum": 20,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 7.5
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "negative_prompt": {
          "examples": [
            "cartoon, illustration, animation. face. male, female",
            "ugly, deformed"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 8,
          "description": "The number of images to generate.",
          "default": 1
        },
        "controlnet_conditioning_scale": {
          "minimum": 0,
          "title": "Controlnet Conditioning Scale",
          "type": "number",
          "maximum": 1,
          "description": "The scale of the controlnet conditioning.",
          "default": 0.5
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "control_image_url": {
          "examples": [
            "https://avatars.githubusercontent.com/u/74778219"
          ],
          "title": "Control Image Url",
          "type": "string",
          "description": "The URL of the control image."
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 25
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "enable_deep_cache": {
          "title": "Enable Deep Cache",
          "type": "boolean",
          "description": "\n            If set to true, DeepCache will be enabled. TBD\n        ",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "control_image_url",
        "controlnet_conditioning_scale",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "enable_deep_cache",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "loras",
        "enable_safety_checker",
        "expand_prompt"
      ],
      "required": [
        "prompt",
        "control_image_url"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/hyper-sdxl",
    "name": "Hyper SDXL",
    "description": "Hyper-charge SDXL's performance and creativity.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal.media/files/kangaroo/LM0fy_9qT_8FlKrWhR7Zt.jpeg",
    "tags": [
      "diffusion",
      "real-time"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": null
  },
  {
    "id": "fal-ai/fast-lcm-diffusion",
    "name": "Latent Consistency Models (v1.5/XL)",
    "description": "Run SDXL at the speed of light",
    "category": "text-to-image",
    "thumbnail_url": "https://fal-cdn.batuhan-941.workers.dev/files/rabbit/P322iQXlz2jOOuRFBWK-q.jpeg",
    "tags": [
      "lcm",
      "diffusion",
      "turbo",
      "real-time"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageLCMInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Self-portrait oil painting, a beautiful cyborg with golden hair, 8k."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": false
        },
        "guidance_rescale": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Guidance Rescale",
          "description": "The rescale factor for the CFG.",
          "default": 0
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 1.5
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "cartoon, illustration, animation. face. male, female",
            "ugly, deformed"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "model_name": {
          "enum": [
            "stabilityai/stable-diffusion-xl-base-1.0",
            "runwayml/stable-diffusion-v1-5"
          ],
          "title": "Model Name",
          "type": "string",
          "description": "The name of the model to use.",
          "examples": [
            "stabilityai/stable-diffusion-xl-base-1.0",
            "runwayml/stable-diffusion-v1-5"
          ],
          "default": "stabilityai/stable-diffusion-xl-base-1.0"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": true
        },
        "safety_checker_version": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Safety Checker Version",
          "type": "string",
          "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
          "default": "v1"
        },
        "request_id": {
          "title": "Request Id",
          "type": "string",
          "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
          "default": ""
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 32,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 6
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "model_name",
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "sync_mode",
        "num_images",
        "enable_safety_checker",
        "safety_checker_version",
        "expand_prompt",
        "format",
        "guidance_rescale",
        "request_id"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/fast-fooocus-sdxl",
    "name": "Fooocus",
    "description": "Fooocus extreme speed mode as a standalone app.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageFooocusInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Self-portrait oil painting, a beautiful cyborg with golden hair, 8k."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "enable_refiner": {
          "title": "Enable Refiner",
          "type": "boolean",
          "description": "If set to true, a smaller model will try to refine the output after it was processed.",
          "default": true
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "The size of the generated image.",
          "default": "square_hd"
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "The list of embeddings to use.",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "If set to true, the prompt will be expanded with additional prompts.",
          "default": true
        },
        "guidance_rescale": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Guidance Rescale",
          "description": "The rescale factor for the CFG.",
          "default": 0
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 2
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "cartoon, illustration, animation. face. male, female",
            "ugly, deformed"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Num Images",
          "description": "The number of images to generate.",
          "default": 1
        },
        "safety_checker_version": {
          "enum": [
            "v1",
            "v2"
          ],
          "title": "Safety Checker Version",
          "type": "string",
          "description": "The version of the safety checker to use. v1 is the default CompVis safety checker. v2 uses a custom ViT model.",
          "default": "v1"
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 24,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 8
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "image_size",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "num_images",
        "embeddings",
        "enable_safety_checker",
        "safety_checker_version",
        "expand_prompt",
        "format",
        "guidance_rescale",
        "enable_refiner"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/illusion-diffusion",
    "name": "Illusion Diffusion",
    "description": "Create illusions conditioned on image.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/illusion-diffusion.jpeg",
    "tags": [
      "composition",
      "stylized"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "IllusionDiffusionInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "(masterpiece:1.4), (best quality), (detailed), Medieval village scene with busy streets and castle in the distance"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ",
          "default": "square_hd"
        },
        "controlnet_conditioning_scale": {
          "title": "Controlnet Conditioning Scale",
          "type": "number",
          "description": "The scale of the ControlNet.",
          "default": 1
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/illusion-examples/pattern.png",
            "https://storage.googleapis.com/falserverless/illusion-examples/checkers.png",
            "https://storage.googleapis.com/falserverless/illusion-examples/checkers_mid.jpg",
            "https://storage.googleapis.com/falserverless/illusion-examples/ultra_checkers.png",
            "https://storage.googleapis.com/falserverless/illusion-examples/funky.jpeg",
            "https://storage.googleapis.com/falserverless/illusion-examples/cubes.jpeg",
            "https://storage.googleapis.com/falserverless/illusion-examples/turkey-flag.png",
            "https://storage.googleapis.com/falserverless/illusion-examples/india-flag.png",
            "https://storage.googleapis.com/falserverless/illusion-examples/usa-flag.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "Input image url."
        },
        "scheduler": {
          "enum": [
            "DPM++ Karras SDE",
            "Euler"
          ],
          "title": "Scheduler",
          "type": "string",
          "description": "Scheduler / sampler to use for the image denoising process.",
          "default": "Euler"
        },
        "control_guidance_start": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Control Guidance Start",
          "default": 0
        },
        "guidance_scale": {
          "maximum": 50,
          "type": "number",
          "title": "Guidance Scale",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "exclusiveMinimum": 0,
          "default": 7.5
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            Seed of the generated Image. It will be the same value of the one passed in the\n            input or the randomly generated that was used in case none was passed.\n        "
        },
        "control_guidance_end": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Control Guidance End",
          "default": 1
        },
        "negative_prompt": {
          "examples": [
            "(worst quality, poor details:1.4), lowres, (artist name, signature, watermark:1.4), bad-artist-anime, bad_prompt_version2, bad-hands-5, ng_deepnegative_v1_75t"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "num_inference_steps": {
          "minimum": 0,
          "maximum": 80,
          "type": "integer",
          "title": "Number of inference steps",
          "description": "\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ",
          "default": 40
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "prompt",
        "negative_prompt",
        "guidance_scale",
        "controlnet_conditioning_scale",
        "control_guidance_start",
        "control_guidance_end",
        "seed",
        "scheduler",
        "num_inference_steps",
        "image_size"
      ],
      "required": [
        "image_url",
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/fooocus/image-prompt",
    "name": "Fooocus Image Prompt",
    "description": "Default parameters with automated optimizations and quality improvements.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "tags": [
      "stylized"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FooocusImagePromptInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "pikachu"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
          "default": ""
        },
        "uov_image_url": {
          "title": "UOV Image URL",
          "type": "string",
          "description": "The image to upscale or vary."
        },
        "performance": {
          "enum": [
            "Speed",
            "Quality",
            "Extreme Speed",
            "Lightning"
          ],
          "title": "Performance",
          "type": "string",
          "description": "\n            You can choose Speed or Quality\n        ",
          "default": "Extreme Speed"
        },
        "image_prompt_3": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "styles": {
          "title": "Styles",
          "type": "array",
          "description": "\n            The style to use.\n        ",
          "uniqueItems": true,
          "items": {
            "enum": [
              "Fooocus V2",
              "Fooocus Enhance",
              "Fooocus Sharp",
              "Fooocus Semi Realistic",
              "Fooocus Masterpiece",
              "Fooocus Photograph",
              "Fooocus Negative",
              "Fooocus Cinematic",
              "SAI 3D Model",
              "SAI Analog Film",
              "SAI Anime",
              "SAI Cinematic",
              "SAI Comic Book",
              "SAI Craft Clay",
              "SAI Digital Art",
              "SAI Enhance",
              "SAI Fantasy Art",
              "SAI Isometric",
              "SAI Line Art",
              "SAI Lowpoly",
              "SAI Neonpunk",
              "SAI Origami",
              "SAI Photographic",
              "SAI Pixel Art",
              "SAI Texture",
              "MRE Cinematic Dynamic",
              "MRE Spontaneous Picture",
              "MRE Artistic Vision",
              "MRE Dark Dream",
              "MRE Gloomy Art",
              "MRE Bad Dream",
              "MRE Underground",
              "MRE Surreal Painting",
              "MRE Dynamic Illustration",
              "MRE Undead Art",
              "MRE Elemental Art",
              "MRE Space Art",
              "MRE Ancient Illustration",
              "MRE Brave Art",
              "MRE Heroic Fantasy",
              "MRE Dark Cyberpunk",
              "MRE Lyrical Geometry",
              "MRE Sumi E Symbolic",
              "MRE Sumi E Detailed",
              "MRE Manga",
              "MRE Anime",
              "MRE Comic",
              "Ads Advertising",
              "Ads Automotive",
              "Ads Corporate",
              "Ads Fashion Editorial",
              "Ads Food Photography",
              "Ads Gourmet Food Photography",
              "Ads Luxury",
              "Ads Real Estate",
              "Ads Retail",
              "Artstyle Abstract",
              "Artstyle Abstract Expressionism",
              "Artstyle Art Deco",
              "Artstyle Art Nouveau",
              "Artstyle Constructivist",
              "Artstyle Cubist",
              "Artstyle Expressionist",
              "Artstyle Graffiti",
              "Artstyle Hyperrealism",
              "Artstyle Impressionist",
              "Artstyle Pointillism",
              "Artstyle Pop Art",
              "Artstyle Psychedelic",
              "Artstyle Renaissance",
              "Artstyle Steampunk",
              "Artstyle Surrealist",
              "Artstyle Typography",
              "Artstyle Watercolor",
              "Futuristic Biomechanical",
              "Futuristic Biomechanical Cyberpunk",
              "Futuristic Cybernetic",
              "Futuristic Cybernetic Robot",
              "Futuristic Cyberpunk Cityscape",
              "Futuristic Futuristic",
              "Futuristic Retro Cyberpunk",
              "Futuristic Retro Futurism",
              "Futuristic Sci Fi",
              "Futuristic Vaporwave",
              "Game Bubble Bobble",
              "Game Cyberpunk Game",
              "Game Fighting Game",
              "Game Gta",
              "Game Mario",
              "Game Minecraft",
              "Game Pokemon",
              "Game Retro Arcade",
              "Game Retro Game",
              "Game Rpg Fantasy Game",
              "Game Strategy Game",
              "Game Streetfighter",
              "Game Zelda",
              "Misc Architectural",
              "Misc Disco",
              "Misc Dreamscape",
              "Misc Dystopian",
              "Misc Fairy Tale",
              "Misc Gothic",
              "Misc Grunge",
              "Misc Horror",
              "Misc Kawaii",
              "Misc Lovecraftian",
              "Misc Macabre",
              "Misc Manga",
              "Misc Metropolis",
              "Misc Minimalist",
              "Misc Monochrome",
              "Misc Nautical",
              "Misc Space",
              "Misc Stained Glass",
              "Misc Techwear Fashion",
              "Misc Tribal",
              "Misc Zentangle",
              "Papercraft Collage",
              "Papercraft Flat Papercut",
              "Papercraft Kirigami",
              "Papercraft Paper Mache",
              "Papercraft Paper Quilling",
              "Papercraft Papercut Collage",
              "Papercraft Papercut Shadow Box",
              "Papercraft Stacked Papercut",
              "Papercraft Thick Layered Papercut",
              "Photo Alien",
              "Photo Film Noir",
              "Photo Glamour",
              "Photo Hdr",
              "Photo Iphone Photographic",
              "Photo Long Exposure",
              "Photo Neon Noir",
              "Photo Silhouette",
              "Photo Tilt Shift",
              "Cinematic Diva",
              "Abstract Expressionism",
              "Academia",
              "Action Figure",
              "Adorable 3D Character",
              "Adorable Kawaii",
              "Art Deco",
              "Art Nouveau",
              "Astral Aura",
              "Avant Garde",
              "Baroque",
              "Bauhaus Style Poster",
              "Blueprint Schematic Drawing",
              "Caricature",
              "Cel Shaded Art",
              "Character Design Sheet",
              "Classicism Art",
              "Color Field Painting",
              "Colored Pencil Art",
              "Conceptual Art",
              "Constructivism",
              "Cubism",
              "Dadaism",
              "Dark Fantasy",
              "Dark Moody Atmosphere",
              "Dmt Art Style",
              "Doodle Art",
              "Double Exposure",
              "Dripping Paint Splatter Art",
              "Expressionism",
              "Faded Polaroid Photo",
              "Fauvism",
              "Flat 2d Art",
              "Fortnite Art Style",
              "Futurism",
              "Glitchcore",
              "Glo Fi",
              "Googie Art Style",
              "Graffiti Art",
              "Harlem Renaissance Art",
              "High Fashion",
              "Idyllic",
              "Impressionism",
              "Infographic Drawing",
              "Ink Dripping Drawing",
              "Japanese Ink Drawing",
              "Knolling Photography",
              "Light Cheery Atmosphere",
              "Logo Design",
              "Luxurious Elegance",
              "Macro Photography",
              "Mandola Art",
              "Marker Drawing",
              "Medievalism",
              "Minimalism",
              "Neo Baroque",
              "Neo Byzantine",
              "Neo Futurism",
              "Neo Impressionism",
              "Neo Rococo",
              "Neoclassicism",
              "Op Art",
              "Ornate And Intricate",
              "Pencil Sketch Drawing",
              "Pop Art 2",
              "Rococo",
              "Silhouette Art",
              "Simple Vector Art",
              "Sketchup",
              "Steampunk 2",
              "Surrealism",
              "Suprematism",
              "Terragen",
              "Tranquil Relaxing Atmosphere",
              "Sticker Designs",
              "Vibrant Rim Light",
              "Volumetric Lighting",
              "Watercolor 2",
              "Whimsical And Playful",
              "Mk Chromolithography",
              "Mk Cross Processing Print",
              "Mk Dufaycolor Photograph",
              "Mk Herbarium",
              "Mk Punk Collage",
              "Mk Mosaic",
              "Mk Van Gogh",
              "Mk Coloring Book",
              "Mk Singer Sargent",
              "Mk Pollock",
              "Mk Basquiat",
              "Mk Andy Warhol",
              "Mk Halftone Print",
              "Mk Gond Painting",
              "Mk Albumen Print",
              "Mk Aquatint Print",
              "Mk Anthotype Print",
              "Mk Inuit Carving",
              "Mk Bromoil Print",
              "Mk Calotype Print",
              "Mk Color Sketchnote",
              "Mk Cibulak Porcelain",
              "Mk Alcohol Ink Art",
              "Mk One Line Art",
              "Mk Blacklight Paint",
              "Mk Carnival Glass",
              "Mk Cyanotype Print",
              "Mk Cross Stitching",
              "Mk Encaustic Paint",
              "Mk Embroidery",
              "Mk Gyotaku",
              "Mk Luminogram",
              "Mk Lite Brite Art",
              "Mk Mokume Gane",
              "Pebble Art",
              "Mk Palekh",
              "Mk Suminagashi",
              "Mk Scrimshaw",
              "Mk Shibori",
              "Mk Vitreous Enamel",
              "Mk Ukiyo E",
              "Mk Vintage Airline Poster",
              "Mk Vintage Travel Poster",
              "Mk Bauhaus Style",
              "Mk Afrofuturism",
              "Mk Atompunk",
              "Mk Constructivism",
              "Mk Chicano Art",
              "Mk De Stijl",
              "Mk Dayak Art",
              "Mk Fayum Portrait",
              "Mk Illuminated Manuscript",
              "Mk Kalighat Painting",
              "Mk Madhubani Painting",
              "Mk Pictorialism",
              "Mk Pichwai Painting",
              "Mk Patachitra Painting",
              "Mk Samoan Art Inspired",
              "Mk Tlingit Art",
              "Mk Adnate Style",
              "Mk Ron English Style",
              "Mk Shepard Fairey Style"
            ],
            "type": "string"
          },
          "default": [
            "Fooocus Enhance",
            "Fooocus V2",
            "Fooocus Sharp"
          ]
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": [
            {
              "path": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors",
              "scale": 0.1
            }
          ]
        },
        "image_prompt_4": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 30,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "sharpness": {
          "minimum": 0,
          "title": "Sharpness",
          "type": "number",
          "maximum": 30,
          "description": "\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ",
          "default": 2
        },
        "mixing_image_prompt_and_inpaint": {
          "title": "Mixing Image Prompt and Inpaint",
          "type": "boolean",
          "description": "Mixing Image Prompt and Inpaint",
          "default": false
        },
        "outpaint_selections": {
          "title": "Outpaint Direction",
          "type": "array",
          "description": "The directions to outpaint.",
          "uniqueItems": true,
          "items": {
            "enum": [
              "Left",
              "Right",
              "Top",
              "Bottom"
            ],
            "type": "string"
          },
          "default": []
        },
        "inpaint_image_url": {
          "title": "Inpaint Image URL",
          "type": "string",
          "description": "The image to use as a reference for inpainting."
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "refiner_model": {
          "enum": [
            "None",
            "realisticVisionV60B1_v51VAE.safetensors"
          ],
          "title": "Refiner Model",
          "type": "string",
          "description": "Refiner (SDXL or SD 1.5)",
          "default": "None"
        },
        "image_prompt_2": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "inpaint_mode": {
          "enum": [
            "Inpaint or Outpaint (default)",
            "Improve Detail (face, hand, eyes, etc.)",
            "Modify Content (add objects, change background, etc.)"
          ],
          "title": "Inpaint Mode",
          "type": "string",
          "description": "The mode to use for inpainting.",
          "default": "Inpaint or Outpaint (default)"
        },
        "uov_method": {
          "enum": [
            "Disabled",
            "Vary (Subtle)",
            "Vary (Strong)",
            "Upscale (1.5x)",
            "Upscale (2x)",
            "Upscale (Fast 2x)"
          ],
          "title": "UOV Method",
          "type": "string",
          "description": "The method to use for upscaling or varying.",
          "default": "Disabled"
        },
        "seed": {
          "examples": [
            176400
          ],
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
          "nullable": true
        },
        "refiner_switch": {
          "description": "\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ",
          "type": "number",
          "minimum": 0,
          "title": "Refiner Switch At",
          "maximum": 1,
          "multipleOf": 0.0001,
          "default": 0.8
        },
        "mixing_image_prompt_and_vary_upscale": {
          "title": "Mixing Image Prompt and Vary/Upscale",
          "type": "boolean",
          "description": "Mixing Image Prompt and Vary/Upscale",
          "default": false
        },
        "mask_image_url": {
          "title": "Mask Image URL",
          "type": "string",
          "description": "The image to use as a mask for the generated image."
        },
        "image_prompt_1": {
          "examples": [
            {
              "weight": 1,
              "stop_at": 1,
              "type": "PyraCanny",
              "image_url": "https://storage.googleapis.com/falserverless/model_tests/fooocus/Pikachu.webp"
            }
          ],
          "title": "Image Prompt 1",
          "allOf": [
            {
              "$ref": "#/components/schemas/ImagePrompt"
            }
          ]
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to false, the safety checker will be disabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "\n            Number of images to generate in one request\n        ",
          "default": 1
        },
        "aspect_ratio": {
          "title": "Aspect Ratio",
          "type": "string",
          "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ",
          "default": "1024x1024"
        },
        "inpaint_additional_prompt": {
          "title": "Inpaint Additional Prompt",
          "type": "string",
          "description": "Describe what you want to inpaint.",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "styles",
        "performance",
        "guidance_scale",
        "sharpness",
        "aspect_ratio",
        "num_images",
        "loras",
        "refiner_model",
        "refiner_switch",
        "output_format",
        "sync_mode",
        "seed",
        "image_prompt_1",
        "image_prompt_2",
        "image_prompt_3",
        "image_prompt_4",
        "inpaint_image_url",
        "mask_image_url",
        "inpaint_mode",
        "inpaint_additional_prompt",
        "outpaint_selections",
        "mixing_image_prompt_and_inpaint",
        "uov_image_url",
        "uov_method",
        "mixing_image_prompt_and_vary_upscale",
        "enable_safety_checker"
      ],
      "required": [
        "image_prompt_1"
      ]
    }
  },
  {
    "id": "fal-ai/fooocus/inpaint",
    "name": "Fooocus Inpainting",
    "description": "Default parameters with automated optimizations and quality improvements.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "tags": [
      "stylized",
      "editing"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FooocusInpaintInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "a cat on a bench, realistic, highly detailed, 8k"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
          "default": ""
        },
        "performance": {
          "enum": [
            "Speed",
            "Quality",
            "Extreme Speed",
            "Lightning"
          ],
          "title": "Performance",
          "type": "string",
          "description": "\n            You can choose Speed or Quality\n        ",
          "default": "Extreme Speed"
        },
        "styles": {
          "title": "Styles",
          "type": "array",
          "description": "\n            The style to use.\n        ",
          "uniqueItems": true,
          "items": {
            "enum": [
              "Fooocus V2",
              "Fooocus Enhance",
              "Fooocus Sharp",
              "Fooocus Semi Realistic",
              "Fooocus Masterpiece",
              "Fooocus Photograph",
              "Fooocus Negative",
              "Fooocus Cinematic",
              "SAI 3D Model",
              "SAI Analog Film",
              "SAI Anime",
              "SAI Cinematic",
              "SAI Comic Book",
              "SAI Craft Clay",
              "SAI Digital Art",
              "SAI Enhance",
              "SAI Fantasy Art",
              "SAI Isometric",
              "SAI Line Art",
              "SAI Lowpoly",
              "SAI Neonpunk",
              "SAI Origami",
              "SAI Photographic",
              "SAI Pixel Art",
              "SAI Texture",
              "MRE Cinematic Dynamic",
              "MRE Spontaneous Picture",
              "MRE Artistic Vision",
              "MRE Dark Dream",
              "MRE Gloomy Art",
              "MRE Bad Dream",
              "MRE Underground",
              "MRE Surreal Painting",
              "MRE Dynamic Illustration",
              "MRE Undead Art",
              "MRE Elemental Art",
              "MRE Space Art",
              "MRE Ancient Illustration",
              "MRE Brave Art",
              "MRE Heroic Fantasy",
              "MRE Dark Cyberpunk",
              "MRE Lyrical Geometry",
              "MRE Sumi E Symbolic",
              "MRE Sumi E Detailed",
              "MRE Manga",
              "MRE Anime",
              "MRE Comic",
              "Ads Advertising",
              "Ads Automotive",
              "Ads Corporate",
              "Ads Fashion Editorial",
              "Ads Food Photography",
              "Ads Gourmet Food Photography",
              "Ads Luxury",
              "Ads Real Estate",
              "Ads Retail",
              "Artstyle Abstract",
              "Artstyle Abstract Expressionism",
              "Artstyle Art Deco",
              "Artstyle Art Nouveau",
              "Artstyle Constructivist",
              "Artstyle Cubist",
              "Artstyle Expressionist",
              "Artstyle Graffiti",
              "Artstyle Hyperrealism",
              "Artstyle Impressionist",
              "Artstyle Pointillism",
              "Artstyle Pop Art",
              "Artstyle Psychedelic",
              "Artstyle Renaissance",
              "Artstyle Steampunk",
              "Artstyle Surrealist",
              "Artstyle Typography",
              "Artstyle Watercolor",
              "Futuristic Biomechanical",
              "Futuristic Biomechanical Cyberpunk",
              "Futuristic Cybernetic",
              "Futuristic Cybernetic Robot",
              "Futuristic Cyberpunk Cityscape",
              "Futuristic Futuristic",
              "Futuristic Retro Cyberpunk",
              "Futuristic Retro Futurism",
              "Futuristic Sci Fi",
              "Futuristic Vaporwave",
              "Game Bubble Bobble",
              "Game Cyberpunk Game",
              "Game Fighting Game",
              "Game Gta",
              "Game Mario",
              "Game Minecraft",
              "Game Pokemon",
              "Game Retro Arcade",
              "Game Retro Game",
              "Game Rpg Fantasy Game",
              "Game Strategy Game",
              "Game Streetfighter",
              "Game Zelda",
              "Misc Architectural",
              "Misc Disco",
              "Misc Dreamscape",
              "Misc Dystopian",
              "Misc Fairy Tale",
              "Misc Gothic",
              "Misc Grunge",
              "Misc Horror",
              "Misc Kawaii",
              "Misc Lovecraftian",
              "Misc Macabre",
              "Misc Manga",
              "Misc Metropolis",
              "Misc Minimalist",
              "Misc Monochrome",
              "Misc Nautical",
              "Misc Space",
              "Misc Stained Glass",
              "Misc Techwear Fashion",
              "Misc Tribal",
              "Misc Zentangle",
              "Papercraft Collage",
              "Papercraft Flat Papercut",
              "Papercraft Kirigami",
              "Papercraft Paper Mache",
              "Papercraft Paper Quilling",
              "Papercraft Papercut Collage",
              "Papercraft Papercut Shadow Box",
              "Papercraft Stacked Papercut",
              "Papercraft Thick Layered Papercut",
              "Photo Alien",
              "Photo Film Noir",
              "Photo Glamour",
              "Photo Hdr",
              "Photo Iphone Photographic",
              "Photo Long Exposure",
              "Photo Neon Noir",
              "Photo Silhouette",
              "Photo Tilt Shift",
              "Cinematic Diva",
              "Abstract Expressionism",
              "Academia",
              "Action Figure",
              "Adorable 3D Character",
              "Adorable Kawaii",
              "Art Deco",
              "Art Nouveau",
              "Astral Aura",
              "Avant Garde",
              "Baroque",
              "Bauhaus Style Poster",
              "Blueprint Schematic Drawing",
              "Caricature",
              "Cel Shaded Art",
              "Character Design Sheet",
              "Classicism Art",
              "Color Field Painting",
              "Colored Pencil Art",
              "Conceptual Art",
              "Constructivism",
              "Cubism",
              "Dadaism",
              "Dark Fantasy",
              "Dark Moody Atmosphere",
              "Dmt Art Style",
              "Doodle Art",
              "Double Exposure",
              "Dripping Paint Splatter Art",
              "Expressionism",
              "Faded Polaroid Photo",
              "Fauvism",
              "Flat 2d Art",
              "Fortnite Art Style",
              "Futurism",
              "Glitchcore",
              "Glo Fi",
              "Googie Art Style",
              "Graffiti Art",
              "Harlem Renaissance Art",
              "High Fashion",
              "Idyllic",
              "Impressionism",
              "Infographic Drawing",
              "Ink Dripping Drawing",
              "Japanese Ink Drawing",
              "Knolling Photography",
              "Light Cheery Atmosphere",
              "Logo Design",
              "Luxurious Elegance",
              "Macro Photography",
              "Mandola Art",
              "Marker Drawing",
              "Medievalism",
              "Minimalism",
              "Neo Baroque",
              "Neo Byzantine",
              "Neo Futurism",
              "Neo Impressionism",
              "Neo Rococo",
              "Neoclassicism",
              "Op Art",
              "Ornate And Intricate",
              "Pencil Sketch Drawing",
              "Pop Art 2",
              "Rococo",
              "Silhouette Art",
              "Simple Vector Art",
              "Sketchup",
              "Steampunk 2",
              "Surrealism",
              "Suprematism",
              "Terragen",
              "Tranquil Relaxing Atmosphere",
              "Sticker Designs",
              "Vibrant Rim Light",
              "Volumetric Lighting",
              "Watercolor 2",
              "Whimsical And Playful",
              "Mk Chromolithography",
              "Mk Cross Processing Print",
              "Mk Dufaycolor Photograph",
              "Mk Herbarium",
              "Mk Punk Collage",
              "Mk Mosaic",
              "Mk Van Gogh",
              "Mk Coloring Book",
              "Mk Singer Sargent",
              "Mk Pollock",
              "Mk Basquiat",
              "Mk Andy Warhol",
              "Mk Halftone Print",
              "Mk Gond Painting",
              "Mk Albumen Print",
              "Mk Aquatint Print",
              "Mk Anthotype Print",
              "Mk Inuit Carving",
              "Mk Bromoil Print",
              "Mk Calotype Print",
              "Mk Color Sketchnote",
              "Mk Cibulak Porcelain",
              "Mk Alcohol Ink Art",
              "Mk One Line Art",
              "Mk Blacklight Paint",
              "Mk Carnival Glass",
              "Mk Cyanotype Print",
              "Mk Cross Stitching",
              "Mk Encaustic Paint",
              "Mk Embroidery",
              "Mk Gyotaku",
              "Mk Luminogram",
              "Mk Lite Brite Art",
              "Mk Mokume Gane",
              "Pebble Art",
              "Mk Palekh",
              "Mk Suminagashi",
              "Mk Scrimshaw",
              "Mk Shibori",
              "Mk Vitreous Enamel",
              "Mk Ukiyo E",
              "Mk Vintage Airline Poster",
              "Mk Vintage Travel Poster",
              "Mk Bauhaus Style",
              "Mk Afrofuturism",
              "Mk Atompunk",
              "Mk Constructivism",
              "Mk Chicano Art",
              "Mk De Stijl",
              "Mk Dayak Art",
              "Mk Fayum Portrait",
              "Mk Illuminated Manuscript",
              "Mk Kalighat Painting",
              "Mk Madhubani Painting",
              "Mk Pictorialism",
              "Mk Pichwai Painting",
              "Mk Patachitra Painting",
              "Mk Samoan Art Inspired",
              "Mk Tlingit Art",
              "Mk Adnate Style",
              "Mk Ron English Style",
              "Mk Shepard Fairey Style"
            ],
            "type": "string"
          },
          "default": [
            "Fooocus Enhance",
            "Fooocus V2",
            "Fooocus Sharp"
          ]
        },
        "image_prompt_3": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": [
            {
              "path": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors",
              "scale": 0.1
            }
          ]
        },
        "image_prompt_4": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 30,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "sharpness": {
          "minimum": 0,
          "title": "Sharpness",
          "type": "number",
          "maximum": 30,
          "description": "\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ",
          "default": 2
        },
        "mixing_image_prompt_and_inpaint": {
          "title": "Mixing Image Prompt and Inpaint",
          "type": "boolean",
          "description": "Mixing Image Prompt and Inpaint",
          "default": false
        },
        "outpaint_selections": {
          "title": "Outpaint Direction",
          "type": "array",
          "description": "The directions to outpaint.",
          "uniqueItems": true,
          "items": {
            "enum": [
              "Left",
              "Right",
              "Top",
              "Bottom"
            ],
            "type": "string"
          },
          "default": []
        },
        "inpaint_image_url": {
          "examples": [
            "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo.png"
          ],
          "title": "Inpaint Image Url",
          "type": "string",
          "description": "The image to use as a reference for inpainting."
        },
        "refiner_model": {
          "enum": [
            "None",
            "realisticVisionV60B1_v51VAE.safetensors"
          ],
          "title": "Refiner Model",
          "type": "string",
          "description": "Refiner (SDXL or SD 1.5)",
          "default": "None"
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "image_prompt_2": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "inpaint_respective_field": {
          "description": "\n            The area to inpaint. Value 0 is same as \"Only Masked\" in A1111. Value 1 is\n            same as \"Whole Image\" in A1111. Only used in inpaint, not used in outpaint.\n            (Outpaint always use 1.0)\n        ",
          "type": "number",
          "minimum": 0,
          "title": "Inpaint Respective Field",
          "maximum": 1,
          "multipleOf": 0.001,
          "default": 0.618
        },
        "inpaint_mode": {
          "enum": [
            "Inpaint or Outpaint (default)",
            "Improve Detail (face, hand, eyes, etc.)",
            "Modify Content (add objects, change background, etc.)"
          ],
          "title": "Inpaint Mode",
          "type": "string",
          "description": "The mode to use for inpainting.",
          "default": "Inpaint or Outpaint (default)"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "seed": {
          "examples": [
            176400
          ],
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
          "nullable": true
        },
        "refiner_switch": {
          "description": "\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ",
          "type": "number",
          "minimum": 0,
          "title": "Refiner Switch At",
          "maximum": 1,
          "multipleOf": 0.0001,
          "default": 0.8
        },
        "inpaint_disable_initial_latent": {
          "title": "Disable Initial Latent In Inpaint",
          "type": "boolean",
          "description": "If set to true, the initial preprocessing will be disabled.",
          "default": false
        },
        "mask_image_url": {
          "examples": [
            "https://raw.githubusercontent.com/CompVis/latent-diffusion/main/data/inpainting_examples/overture-creations-5sI6fQgYIuo_mask.png"
          ],
          "title": "Mask Image Url",
          "type": "string",
          "description": "The image to use as a mask for the generated image."
        },
        "invert_mask": {
          "title": "Invert Mask",
          "type": "boolean",
          "description": "If set to true, the mask will be inverted.",
          "default": false
        },
        "image_prompt_1": {
          "$ref": "#/components/schemas/ImagePrompt"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to false, the safety checker will be disabled.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "\n            Number of images to generate in one request\n        ",
          "default": 1
        },
        "aspect_ratio": {
          "title": "Aspect Ratio",
          "type": "string",
          "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ",
          "default": "1024x1024"
        },
        "inpaint_additional_prompt": {
          "title": "Inpaint Additional Prompt",
          "type": "string",
          "description": "Describe what you want to inpaint.",
          "default": ""
        },
        "inpaint_strength": {
          "description": "\n            Same as the denoising strength in A1111 inpaint. Only used in inpaint, not\n            used in outpaint. (Outpaint always use 1.0)\n        ",
          "type": "number",
          "title": "Inpaint Denoising Strength",
          "maximum": 1,
          "multipleOf": 0.001,
          "exclusiveMinimum": 0,
          "default": 1
        },
        "override_inpaint_options": {
          "title": "Override Inpaint Options",
          "type": "boolean",
          "description": "\n            If set to true, the advanced inpaint options ('inpaint_disable_initial_latent',\n            'inpaint_engine', 'inpaint_strength', 'inpaint_respective_field',\n            'inpaint_erode_or_dilate') will be overridden.\n            Otherwise, the default values will be used.\n        ",
          "default": false
        },
        "inpaint_engine": {
          "enum": [
            "None",
            "v1",
            "v2.5",
            "v2.6"
          ],
          "title": "Inpaint Engine",
          "type": "string",
          "description": "Version of Fooocus inpaint model",
          "default": "v2.6"
        },
        "inpaint_erode_or_dilate": {
          "description": "\n            Positive value will make white area in the mask larger, negative value will\n            make white area smaller. (default is 0, always process before any mask\n            invert)\n        ",
          "type": "number",
          "minimum": -64,
          "title": "Mask Erode or Dilate",
          "maximum": 64,
          "multipleOf": 1,
          "default": 0
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "styles",
        "performance",
        "guidance_scale",
        "sharpness",
        "aspect_ratio",
        "num_images",
        "loras",
        "refiner_model",
        "refiner_switch",
        "output_format",
        "sync_mode",
        "seed",
        "inpaint_image_url",
        "mask_image_url",
        "inpaint_mode",
        "inpaint_additional_prompt",
        "outpaint_selections",
        "override_inpaint_options",
        "inpaint_disable_initial_latent",
        "inpaint_engine",
        "inpaint_strength",
        "inpaint_respective_field",
        "inpaint_erode_or_dilate",
        "invert_mask",
        "image_prompt_1",
        "image_prompt_2",
        "image_prompt_3",
        "image_prompt_4",
        "mixing_image_prompt_and_inpaint",
        "enable_safety_checker"
      ],
      "required": [
        "inpaint_image_url"
      ]
    }
  },
  {
    "id": "fal-ai/lcm",
    "name": "Latent Consistency (SDXL & SDv1.5)",
    "description": "Produce high-quality images with minimal inference steps.",
    "category": "text-to-image",
    "thumbnail_url": "https://fal-cdn.batuhan-941.workers.dev/files/penguin/FS1_8TqEc1VEk8fFSes1C.jpeg",
    "tags": [
      "diffusion",
      "lcm",
      "real-time"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LCMInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "a black cat with glowing eyes, cute, adorable, disney, pixar, highly detailed, 8k",
            "an island near sea, with seagulls, moon shining over the sea, light house, boats int he background, fish flying over the sea"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "controlnet_inpaint": {
          "title": "Controlnet Inpaint",
          "type": "boolean",
          "description": "\n            If set to true, the inpainting pipeline will use controlnet inpainting.\n            Only effective for inpainting pipelines.\n        ",
          "default": false
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n\n            If not provided:\n            - For text-to-image generations, the default size is 512x512.\n            - For image-to-image generations, the default size is the same as the input image.\n            - For inpainting generations, the default size is the same as the input image.\n        "
        },
        "enable_safety_checks": {
          "title": "Enable Safety Checks",
          "type": "boolean",
          "description": "\n            If set to true, the resulting image will be checked whether it includes any\n            potentially unsafe content. If it does, it will be replaced with a black\n            image.\n        ",
          "default": true
        },
        "model": {
          "enum": [
            "sdxl",
            "sdv1-5"
          ],
          "title": "Model",
          "type": "string",
          "description": "The model to use for generating the image.",
          "default": "sdv1-5"
        },
        "lora_url": {
          "title": "Lora Url",
          "type": "string",
          "description": "\n            The url of the lora server to use for image generation.\n        "
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "maximum": 8,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 1
        },
        "negative_prompt": {
          "examples": [
            "cartoon, illustration, animation. face. male, female",
            "ugly, deformed"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "inpaint_mask_only": {
          "title": "Inpaint Mask Only",
          "type": "boolean",
          "description": "\n            If set to true, the inpainting pipeline will only inpaint the provided mask\n            area. Only effective for inpainting pipelines.\n        ",
          "default": false
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 8,
          "description": "\n            The number of images to generate. The function will return a list of images\n            with the same prompt and negative prompt but different seeds.\n        ",
          "default": 1
        },
        "lora_scale": {
          "title": "Lora Scale",
          "type": "number",
          "description": "\n            The scale of the lora server to use for image generation.\n        ",
          "default": 1
        },
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/lcm/inpaint_image.png",
            "https://storage.googleapis.com/falserverless/model_tests/lcm/beach.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "\n        The base image to use for guiding the image generation on image-to-image\n        generations. If the either width or height of the image is larger than 1024\n        pixels, the image will be resized to 1024 pixels while keeping the aspect ratio.\n        "
        },
        "strength": {
          "minimum": 0,
          "title": "Strength",
          "type": "number",
          "maximum": 1,
          "description": "\n        The strength of the image that is passed as `image_url`. The strength\n        determines how much the generated image will be similar to the image passed as\n        `image_url`. The higher the strength the more model gets \"creative\" and\n        generates an image that's different from the initial image. A strength of 1.0\n        means that the initial image is more or less ignored and the model will try to\n        generate an image that's as close as possible to the prompt.\n        ",
          "default": 0.8
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "request_id": {
          "title": "Request Id",
          "type": "string",
          "description": "\n            An id bound to a request, can be used with response to identify the request\n            itself.\n        ",
          "default": ""
        },
        "seed": {
          "examples": [
            42
          ],
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "mask_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/lcm/inpaint_mask.png"
          ],
          "title": "Mask Url",
          "type": "string",
          "description": "\n        The mask to use for guiding the image generation on image\n        inpainting. The model will focus on the mask area and try to fill it with\n        the most relevant content.\n\n        The mask must be a black and white image where the white area is the area\n        that needs to be filled and the black area is the area that should be\n        ignored.\n\n        The mask must have the same dimensions as the image passed as `image_url`.\n        "
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 12,
          "description": "\n            The number of inference steps to use for generating the image. The more steps\n            the better the image will be but it will also take longer to generate.\n        ",
          "default": 4
        }
      },
      "x-fal-order-properties": [
        "model",
        "prompt",
        "image_url",
        "mask_url",
        "strength",
        "negative_prompt",
        "seed",
        "guidance_scale",
        "num_inference_steps",
        "image_size",
        "sync_mode",
        "num_images",
        "enable_safety_checks",
        "request_id",
        "inpaint_mask_only",
        "controlnet_inpaint",
        "lora_url",
        "lora_scale"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/diffusion-edge",
    "name": "DiffusionEdge",
    "description": "Diffusion based high quality edge detection",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/diffusion_edge_1.png",
    "tags": [
      "detection"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "DiffusionEdgeInput",
      "type": "object",
      "properties": {
        "image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/model_tests/upscale/hamburger.png"
          ],
          "title": "Image Url",
          "type": "string",
          "description": "The text prompt you would like to convert to speech."
        }
      },
      "x-fal-order-properties": [
        "image_url"
      ],
      "required": [
        "image_url"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/fooocus",
    "name": "Fooocus",
    "description": "Default parameters with automated optimizations and quality improvements.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/fooocus/fal_ai_fooocus_cyberpunk-city.jpeg",
    "tags": [
      "stylized"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FooocusLegacyInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "an astronaut in the jungle, cold color palette with butterflies in the background, highly detailed, 8k"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results.",
          "default": ""
        },
        "performance": {
          "enum": [
            "Speed",
            "Quality",
            "Extreme Speed",
            "Lightning"
          ],
          "title": "Performance",
          "type": "string",
          "description": "\n            You can choose Speed or Quality\n        ",
          "default": "Extreme Speed"
        },
        "styles": {
          "title": "Styles",
          "type": "array",
          "description": "\n            The style to use.\n        ",
          "uniqueItems": true,
          "items": {
            "enum": [
              "Fooocus V2",
              "Fooocus Enhance",
              "Fooocus Sharp",
              "Fooocus Semi Realistic",
              "Fooocus Masterpiece",
              "Fooocus Photograph",
              "Fooocus Negative",
              "Fooocus Cinematic",
              "SAI 3D Model",
              "SAI Analog Film",
              "SAI Anime",
              "SAI Cinematic",
              "SAI Comic Book",
              "SAI Craft Clay",
              "SAI Digital Art",
              "SAI Enhance",
              "SAI Fantasy Art",
              "SAI Isometric",
              "SAI Line Art",
              "SAI Lowpoly",
              "SAI Neonpunk",
              "SAI Origami",
              "SAI Photographic",
              "SAI Pixel Art",
              "SAI Texture",
              "MRE Cinematic Dynamic",
              "MRE Spontaneous Picture",
              "MRE Artistic Vision",
              "MRE Dark Dream",
              "MRE Gloomy Art",
              "MRE Bad Dream",
              "MRE Underground",
              "MRE Surreal Painting",
              "MRE Dynamic Illustration",
              "MRE Undead Art",
              "MRE Elemental Art",
              "MRE Space Art",
              "MRE Ancient Illustration",
              "MRE Brave Art",
              "MRE Heroic Fantasy",
              "MRE Dark Cyberpunk",
              "MRE Lyrical Geometry",
              "MRE Sumi E Symbolic",
              "MRE Sumi E Detailed",
              "MRE Manga",
              "MRE Anime",
              "MRE Comic",
              "Ads Advertising",
              "Ads Automotive",
              "Ads Corporate",
              "Ads Fashion Editorial",
              "Ads Food Photography",
              "Ads Gourmet Food Photography",
              "Ads Luxury",
              "Ads Real Estate",
              "Ads Retail",
              "Artstyle Abstract",
              "Artstyle Abstract Expressionism",
              "Artstyle Art Deco",
              "Artstyle Art Nouveau",
              "Artstyle Constructivist",
              "Artstyle Cubist",
              "Artstyle Expressionist",
              "Artstyle Graffiti",
              "Artstyle Hyperrealism",
              "Artstyle Impressionist",
              "Artstyle Pointillism",
              "Artstyle Pop Art",
              "Artstyle Psychedelic",
              "Artstyle Renaissance",
              "Artstyle Steampunk",
              "Artstyle Surrealist",
              "Artstyle Typography",
              "Artstyle Watercolor",
              "Futuristic Biomechanical",
              "Futuristic Biomechanical Cyberpunk",
              "Futuristic Cybernetic",
              "Futuristic Cybernetic Robot",
              "Futuristic Cyberpunk Cityscape",
              "Futuristic Futuristic",
              "Futuristic Retro Cyberpunk",
              "Futuristic Retro Futurism",
              "Futuristic Sci Fi",
              "Futuristic Vaporwave",
              "Game Bubble Bobble",
              "Game Cyberpunk Game",
              "Game Fighting Game",
              "Game Gta",
              "Game Mario",
              "Game Minecraft",
              "Game Pokemon",
              "Game Retro Arcade",
              "Game Retro Game",
              "Game Rpg Fantasy Game",
              "Game Strategy Game",
              "Game Streetfighter",
              "Game Zelda",
              "Misc Architectural",
              "Misc Disco",
              "Misc Dreamscape",
              "Misc Dystopian",
              "Misc Fairy Tale",
              "Misc Gothic",
              "Misc Grunge",
              "Misc Horror",
              "Misc Kawaii",
              "Misc Lovecraftian",
              "Misc Macabre",
              "Misc Manga",
              "Misc Metropolis",
              "Misc Minimalist",
              "Misc Monochrome",
              "Misc Nautical",
              "Misc Space",
              "Misc Stained Glass",
              "Misc Techwear Fashion",
              "Misc Tribal",
              "Misc Zentangle",
              "Papercraft Collage",
              "Papercraft Flat Papercut",
              "Papercraft Kirigami",
              "Papercraft Paper Mache",
              "Papercraft Paper Quilling",
              "Papercraft Papercut Collage",
              "Papercraft Papercut Shadow Box",
              "Papercraft Stacked Papercut",
              "Papercraft Thick Layered Papercut",
              "Photo Alien",
              "Photo Film Noir",
              "Photo Glamour",
              "Photo Hdr",
              "Photo Iphone Photographic",
              "Photo Long Exposure",
              "Photo Neon Noir",
              "Photo Silhouette",
              "Photo Tilt Shift",
              "Cinematic Diva",
              "Abstract Expressionism",
              "Academia",
              "Action Figure",
              "Adorable 3D Character",
              "Adorable Kawaii",
              "Art Deco",
              "Art Nouveau",
              "Astral Aura",
              "Avant Garde",
              "Baroque",
              "Bauhaus Style Poster",
              "Blueprint Schematic Drawing",
              "Caricature",
              "Cel Shaded Art",
              "Character Design Sheet",
              "Classicism Art",
              "Color Field Painting",
              "Colored Pencil Art",
              "Conceptual Art",
              "Constructivism",
              "Cubism",
              "Dadaism",
              "Dark Fantasy",
              "Dark Moody Atmosphere",
              "Dmt Art Style",
              "Doodle Art",
              "Double Exposure",
              "Dripping Paint Splatter Art",
              "Expressionism",
              "Faded Polaroid Photo",
              "Fauvism",
              "Flat 2d Art",
              "Fortnite Art Style",
              "Futurism",
              "Glitchcore",
              "Glo Fi",
              "Googie Art Style",
              "Graffiti Art",
              "Harlem Renaissance Art",
              "High Fashion",
              "Idyllic",
              "Impressionism",
              "Infographic Drawing",
              "Ink Dripping Drawing",
              "Japanese Ink Drawing",
              "Knolling Photography",
              "Light Cheery Atmosphere",
              "Logo Design",
              "Luxurious Elegance",
              "Macro Photography",
              "Mandola Art",
              "Marker Drawing",
              "Medievalism",
              "Minimalism",
              "Neo Baroque",
              "Neo Byzantine",
              "Neo Futurism",
              "Neo Impressionism",
              "Neo Rococo",
              "Neoclassicism",
              "Op Art",
              "Ornate And Intricate",
              "Pencil Sketch Drawing",
              "Pop Art 2",
              "Rococo",
              "Silhouette Art",
              "Simple Vector Art",
              "Sketchup",
              "Steampunk 2",
              "Surrealism",
              "Suprematism",
              "Terragen",
              "Tranquil Relaxing Atmosphere",
              "Sticker Designs",
              "Vibrant Rim Light",
              "Volumetric Lighting",
              "Watercolor 2",
              "Whimsical And Playful",
              "Mk Chromolithography",
              "Mk Cross Processing Print",
              "Mk Dufaycolor Photograph",
              "Mk Herbarium",
              "Mk Punk Collage",
              "Mk Mosaic",
              "Mk Van Gogh",
              "Mk Coloring Book",
              "Mk Singer Sargent",
              "Mk Pollock",
              "Mk Basquiat",
              "Mk Andy Warhol",
              "Mk Halftone Print",
              "Mk Gond Painting",
              "Mk Albumen Print",
              "Mk Aquatint Print",
              "Mk Anthotype Print",
              "Mk Inuit Carving",
              "Mk Bromoil Print",
              "Mk Calotype Print",
              "Mk Color Sketchnote",
              "Mk Cibulak Porcelain",
              "Mk Alcohol Ink Art",
              "Mk One Line Art",
              "Mk Blacklight Paint",
              "Mk Carnival Glass",
              "Mk Cyanotype Print",
              "Mk Cross Stitching",
              "Mk Encaustic Paint",
              "Mk Embroidery",
              "Mk Gyotaku",
              "Mk Luminogram",
              "Mk Lite Brite Art",
              "Mk Mokume Gane",
              "Pebble Art",
              "Mk Palekh",
              "Mk Suminagashi",
              "Mk Scrimshaw",
              "Mk Shibori",
              "Mk Vitreous Enamel",
              "Mk Ukiyo E",
              "Mk Vintage Airline Poster",
              "Mk Vintage Travel Poster",
              "Mk Bauhaus Style",
              "Mk Afrofuturism",
              "Mk Atompunk",
              "Mk Constructivism",
              "Mk Chicano Art",
              "Mk De Stijl",
              "Mk Dayak Art",
              "Mk Fayum Portrait",
              "Mk Illuminated Manuscript",
              "Mk Kalighat Painting",
              "Mk Madhubani Painting",
              "Mk Pictorialism",
              "Mk Pichwai Painting",
              "Mk Patachitra Painting",
              "Mk Samoan Art Inspired",
              "Mk Tlingit Art",
              "Mk Adnate Style",
              "Mk Ron English Style",
              "Mk Shepard Fairey Style"
            ],
            "type": "string"
          },
          "default": [
            "Fooocus Enhance",
            "Fooocus V2",
            "Fooocus Sharp"
          ]
        },
        "control_type": {
          "enum": [
            "ImagePrompt",
            "PyraCanny",
            "CPDS",
            "FaceSwap"
          ],
          "title": "Control Type",
          "type": "string",
          "examples": [
            "ImagePrompt",
            "PyraCanny",
            "CPDS",
            "FaceSwap"
          ],
          "description": "The type of image control",
          "default": "PyraCanny"
        },
        "mask_image_url": {
          "title": "Mask Image Url",
          "type": "string",
          "description": "The image to use as a mask for the generated image.",
          "nullable": true
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "\n            The LoRAs to use for the image generation. You can use up to 5 LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": [
            {
              "path": "https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors",
              "scale": 0.1
            }
          ]
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to false, the safety checker will be disabled.",
          "default": true
        },
        "sharpness": {
          "minimum": 0,
          "title": "Sharpness",
          "type": "number",
          "maximum": 30,
          "description": "\n            The sharpness of the generated image. Use it to control how sharp the generated\n            image should be. Higher value means image and texture are sharper.\n        ",
          "default": 2
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 30,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 4
        },
        "negative_prompt": {
          "examples": [
            "(worst quality, low quality, normal quality, lowres, low details, oversaturated, undersaturated, overexposed, underexposed, grayscale, bw, bad photo, bad photography, bad art:1.4), (watermark, signature, text font, username, error, logo, words, letters, digits, autograph, trademark, name:1.2), (blur, blurry, grainy), morbid, ugly, asymmetrical, mutated malformed, mutilated, poorly lit, bad shadow, draft, cropped, out of frame, cut off, censored, jpeg artifacts, out of focus, glitch, duplicate, (airbrushed, cartoon, anime, semi-realistic, cgi, render, blender, digital art, manga, amateur:1.3), (3D ,3D Game, 3D Game Scene, 3D Character:1.1), (bad hands, bad anatomy, bad body, bad face, bad teeth, bad arms, bad legs, deformities:1.3)"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "inpaint_image_url": {
          "title": "Inpaint Image Url",
          "type": "string",
          "description": "The image to use as a reference for inpainting.",
          "nullable": true
        },
        "mixing_image_prompt_and_inpaint": {
          "title": "Mixing Image Prompt And Inpaint",
          "type": "boolean",
          "default": false
        },
        "aspect_ratio": {
          "title": "Aspect Ratio",
          "type": "string",
          "description": "\n            The size of the generated image. You can choose between some presets or\n            custom height and width that **must be multiples of 8**.\n        ",
          "default": "1024x1024"
        },
        "num_images": {
          "minimum": 1,
          "title": "Num Images",
          "type": "integer",
          "maximum": 4,
          "description": "\n            Number of images to generate in one request\n        ",
          "default": 1
        },
        "output_format": {
          "enum": [
            "png",
            "jpeg",
            "webp"
          ],
          "title": "Output Format",
          "type": "string",
          "description": "The format of the generated image.",
          "default": "jpeg"
        },
        "refiner_model": {
          "enum": [
            "None",
            "realisticVisionV60B1_v51VAE.safetensors"
          ],
          "title": "Refiner Model",
          "type": "string",
          "description": "Refiner (SDXL or SD 1.5)",
          "default": "None"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "\n            If set to true, the function will wait for the image to be generated and uploaded\n            before returning the response. This will increase the latency of the function but\n            it allows you to get the image directly in the response without going through the CDN.\n        ",
          "default": false
        },
        "control_image_url": {
          "title": "Control Image Url",
          "type": "string",
          "description": "The image to use as a reference for the generated image.",
          "nullable": true
        },
        "seed": {
          "examples": [
            176400
          ],
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        ",
          "nullable": true
        },
        "refiner_switch": {
          "description": "\n            Use 0.4 for SD1.5 realistic models; 0.667 for SD1.5 anime models\n            0.8 for XL-refiners; or any value for switching two SDXL models.\n        ",
          "type": "number",
          "minimum": 0,
          "title": "Refiner Switch At",
          "maximum": 1,
          "multipleOf": 0.0001,
          "default": 0.8
        },
        "control_image_weight": {
          "minimum": 0,
          "title": "Control Image Weight",
          "type": "number",
          "maximum": 2,
          "description": "\n            The strength of the control image. Use it to control how much the generated image\n            should look like the control image.\n        ",
          "default": 1
        },
        "control_image_stop_at": {
          "minimum": 0,
          "title": "Control Image Stop At",
          "type": "number",
          "maximum": 1,
          "description": "\n            The stop at value of the control image. Use it to control how much the generated image\n            should look like the control image.\n        ",
          "default": 1
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "styles",
        "performance",
        "guidance_scale",
        "sharpness",
        "aspect_ratio",
        "num_images",
        "loras",
        "refiner_model",
        "refiner_switch",
        "output_format",
        "sync_mode",
        "seed",
        "control_image_url",
        "control_type",
        "control_image_weight",
        "control_image_stop_at",
        "inpaint_image_url",
        "mask_image_url",
        "mixing_image_prompt_and_inpaint",
        "enable_safety_checker"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/lora",
    "name": "Stable Diffusion with LoRAs",
    "description": "Run Any Stable Diffusion model with customizable LoRA weights.",
    "category": "text-to-image",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/sd-loras.jpeg",
    "tags": [
      "diffusion",
      "lora",
      "customization"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToImageInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Photo of a european medieval 40 year old queen, silver hair, highly detailed face, detailed eyes, head shot, intricate crown, age spots, wrinkles",
            "Photo of a classic red mustang car parked in las vegas strip at night"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "image_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Image Size",
          "description": "\n            The size of the generated image. You can choose between some presets or custom height and width\n            that **must be multiples of 8**.\n        ",
          "default": "square_hd"
        },
        "tile_height": {
          "minimum": 128,
          "maximum": 4096,
          "type": "integer",
          "title": "Tile Height",
          "description": "The size of the tiles to be used for the image generation.",
          "default": 4096
        },
        "embeddings": {
          "title": "Embeddings",
          "type": "array",
          "description": "\n            The embeddings to use for the image generation. Only a single embedding is supported at the moment.\n            The embeddings will be used to map the tokens in the prompt to the embedding weights.\n        ",
          "items": {
            "$ref": "#/components/schemas/Embedding"
          },
          "default": []
        },
        "ic_light_model_url": {
          "title": "Ic Light Model Url",
          "type": "string",
          "description": "\n            The URL of the IC Light model to use for the image generation.\n        "
        },
        "image_encoder_weight_name": {
          "examples": [
            "pytorch_model.bin"
          ],
          "title": "Image Encoder Weight Name",
          "type": "string",
          "description": "\n            The weight name of the image encoder model to use for the image generation.\n        ",
          "default": "pytorch_model.bin"
        },
        "ip_adapter": {
          "title": "Ip Adapter",
          "type": "array",
          "description": "\n            The IP adapter to use for the image generation.\n        ",
          "items": {
            "$ref": "#/components/schemas/IPAdapter"
          },
          "default": []
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "scheduler": {
          "enum": [
            "DPM++ 2M",
            "DPM++ 2M Karras",
            "DPM++ 2M SDE",
            "DPM++ 2M SDE Karras",
            "Euler",
            "Euler A",
            "Euler (trailing timesteps)",
            "LCM",
            "LCM (trailing timesteps)",
            "DDIM",
            "TCD"
          ],
          "title": "Scheduler",
          "type": "string",
          "description": "Scheduler / sampler to use for the image denoising process."
        },
        "sigmas": {
          "default": {
            "method": "default",
            "array": []
          },
          "title": "Sigmas",
          "description": "\n            Optionally override the sigmas to use for the denoising process. Only works with schedulers which support the `sigmas` argument in their `set_sigmas` method.\n            Defaults to not overriding, in which case the scheduler automatically sets the sigmas based on the `num_inference_steps` parameter.\n            If set to a custom sigma schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `timesteps` is set.\n        ",
          "allOf": [
            {
              "$ref": "#/components/schemas/SigmasInput"
            }
          ]
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 7.5
        },
        "tile_stride_width": {
          "minimum": 64,
          "maximum": 2048,
          "type": "integer",
          "title": "Tile Stride Width",
          "description": "The stride of the tiles to be used for the image generation.",
          "default": 2048
        },
        "debug_per_pass_latents": {
          "title": "Debug Per Pass Latents",
          "type": "boolean",
          "description": "If set to true, the latents will be saved for debugging per pass.",
          "default": false
        },
        "timesteps": {
          "default": {
            "method": "default",
            "array": []
          },
          "title": "Timesteps",
          "description": "\n            Optionally override the timesteps to use for the denoising process. Only works with schedulers which support the `timesteps` argument in their `set_timesteps` method.\n            Defaults to not overriding, in which case the scheduler automatically sets the timesteps based on the `num_inference_steps` parameter.\n            If set to a custom timestep schedule, the `num_inference_steps` parameter will be ignored. Cannot be set if `sigmas` is set.\n        ",
          "allOf": [
            {
              "$ref": "#/components/schemas/TimestepsInput"
            }
          ]
        },
        "image_encoder_subfolder": {
          "examples": [],
          "title": "Image Encoder Subfolder",
          "type": "string",
          "description": "\n            The subfolder of the image encoder model to use for the image generation.\n        "
        },
        "prompt_weighting": {
          "examples": [
            true
          ],
          "title": "Prompt Weighting",
          "type": "boolean",
          "description": "\n            If set to true, the prompt weighting syntax will be used.\n            Additionally, this will lift the 77 token limit by averaging embeddings.\n        ",
          "default": false
        },
        "variant": {
          "title": "Variant",
          "type": "string",
          "description": "The variant of the model to use for huggingface models, e.g. 'fp16'."
        },
        "model_name": {
          "examples": [
            "stabilityai/stable-diffusion-xl-base-1.0",
            "runwayml/stable-diffusion-v1-5",
            "SG161222/Realistic_Vision_V2.0"
          ],
          "title": "Model Name",
          "type": "string",
          "description": "URL or HuggingFace ID of the base model to generate the image."
        },
        "controlnet_guess_mode": {
          "title": "Controlnet Guess Mode",
          "type": "boolean",
          "description": "\n            If set to true, the controlnet will be applied to only the conditional predictions.\n        ",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "ic_light_model_background_image_url": {
          "title": "Ic Light Model Background Image Url",
          "type": "string",
          "description": "\n            The URL of the IC Light model background image to use for the image generation.\n            Make sure to use a background compatible with the model.\n        "
        },
        "rescale_betas_snr_zero": {
          "title": "Rescale Betas Snr Zero",
          "type": "boolean",
          "description": "\n            Whether to set the rescale_betas_snr_zero option or not for the sampler\n        ",
          "default": false
        },
        "tile_width": {
          "minimum": 128,
          "maximum": 4096,
          "type": "integer",
          "title": "Tile Width",
          "description": "The size of the tiles to be used for the image generation.",
          "default": 4096
        },
        "prediction_type": {
          "enum": [
            "v_prediction",
            "epsilon"
          ],
          "title": "Prediction Type",
          "type": "string",
          "description": "\n            The type of prediction to use for the image generation.\n            The `epsilon` is the default.\n        ",
          "default": "epsilon"
        },
        "eta": {
          "minimum": 0,
          "maximum": 1,
          "type": "number",
          "title": "Eta",
          "description": "The eta value to be used for the image generation.",
          "default": 0
        },
        "image_encoder_path": {
          "title": "Image Encoder Path",
          "type": "string",
          "description": "\n            The path to the image encoder model to use for the image generation.\n        "
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "negative_prompt": {
          "examples": [
            "cartoon, painting, illustration, worst quality, low quality, normal quality"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use.Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": ""
        },
        "image_format": {
          "enum": [
            "jpeg",
            "png"
          ],
          "title": "Image Format",
          "type": "string",
          "description": "The format of the generated image.",
          "examples": [
            "jpeg"
          ],
          "default": "png"
        },
        "num_images": {
          "minimum": 1,
          "maximum": 8,
          "type": "integer",
          "title": "Number of images",
          "description": "\n            Number of images to generate in one request. Note that the higher the batch size,\n            the longer it will take to generate the images.\n        ",
          "default": 1
        },
        "debug_latents": {
          "title": "Debug Latents",
          "type": "boolean",
          "description": "If set to true, the latents will be saved for debugging.",
          "default": false
        },
        "ic_light_image_url": {
          "title": "Ic Light Image Url",
          "type": "string",
          "description": "\n            The URL of the IC Light model image to use for the image generation.\n        "
        },
        "unet_name": {
          "title": "Unet Name",
          "type": "string",
          "description": "URL or HuggingFace ID of the custom U-Net model to use for the image generation."
        },
        "clip_skip": {
          "minimum": 0,
          "maximum": 2,
          "type": "integer",
          "title": "Clip Skip",
          "description": "\n            Skips part of the image generation process, leading to slightly different results.\n            This means the image renders faster, too.\n        ",
          "default": 0
        },
        "tile_stride_height": {
          "minimum": 64,
          "maximum": 2048,
          "type": "integer",
          "title": "Tile Stride Height",
          "description": "The stride of the tiles to be used for the image generation.",
          "default": 2048
        },
        "controlnets": {
          "title": "Controlnets",
          "type": "array",
          "description": "\n            The control nets to use for the image generation. You can use any number of control nets\n            and they will be applied to the image at the specified timesteps.\n        ",
          "items": {
            "$ref": "#/components/schemas/ControlNet"
          },
          "default": []
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 150,
          "type": "integer",
          "title": "Number of inference steps",
          "description": "\n            Increasing the amount of steps tells Stable Diffusion that it should take more steps\n            to generate your final result which can increase the amount of detail in your image.\n        ",
          "default": 30
        }
      },
      "x-fal-order-properties": [
        "model_name",
        "unet_name",
        "variant",
        "prompt",
        "negative_prompt",
        "prompt_weighting",
        "loras",
        "embeddings",
        "controlnets",
        "controlnet_guess_mode",
        "ip_adapter",
        "image_encoder_path",
        "image_encoder_subfolder",
        "image_encoder_weight_name",
        "ic_light_model_url",
        "ic_light_model_background_image_url",
        "ic_light_image_url",
        "seed",
        "image_size",
        "num_inference_steps",
        "guidance_scale",
        "clip_skip",
        "scheduler",
        "timesteps",
        "sigmas",
        "prediction_type",
        "rescale_betas_snr_zero",
        "image_format",
        "num_images",
        "enable_safety_checker",
        "tile_width",
        "tile_height",
        "tile_stride_width",
        "tile_stride_height",
        "eta",
        "debug_latents",
        "debug_per_pass_latents"
      ],
      "required": [
        "model_name",
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/kling-video/v2.5-turbo/pro/text-to-video",
    "name": "Kling v2.5 Text to Video",
    "description": "Kling 2.5 Turbo Pro: Top-tier text-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3.fal.media/files/panda/6YaK9lV7ySsUA9I3dUp5r_8a807b0c8e2641db9e345107ab8a809e.jpg",
    "tags": [
      "animation",
      "stylized"
    ],
    "highlighted": true,
    "pinned": true,
    "input_schema": {
      "title": "TextToVideoV25ProRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A noble lord walks among his people, his presence a comforting reassurance. He greets them with a gentle smile, embodying their hopes and earning their respect through simple interactions. The atmosphere is intimate and sincere, highlighting the bond between the leader and community."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "duration",
        "aspect_ratio",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 7,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/veo3/fast",
    "name": "Veo 3 Fast",
    "description": "Faster and more cost effective version of Google's Veo 3! ",
    "category": "text-to-video",
    "thumbnail_url": "/video-thumbnails/veo3-fast-thumb.mp4",
    "tags": [],
    "highlighted": true,
    "pinned": true,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "duration",
        "negative_prompt",
        "enhance_prompt",
        "seed",
        "auto_fix",
        "resolution",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A casual street interview on a busy New York City sidewalk in the afternoon. The interviewer holds a plain, unbranded microphone and asks: Have you seen Google's new Veo3 model It is a super good model. Person replies: Yeah I saw it, it's already available on fal. It's crazy good."
          ],
          "description": "The text prompt describing the video you want to generate",
          "minLength": 1,
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9",
            "1:1"
          ],
          "description": "The aspect ratio of the generated video. If it is set to 1:1, the video will be outpainted.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "4s",
            "6s",
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 33% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "auto_fix": {
          "description": "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them",
          "type": "boolean",
          "title": "Auto Fix",
          "default": true
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "seed": {
          "description": "A seed to use for the video generation",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "description": "A negative prompt to guide the video generation",
          "type": "string",
          "title": "Negative Prompt"
        },
        "enhance_prompt": {
          "description": "Whether to enhance the video generation",
          "type": "boolean",
          "title": "Enhance Prompt",
          "default": true
        }
      },
      "title": "TextToVideoPreviewFastInput",
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-02/standard/text-to-video",
    "name": "MiniMax Hailuo 02 [Standard] (Text to Video)",
    "description": "MiniMax Hailuo-02 Text To Video API (Standard, 768p): Advanced video generation model with 768p resolution",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "StandardTextToVideoHailuo02Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "duration": {
          "enum": [
            "6",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the video in seconds. 10 seconds videos are not supported for 1080p resolution.",
          "default": "6"
        },
        "prompt": {
          "examples": [
            "A Galactic Smuggler is a rogue figure with a cybernetic arm and a well-worn coat that hints at many dangerous escapades across the galaxy. Their ship is filled with rare and exotic treasures from distant planets, concealed in hidden compartments, showing their expertise in illicit trade. Their belt is adorned with energy-based weapons, ready to be drawn at any moment to protect themselves or escape from tight situations. This character thrives in the shadows of space, navigating between the law and chaos with stealth and wit, always seeking the next big score while evading bounty hunters and law enforcement. The rogue's ship, rugged yet efficient, serves as both a home and a tool for their dangerous lifestyle. The treasures they collect reflect the diverse and intriguing worlds they've encountered\u2014alien artifacts, rare minerals, and artifacts of unknown origin. Their reputation precedes them, with whispers of their dealings and the deadly encounters that often follow. A master of negotiation and deception, the Galactic Smuggler navigates the cosmos with an eye on the horizon, always one step ahead of those who pursue them."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000,
          "minLength": 1
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "duration",
        "prompt_optimizer"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 5,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/veo3",
    "name": "Veo 3",
    "description": "Veo 3 by Google, the most advanced AI video generation model in the world. With sound on!",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "duration",
        "negative_prompt",
        "enhance_prompt",
        "seed",
        "auto_fix",
        "resolution",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A casual street interview on a busy New York City sidewalk in the afternoon. The interviewer holds a plain, unbranded microphone and asks: Have you seen Google's new Veo3 model It is a super good model. Person replies: Yeah I saw it, it's already available on fal. It's crazy good."
          ],
          "description": "The text prompt describing the video you want to generate",
          "minLength": 1,
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9",
            "1:1"
          ],
          "description": "The aspect ratio of the generated video. If it is set to 1:1, the video will be outpainted.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "4s",
            "6s",
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 50% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "auto_fix": {
          "description": "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them",
          "type": "boolean",
          "title": "Auto Fix",
          "default": true
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "seed": {
          "description": "A seed to use for the video generation",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "description": "A negative prompt to guide the video generation",
          "type": "string",
          "title": "Negative Prompt"
        },
        "enhance_prompt": {
          "description": "Whether to enhance the video generation",
          "type": "boolean",
          "title": "Enhance Prompt",
          "default": true
        }
      },
      "title": "TextToVideoPreviewInput",
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v2/master/text-to-video",
    "name": "Kling 2.0 Master",
    "description": "Generate video clips from your prompts using Kling 2.0 Master",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-5.jpeg",
    "tags": [],
    "highlighted": true,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoV2MasterRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A slow-motion drone shot descending from above a maze of neon-lit Tokyo alleyways at night during heavy rainfall. The camera gradually focuses on a lone figure in a luminescent white raincoat standing perfectly still amid the bustling crowd, all carrying black umbrellas. As the camera continues its downward journey, we see the raindrops creating rippling patterns on puddles that reflect the kaleidoscope of colors from the surrounding signs, creating a mirror world beneath the city."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "duration",
        "aspect_ratio",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 28,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/hunyuan-video-v1.5/text-to-video",
    "name": "Hunyuan Video V1.5",
    "description": "Hunyuan Video 1.5 is Tencent's latest and best video model",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/9Eu2FRY2-PvDsYSzRJoXL.png",
    "tags": [
      "hunyuan-video",
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "HunyuanVideo15T2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video."
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the video.",
          "default": "16:9"
        },
        "resolution": {
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the video.",
          "const": "480p",
          "default": "480p"
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Enable prompt expansion to enhance the input prompt.",
          "default": true
        },
        "num_frames": {
          "minimum": 1,
          "maximum": 121,
          "type": "integer",
          "title": "Num Frames",
          "description": "The number of frames to generate.",
          "default": 121
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Random seed for reproducibility."
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to guide what not to generate.",
          "default": ""
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps.",
          "default": 28
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_inference_steps",
        "seed",
        "aspect_ratio",
        "resolution",
        "num_frames",
        "enable_prompt_expansion"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/infinity-star/text-to-video",
    "name": "Infinity Star",
    "description": "InfinityStar\u2019s unified 8B spacetime autoregressive engine to turn any text prompt into crisp 720p videos - 10\u00d7 faster than diffusion models.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/eo_C3d0eQJbsr5Yisn1Tg_363925b0a47242e68029c39bc698cb65.jpg",
    "tags": [
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_inference_steps",
        "guidance_scale",
        "tau_video",
        "use_apg",
        "aspect_ratio",
        "seed",
        "enhance_prompt"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A serene mountain landscape at sunset with flowing clouds"
          ],
          "description": "Text prompt for generating the video",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "1:1",
            "9:16"
          ],
          "description": "Aspect ratio of the generated output",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "enhance_prompt": {
          "description": "Whether to use an LLM to enhance the prompt.",
          "type": "boolean",
          "title": "Enhance Prompt",
          "default": true
        },
        "use_apg": {
          "description": "Whether to use APG",
          "type": "boolean",
          "title": "Use Apg",
          "default": true
        },
        "guidance_scale": {
          "minimum": 1,
          "description": "Guidance scale for generation",
          "type": "number",
          "maximum": 40,
          "title": "Guidance Scale",
          "default": 7.5
        },
        "num_inference_steps": {
          "minimum": 1,
          "description": "Number of inference steps",
          "type": "integer",
          "maximum": 100,
          "title": "Num Inference Steps",
          "default": 50
        },
        "seed": {
          "description": "Random seed for reproducibility. Leave empty for random generation.",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "description": "Negative prompt to guide what to avoid in generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        },
        "tau_video": {
          "minimum": 0.1,
          "description": "Tau value for video scale",
          "type": "number",
          "maximum": 1,
          "title": "Tau Video",
          "default": 0.4
        }
      },
      "description": "Input model for text-to-video generation",
      "title": "GenerationInput",
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/sana-video",
    "name": "Sana Video",
    "description": "Leverage Sana's ultra-fast processing speed to generate high-quality assets that transform your text prompts into production-ready videos",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/GCWRmD1TPULLBQ1NCWtwo_02d01a7c0e0b4e5f98c4ed4c18a9be72.jpg",
    "tags": [
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "SanaVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Evening, backlight, side lighting, soft light, high contrast, mid-shot, centered composition, clean solo shot, warm color. A young Caucasian man stands in a forest, golden light glimmers on his hair as sunlight filters through the leaves."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt describing the video to generate"
        },
        "resolution": {
          "enum": [
            "480p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the output video",
          "default": "480p"
        },
        "fps": {
          "minimum": 8,
          "title": "Fps",
          "type": "integer",
          "maximum": 30,
          "description": "Frames per second for the output video",
          "default": 16
        },
        "motion_score": {
          "minimum": 0,
          "title": "Motion Score",
          "type": "integer",
          "maximum": 100,
          "description": "Motion intensity score (higher = more motion)",
          "default": 30
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 20,
          "description": "Guidance scale for generation (higher = more prompt adherence)",
          "default": 6
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "Number of denoising steps",
          "default": 28
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducible generation. If not provided, a random seed will be used."
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt describing what to avoid in the generation",
          "default": "A chaotic sequence with misshapen, deformed limbs in heavy motion blur, sudden disappearance, jump cuts, jerky movements, rapid shot changes, frames out of sync, inconsistent character shapes, temporal artifacts, jitter, and ghosting effects, creating a disorienting visual experience."
        },
        "num_frames": {
          "minimum": 16,
          "title": "Num Frames",
          "type": "integer",
          "maximum": 200,
          "description": "Number of frames to generate",
          "default": 81
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "resolution",
        "num_frames",
        "fps",
        "motion_score",
        "guidance_scale",
        "num_inference_steps",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/longcat-video/text-to-video/720p",
    "name": "LongCat Video",
    "description": "Generate long videos in 720p/30fps from text using LongCat Video",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/CY4FlHWoLckmlvvquFUeu_b3840719e081495983b5fe1d2648f0fb.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LongCat720PCFGVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "realistic filming style, a person wearing a dark helmet, a deep-colored jacket, blue jeans, and bright yellow shoes rides a skateboard along a winding mountain road. The skateboarder starts in a standing position, then gradually lowers into a crouch, extending one hand to touch the road surface while maintaining a low center of gravity to navigate a sharp curve. After completing the turn, the skateboarder rises back to a standing position and continues gliding forward. The background features lush green hills flanking both sides of the road, with distant snow-capped mountain peaks rising against a clear, bright blue sky. The camera follows closely from behind, smoothly tracking the skateboarder\u2019s movements and capturing the dynamic scenery along the route. The scene is shot in natural daylight, highlighting the vivid outdoor environment and the skateboarder\u2019s fluid actions."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to guide the video generation."
        },
        "acceleration": {
          "examples": [
            "regular"
          ],
          "description": "The acceleration level to use for the video generation.",
          "type": "string",
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "default": "regular"
        },
        "fps": {
          "minimum": 1,
          "title": "FPS",
          "type": "integer",
          "description": "The frame rate of the generated video.",
          "maximum": 60,
          "default": 30
        },
        "num_refine_inference_steps": {
          "minimum": 8,
          "title": "Number of Refinement Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use for refinement.",
          "maximum": 50,
          "default": 40
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable safety checker.",
          "default": true
        },
        "num_frames": {
          "description": "The number of frames to generate.",
          "type": "integer",
          "minimum": 17,
          "title": "Number of Frames",
          "maximum": 961,
          "default": 162
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale",
          "type": "number",
          "description": "The guidance scale to use for the video generation.",
          "maximum": 10,
          "default": 4
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use for the video generation.",
          "default": "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the generated video.",
          "default": "balanced"
        },
        "video_output_type": {
          "enum": [
            "X264 (.mp4)",
            "VP9 (.webm)",
            "PRORES4444 (.mov)",
            "GIF (.gif)"
          ],
          "title": "Video Output Type",
          "type": "string",
          "description": "The output type of the generated video.",
          "default": "X264 (.mp4)"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video.",
          "default": "16:9"
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the generated video.",
          "default": "high"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 8,
          "title": "Number of Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use for the video generation.",
          "maximum": 50,
          "default": 40
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_frames",
        "num_inference_steps",
        "num_refine_inference_steps",
        "guidance_scale",
        "aspect_ratio",
        "fps",
        "seed",
        "enable_prompt_expansion",
        "enable_safety_checker",
        "video_output_type",
        "video_quality",
        "video_write_mode",
        "sync_mode",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 4,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/longcat-video/text-to-video/480p",
    "name": "LongCat Video",
    "description": "Generate long videos from text using LongCat Video",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/zebra/Jsadvlb-GTl-D6qEnTjNV_20034d8c9b054c1ab355507d2b524db7.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LongCatCFGVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "realistic filming style, a person wearing a dark helmet, a deep-colored jacket, blue jeans, and bright yellow shoes rides a skateboard along a winding mountain road. The skateboarder starts in a standing position, then gradually lowers into a crouch, extending one hand to touch the road surface while maintaining a low center of gravity to navigate a sharp curve. After completing the turn, the skateboarder rises back to a standing position and continues gliding forward. The background features lush green hills flanking both sides of the road, with distant snow-capped mountain peaks rising against a clear, bright blue sky. The camera follows closely from behind, smoothly tracking the skateboarder\u2019s movements and capturing the dynamic scenery along the route. The scene is shot in natural daylight, highlighting the vivid outdoor environment and the skateboarder\u2019s fluid actions."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to guide the video generation."
        },
        "acceleration": {
          "examples": [
            "regular"
          ],
          "description": "The acceleration level to use for the video generation.",
          "type": "string",
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "default": "regular"
        },
        "fps": {
          "minimum": 1,
          "title": "FPS",
          "type": "integer",
          "description": "The frame rate of the generated video.",
          "maximum": 60,
          "default": 15
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable safety checker.",
          "default": true
        },
        "num_frames": {
          "description": "The number of frames to generate.",
          "type": "integer",
          "minimum": 17,
          "title": "Number of Frames",
          "maximum": 961,
          "default": 162
        },
        "guidance_scale": {
          "minimum": 1,
          "title": "Guidance Scale",
          "type": "number",
          "description": "The guidance scale to use for the video generation.",
          "maximum": 10,
          "default": 4
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use for the video generation.",
          "default": "Bright tones, overexposed, static, blurred details, subtitles, style, works, paintings, images, static, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, misshapen limbs, fused fingers, still picture, messy background, three legs, many people in the background, walking backwards"
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the generated video.",
          "default": "balanced"
        },
        "video_output_type": {
          "enum": [
            "X264 (.mp4)",
            "VP9 (.webm)",
            "PRORES4444 (.mov)",
            "GIF (.gif)"
          ],
          "title": "Video Output Type",
          "type": "string",
          "description": "The output type of the generated video.",
          "default": "X264 (.mp4)"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video.",
          "default": "16:9"
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the generated video.",
          "default": "high"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 8,
          "title": "Number of Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use for the video generation.",
          "maximum": 50,
          "default": 40
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_frames",
        "num_inference_steps",
        "guidance_scale",
        "aspect_ratio",
        "fps",
        "seed",
        "enable_prompt_expansion",
        "enable_safety_checker",
        "video_output_type",
        "video_quality",
        "video_write_mode",
        "sync_mode",
        "acceleration"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 3,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/longcat-video/distilled/text-to-video/720p",
    "name": "LongCat Video Distilled",
    "description": "Generate long videos in 720p/30fps from text using LongCat Video Distilled",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/LG1BXVYrhBm6J6Dnv4zAP_ee476e357e4e4bc7bcff9a7812d16c1b.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LongCat720PVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "realistic filming style, a person wearing a dark helmet, a deep-colored jacket, blue jeans, and bright yellow shoes rides a skateboard along a winding mountain road. The skateboarder starts in a standing position, then gradually lowers into a crouch, extending one hand to touch the road surface while maintaining a low center of gravity to navigate a sharp curve. After completing the turn, the skateboarder rises back to a standing position and continues gliding forward. The background features lush green hills flanking both sides of the road, with distant snow-capped mountain peaks rising against a clear, bright blue sky. The camera follows closely from behind, smoothly tracking the skateboarder\u2019s movements and capturing the dynamic scenery along the route. The scene is shot in natural daylight, highlighting the vivid outdoor environment and the skateboarder\u2019s fluid actions."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to guide the video generation."
        },
        "video_output_type": {
          "enum": [
            "X264 (.mp4)",
            "VP9 (.webm)",
            "PRORES4444 (.mov)",
            "GIF (.gif)"
          ],
          "title": "Video Output Type",
          "type": "string",
          "description": "The output type of the generated video.",
          "default": "X264 (.mp4)"
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the generated video.",
          "default": "balanced"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video.",
          "default": "16:9"
        },
        "fps": {
          "minimum": 1,
          "title": "FPS",
          "type": "integer",
          "description": "The frame rate of the generated video.",
          "maximum": 60,
          "default": 30
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the generated video.",
          "default": "high"
        },
        "num_refine_inference_steps": {
          "minimum": 2,
          "title": "Number of Refinement Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use for refinement.",
          "maximum": 16,
          "default": 12
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "num_frames": {
          "description": "The number of frames to generate.",
          "type": "integer",
          "minimum": 17,
          "title": "Number of Frames",
          "maximum": 961,
          "default": 162
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable safety checker.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Number of Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use.",
          "maximum": 16,
          "default": 12
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_frames",
        "num_inference_steps",
        "num_refine_inference_steps",
        "aspect_ratio",
        "fps",
        "seed",
        "enable_prompt_expansion",
        "enable_safety_checker",
        "video_output_type",
        "video_quality",
        "video_write_mode",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 1,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/longcat-video/distilled/text-to-video/480p",
    "name": "LongCat Video Distilled",
    "description": "Generate long videos from text using LongCat Video Distilled",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/koala/RWTqBORnZpIgG6D_kh88p_14d4a40aa377471984f0b04b20947d82.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LongCatVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "realistic filming style, a person wearing a dark helmet, a deep-colored jacket, blue jeans, and bright yellow shoes rides a skateboard along a winding mountain road. The skateboarder starts in a standing position, then gradually lowers into a crouch, extending one hand to touch the road surface while maintaining a low center of gravity to navigate a sharp curve. After completing the turn, the skateboarder rises back to a standing position and continues gliding forward. The background features lush green hills flanking both sides of the road, with distant snow-capped mountain peaks rising against a clear, bright blue sky. The camera follows closely from behind, smoothly tracking the skateboarder\u2019s movements and capturing the dynamic scenery along the route. The scene is shot in natural daylight, highlighting the vivid outdoor environment and the skateboarder\u2019s fluid actions."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to guide the video generation."
        },
        "video_output_type": {
          "enum": [
            "X264 (.mp4)",
            "VP9 (.webm)",
            "PRORES4444 (.mov)",
            "GIF (.gif)"
          ],
          "title": "Video Output Type",
          "type": "string",
          "description": "The output type of the generated video.",
          "default": "X264 (.mp4)"
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the generated video.",
          "default": "balanced"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video.",
          "default": "16:9"
        },
        "fps": {
          "minimum": 1,
          "title": "FPS",
          "type": "integer",
          "description": "The frame rate of the generated video.",
          "maximum": 60,
          "default": 15
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the generated video.",
          "default": "high"
        },
        "sync_mode": {
          "title": "Sync Mode",
          "type": "boolean",
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "default": false
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        },
        "num_frames": {
          "description": "The number of frames to generate.",
          "type": "integer",
          "minimum": 17,
          "title": "Number of Frames",
          "maximum": 961,
          "default": 162
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable safety checker.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Number of Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to use.",
          "maximum": 16,
          "default": 12
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_frames",
        "num_inference_steps",
        "aspect_ratio",
        "fps",
        "seed",
        "enable_prompt_expansion",
        "enable_safety_checker",
        "video_output_type",
        "video_quality",
        "video_write_mode",
        "sync_mode"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3/standard/text-to-video",
    "name": "MiniMax Hailuo 2.3 [Standard] (Text to Video)",
    "description": "MiniMax Hailuo-2.3 Text To Video API (Standard, 768p): Advanced text-to-video generation model with 768p resolution",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/elephant/j3hSIKLqmWT7NXmIwTUQ0_1ec8fc1d7a53473fac7c2892ff459693.jpg",
    "tags": [
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "StandardTextToVideoHailuo23Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "duration": {
          "enum": [
            "6",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the video in seconds.",
          "default": "6"
        },
        "prompt": {
          "examples": [
            "An intense electrical storm rages over a modern city skyline at night. Multiple lightning bolts strike simultaneously, illuminating the towering skyscrapers in brilliant white flashes. Thunder clouds roil and churn overhead while constant lightning creates a strobe effect. Rain pours in heavy sheets, visible in the glow of city lights. The camera captures the drama from across a river as lightning reflects in the water. Lightning branches across the sky in intricate patterns. Atmosphere: dramatic, powerful, electrifying urban storm."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000,
          "minLength": 1
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "prompt_optimizer",
        "duration"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-2.3/pro/text-to-video",
    "name": "MiniMax Hailuo 2.3 [Pro] (Text to Video)",
    "description": "MiniMax Hailuo-2.3 Text To Video API (Pro, 1080p): Advanced text-to-video generation model with 1080p resolution",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/x_n_LT1ApmpYZnZw8sdNq_0147471d0d7e4bbba8780820dee6a3da.jpg",
    "tags": [
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ProTextToVideoHailuo23Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "The camera follows the snowboarder as they carve down the mountain through deep powder, each turn sending up huge rooster tails of snow. They navigate between trees, floating through the powder with smooth, flowing movements. The rider launches off a natural jump, grabbing the board mid-air before landing softly in deep snow and continuing down. Powder sprays continuously as they link turns together. The atmosphere is exhilarating and free. Audio: Board cutting through snow, powder spraying, wind rushing, the rider's excited shouts, and the soft thuds of landing in deep snow."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000,
          "description": "Text prompt for video generation",
          "minLength": 1
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "prompt_optimizer"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 10,
    "pricing_unit": "units"
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/pro/fast/text-to-video",
    "name": "Bytedance",
    "description": "Text to Video endpoint for Seedance 1.0 Pro Fast, a next-generation video model designed to deliver maximum performance at minimal cost",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/vuOJvxcEA4z0fsRkw3r4Y_4930420a08f045c9ae3c401e3a6d20fc.jpg",
    "tags": [
      "bytedance",
      "fast",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "camera_fixed",
        "seed",
        "enable_safety_checker"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Inside a quiet dojo, a martial artist moves with precision and grace. The performance highlights the beauty and discipline inherent in the ancient practice. Each form unfolds clearly, a testament to dedication and skill."
          ],
          "description": "The text prompt used to generate the video",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p",
            "1080p"
          ],
          "description": "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
          "type": "string",
          "title": "Resolution",
          "default": "1080p"
        },
        "duration": {
          "enum": [
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
          ],
          "description": "Duration of the video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "camera_fixed": {
          "description": "Whether to fix the camera position",
          "type": "boolean",
          "title": "Camera Fixed",
          "default": false
        },
        "seed": {
          "description": "Random seed to control video generation. Use -1 for random.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "SeedanceProFastTextToVideoInput",
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/ltxv-2/text-to-video/fast",
    "name": "LTX Video 2.0 Fast",
    "description": "Create high-fidelity video with audio from text with LTX-2 Fast",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/monkey/1z0o3ma3f3JwQMO9xlnKR_79bee919aeb04b6d93428c650ee87a5e.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "duration",
        "resolution",
        "aspect_ratio",
        "fps",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cowboy walking through a dusty town at high noon, camera following from behind, cinematic depth, realistic lighting, western mood, 4K film grain."
          ],
          "maxLength": 5000,
          "minLength": 1,
          "title": "Prompt",
          "description": "The prompt to generate the video from",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "1080p"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the generated video",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "duration": {
          "enum": [
            6,
            8,
            10,
            12,
            14,
            16,
            18,
            20
          ],
          "description": "The duration of the generated video in seconds. The fast model supports 6-20 seconds. Note: Durations longer than 10 seconds (12, 14, 16, 18, 20) are only supported with 25 FPS and 1080p resolution.",
          "type": "integer",
          "title": "Duration",
          "default": 6
        },
        "fps": {
          "enum": [
            25,
            50
          ],
          "description": "The frames per second of the generated video",
          "type": "integer",
          "title": "Frames per Second",
          "default": 25
        }
      },
      "title": "LTXVTextToVideoFastRequest",
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 4,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/ltxv-2/text-to-video",
    "name": "LTX Video 2.0 Pro",
    "description": "Create high-fidelity video with audio from text with LTX-2 Pro.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/rabbit/ylyM62sWoJM8GAjBUmYOa_930f3f7413604a7fa1e641a25c9d7ff4.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "duration",
        "resolution",
        "aspect_ratio",
        "fps",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cowboy walking through a dusty town at high noon, camera following from behind, cinematic depth, realistic lighting, western mood, 4K film grain."
          ],
          "maxLength": 5000,
          "minLength": 1,
          "title": "Prompt",
          "description": "The prompt to generate the video from",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "1080p",
            "1440p",
            "2160p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "1080p"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the generated video",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "duration": {
          "enum": [
            6,
            8,
            10
          ],
          "description": "The duration of the generated video in seconds",
          "type": "integer",
          "title": "Duration",
          "default": 6
        },
        "fps": {
          "enum": [
            25,
            50
          ],
          "description": "The frames per second of the generated video",
          "type": "integer",
          "title": "Frames per Second",
          "default": 25
        }
      },
      "title": "LTXVTextToVideoRequest",
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 6,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/vidu/q2/text-to-video",
    "name": "Vidu",
    "description": "Use the latest Vidu Q2 models which much more better quality and control on your videos.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/ui3mJj8_Fmxg22mCDuesY_38c8acb860cf4072899ec0c062efcf9e.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Q2TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cinematic shot of a futuristic city at sunset, with flying cars and towering skyscrapers."
          ],
          "maxLength": 3000,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 3000 characters"
        },
        "duration": {
          "enum": [
            2,
            3,
            4,
            5,
            6,
            7,
            8
          ],
          "title": "Duration",
          "type": "integer",
          "description": "Duration of the video in seconds",
          "default": 4
        },
        "resolution": {
          "enum": [
            "360p",
            "520p",
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Output video resolution",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the output video",
          "default": "16:9"
        },
        "bgm": {
          "title": "Bgm",
          "type": "boolean",
          "description": "Whether to add background music to the video (only for 4-second videos)",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "duration",
        "resolution",
        "aspect_ratio",
        "movement_amplitude",
        "bgm"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 2,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/krea-wan-14b/text-to-video",
    "name": "Krea Wan 14b- Text to Video",
    "description": "Fast Text-to-Video endpoint for Krea's Wan 14b model.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/rabbit/n7SozOMd7d9UiTYhyZ4w3_99e21d49333f47b9be7e834d73a16d8a.jpg",
    "tags": [
      "text to video",
      "fast"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A powerful, matte black jeep, its robust frame contrasting with the lush green surroundings, navigates a winding jungle road, kicking up small clouds of dust and loose earth from its tires."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Prompt for the video-to-video generation."
        },
        "enable_prompt_expansion": {
          "examples": [
            true
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "num_frames": {
          "minimum": 18,
          "maximum": 162,
          "type": "integer",
          "title": "Num Frames",
          "description": "Number of frames to generate. Must be a multiple of 12 plus 6, for example 6, 18, 30, 42, etc.",
          "default": 78
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for the video-to-video generation."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_frames",
        "enable_prompt_expansion",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 3,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/wan-alpha",
    "name": "Wan Alpha",
    "description": "Generate videos with transparent backgrounds",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/3oIcvX_9oIQh2cDai8geS_59a419be75fb46c5bd8094bb50e9cabf.jpg",
    "tags": [
      "transparent",
      "alpha"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "num_frames",
        "fps",
        "num_inference_steps",
        "seed",
        "sampler",
        "shift",
        "resolution",
        "aspect_ratio",
        "enable_prompt_expansion",
        "enable_safety_checker",
        "mask_clamp_lower",
        "mask_clamp_upper",
        "binarize_mask",
        "mask_binarization_threshold",
        "video_output_type",
        "video_quality",
        "video_write_mode",
        "sync_mode"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Medium shot. A little girl holds a bubble wand and blows out colorful bubbles that float and pop in the air. The background of this video is transparent. Realistic style."
          ],
          "description": "The prompt to guide the video generation.",
          "type": "string",
          "title": "Prompt"
        },
        "shift": {
          "minimum": 1,
          "description": "The shift of the generated video.",
          "type": "number",
          "maximum": 15,
          "title": "Shift",
          "default": 10.5
        },
        "mask_clamp_upper": {
          "minimum": 0,
          "description": "The upper bound of the mask clamping.",
          "type": "number",
          "maximum": 1,
          "title": "Mask Clamp Upper",
          "default": 0.75
        },
        "fps": {
          "minimum": 1,
          "description": "The frame rate of the generated video.",
          "type": "integer",
          "maximum": 60,
          "title": "FPS",
          "default": 16
        },
        "mask_clamp_lower": {
          "minimum": 0,
          "description": "The lower bound of the mask clamping.",
          "type": "number",
          "maximum": 1,
          "title": "Mask Clamp Lower",
          "default": 0.1
        },
        "num_frames": {
          "description": "The number of frames to generate.",
          "type": "integer",
          "minimum": 17,
          "maximum": 121,
          "title": "Number of Frames",
          "default": 81
        },
        "enable_safety_checker": {
          "description": "Whether to enable safety checker.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "mask_binarization_threshold": {
          "minimum": 0,
          "description": "The threshold for mask binarization. When binarize_mask is True, this threshold will be used to binarize the mask. This will also be used for transparency when the output type is `.webm`.",
          "type": "number",
          "maximum": 1,
          "title": "Mask Binarization Threshold",
          "default": 0.8
        },
        "binarize_mask": {
          "description": "Whether to binarize the mask.",
          "type": "boolean",
          "title": "Binarize Mask",
          "default": false
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "description": "The write mode of the generated video.",
          "type": "string",
          "title": "Video Write Mode",
          "default": "balanced"
        },
        "resolution": {
          "enum": [
            "240p",
            "360p",
            "480p",
            "580p",
            "720p"
          ],
          "description": "The resolution of the generated video.",
          "type": "string",
          "title": "Resolution",
          "default": "480p"
        },
        "video_output_type": {
          "enum": [
            "X264 (.mp4)",
            "VP9 (.webm)",
            "PRORES4444 (.mov)",
            "GIF (.gif)"
          ],
          "description": "The output type of the generated video.",
          "type": "string",
          "title": "Video Output Type",
          "default": "VP9 (.webm)"
        },
        "sampler": {
          "enum": [
            "unipc",
            "dpm++",
            "euler"
          ],
          "description": "The sampler to use.",
          "type": "string",
          "title": "Sampler",
          "default": "euler"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "1:1",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "description": "The quality of the generated video.",
          "type": "string",
          "title": "Video Quality",
          "default": "high"
        },
        "sync_mode": {
          "description": "If `True`, the media will be returned as a data URI and the output data won't be available in the request history.",
          "type": "boolean",
          "title": "Sync Mode",
          "default": false
        },
        "enable_prompt_expansion": {
          "description": "Whether to enable prompt expansion.",
          "type": "boolean",
          "title": "Enable Prompt Expansion",
          "default": false
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "description": "The seed for the random number generator.",
          "title": "Seed"
        },
        "num_inference_steps": {
          "minimum": 2,
          "description": "The number of inference steps to use.",
          "type": "integer",
          "maximum": 16,
          "title": "Number of Inference Steps",
          "default": 8
        }
      },
      "title": "WanAlphaRequest",
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/kandinsky5/text-to-video/distill",
    "name": "Kandinsky5",
    "description": "Kandinsky 5.0 Distilled is a lightweight diffusion model for fast, high-quality text-to-video generation.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/TyHaKAdxHRg3VIjUlKZPI_674ee5ee1f2d467e9f3806531f85dee2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "KandinskyT2VDistillRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A dog in red hat"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "768x512"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).",
          "default": "768x512"
        },
        "aspect_ratio": {
          "enum": [
            "3:2",
            "1:1",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).",
          "default": "3:2"
        },
        "duration": {
          "enum": [
            "5s",
            "10s"
          ],
          "description": "The length of the video to generate (5s or 10s)",
          "type": "string",
          "examples": [
            "5s",
            "10s"
          ],
          "title": "Duration",
          "default": "5s"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "resolution",
        "aspect_ratio",
        "duration"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/kandinsky5/text-to-video",
    "name": "Kandinsky5",
    "description": "Kandinsky 5.0 is a diffusion model for fast, high-quality text-to-video  generation.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/F-LagExgsZASG2uyIcj6X_093dccc7417c47e593e245767017f251.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "KandinskyT2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A dog in red hat"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "768x512"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video in W:H format. Will be calculated based on the aspect ratio(768x512, 512x512, 512x768).",
          "default": "768x512"
        },
        "aspect_ratio": {
          "enum": [
            "3:2",
            "1:1",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. One of (3:2, 1:1, 2:3).",
          "default": "3:2"
        },
        "duration": {
          "enum": [
            "5s",
            "10s"
          ],
          "description": "The length of the video to generate (5s or 10s)",
          "type": "string",
          "examples": [
            "5s",
            "10s"
          ],
          "title": "Duration",
          "default": "5s"
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps.",
          "default": 30
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "resolution",
        "aspect_ratio",
        "duration",
        "num_inference_steps"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 2,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/veo3.1/fast",
    "name": "Veo 3.1 Fast",
    "description": "Faster and more cost effective version of Google's Veo 3.1! ",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/o5x4rjXr3fAEwQgr4Y5vp_69ee214c658e428ba2f8f8b054d70a0e.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "duration",
        "negative_prompt",
        "enhance_prompt",
        "seed",
        "auto_fix",
        "resolution",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A casual street interview on a busy New York City sidewalk in the afternoon. The interviewer holds a plain, unbranded microphone and asks: Have you seen Google's new Veo3 model It is a super good model. Person replies: Yeah I saw it, it's already available on fal. It's crazy good."
          ],
          "title": "Prompt",
          "minLength": 1,
          "type": "string",
          "description": "The text prompt describing the video you want to generate"
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "duration": {
          "enum": [
            "4s",
            "6s",
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 33% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9",
            "1:1"
          ],
          "description": "The aspect ratio of the generated video. If it is set to 1:1, the video will be outpainted.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "auto_fix": {
          "description": "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them",
          "type": "boolean",
          "title": "Auto Fix",
          "default": true
        },
        "seed": {
          "description": "A seed to use for the video generation",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "description": "A negative prompt to guide the video generation",
          "type": "string",
          "title": "Negative Prompt"
        },
        "enhance_prompt": {
          "description": "Whether to enhance the video generation",
          "type": "boolean",
          "title": "Enhance Prompt",
          "default": true
        }
      },
      "title": "TextToVideoPreviewFastInput",
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/veo3.1",
    "name": "Veo 3.1",
    "description": "Veo 3.1 by Google, the most advanced AI video generation model in the world. With sound on!",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/tiger/TGTZBJyLk9HdwjB6SB90e.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "duration",
        "negative_prompt",
        "enhance_prompt",
        "seed",
        "auto_fix",
        "resolution",
        "generate_audio"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Two person street interview in New York City.\nSample Dialogue:\nHost: \"Did you hear the news?\"\nPerson: \"Yes! Veo 3.1 is now available on fal. If you want to see it, go check their website.\""
          ],
          "description": "The text prompt describing the video you want to generate",
          "type": "string",
          "title": "Prompt"
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "duration": {
          "enum": [
            "4s",
            "6s",
            "8s"
          ],
          "description": "The duration of the generated video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "8s"
        },
        "generate_audio": {
          "description": "Whether to generate audio for the video. If false, 50% less credits will be used.",
          "type": "boolean",
          "title": "Generate Audio",
          "default": true
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9",
            "1:1"
          ],
          "description": "The aspect ratio of the generated video. If it is set to 1:1, the video will be outpainted.",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "auto_fix": {
          "description": "Whether to automatically attempt to fix prompts that fail content policy or other validation checks by rewriting them",
          "type": "boolean",
          "title": "Auto Fix",
          "default": true
        },
        "seed": {
          "description": "A seed to use for the video generation",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "description": "A negative prompt to guide the video generation",
          "type": "string",
          "title": "Negative Prompt"
        },
        "enhance_prompt": {
          "description": "Whether to enhance the video generation",
          "type": "boolean",
          "title": "Enhance Prompt",
          "default": true
        }
      },
      "title": "TextToVideo31Input",
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/sora-2/text-to-video/pro",
    "name": "Sora 2",
    "description": "Text-to-video endpoint for Sora 2 Pro, OpenAI's state-of-the-art video model capable of creating richly detailed, dynamic clips with audio from natural language or images.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/lion/0bXyMS_zSKpeaG3LM6ARv_d4ee6acbfd9a4168b012a848c33b154d.jpg",
    "tags": [
      "text-to-video",
      "audio",
      "sora-2-pro"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "resolution",
        "aspect_ratio",
        "duration",
        "delete_video"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A dramatic Hollywood breakup scene at dusk on a quiet suburban street. A man and a woman in their 30s face each other, speaking softly but emotionally, lips syncing to breakup dialogue. Cinematic lighting, warm sunset tones, shallow depth of field, gentle breeze moving autumn leaves, realistic natural sound, no background music"
          ],
          "maxLength": 5000,
          "minLength": 1,
          "title": "Prompt",
          "description": "The text prompt describing the video you want to generate",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "1080p"
        },
        "duration": {
          "enum": [
            4,
            8,
            12
          ],
          "description": "Duration of the generated video in seconds",
          "type": "integer",
          "title": "Duration",
          "default": 4
        },
        "delete_video": {
          "description": "Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.",
          "type": "boolean",
          "title": "Delete Video",
          "default": true
        }
      },
      "title": "ProTextToVideoInput",
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/sora-2/text-to-video",
    "name": "Sora 2",
    "description": "Text-to-video endpoint for Sora 2, OpenAI's state-of-the-art video model capable of creating richly detailed, dynamic clips with audio from natural language or images.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3.fal.media/files/penguin/eOGowiQKXIKwyDfwgeWQO_b80784431c524553a564ebdd7550d7e6.jpg",
    "tags": [
      "text to video",
      "audio",
      "sora"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "resolution",
        "aspect_ratio",
        "duration",
        "delete_video"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A dramatic Hollywood breakup scene at dusk on a quiet suburban street. A man and a woman in their 30s face each other, speaking softly but emotionally, lips syncing to breakup dialogue. Cinematic lighting, warm sunset tones, shallow depth of field, gentle breeze moving autumn leaves, realistic natural sound, no background music"
          ],
          "maxLength": 5000,
          "minLength": 1,
          "title": "Prompt",
          "description": "The text prompt describing the video you want to generate",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "720p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "duration": {
          "enum": [
            4,
            8,
            12
          ],
          "description": "Duration of the generated video in seconds",
          "type": "integer",
          "title": "Duration",
          "default": 4
        },
        "delete_video": {
          "description": "Whether to delete the video after generation for privacy reasons. If True, the video cannot be used for remixing and will be permanently deleted.",
          "type": "boolean",
          "title": "Delete Video",
          "default": true
        }
      },
      "title": "TextToVideoInput",
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/ovi",
    "name": "Ovi Text to Video",
    "description": "A unified paradigm for audio-video generation",
    "category": "text-to-video",
    "thumbnail_url": "https://v3.fal.media/files/lion/yU9aRgq2QMYK4eGH5mohA_2822a9b5892d46699e218791b207ae5c.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "OviT2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A close-up of someone's face as they pet a cat, their hands stroking the soft fur in the foreground. Their affectionate expression shows as the cat purrs contentedly in their lap. They say, <S>This little guy has been with me for eight years now. He knows exactly when I need comfort. Animals are pretty amazing that way.<E>.<AUDCAP>Affectionate voice with cat purring and gentle petting sounds<ENDAUDCAP>"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "512x992",
            "992x512",
            "960x512",
            "512x960",
            "720x720",
            "448x1120",
            "1120x448"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video in W:H format. One of (512x992, 992x512, 960x512, 512x960, 720x720, or 448x1120).",
          "default": "992x512"
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps.",
          "default": 30
        },
        "audio_negative_prompt": {
          "title": "Audio Negative Prompt",
          "type": "string",
          "description": "Negative prompt for audio generation.",
          "default": "robotic, muffled, echo, distorted"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": "jitter, bad hands, blur, distortion"
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_inference_steps",
        "audio_negative_prompt",
        "seed",
        "resolution"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/wan-25-preview/text-to-video",
    "name": "Wan 2.5 Text to Video",
    "description": "Wan 2.5 text-to-video model.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3.fal.media/files/koala/yojKCMBipiqJvLr9a3sLC_deec1d2b5b2c4019bc353f6060ec0c09.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The white dragon warrior stands still, eyes full of determination and strength. The camera slowly moves closer or circles around the warrior, highlighting the powerful presence and heroic spirit of the character."
          ],
          "title": "Prompt",
          "type": "string",
          "minLength": 1,
          "description": "The text prompt for video generation. Supports Chinese and English, max 800 characters."
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Video resolution tier",
          "default": "1080p"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "Duration of the generated video in seconds. Choose between 5 or 10 seconds.",
          "examples": [
            "5",
            "10"
          ],
          "default": "5"
        },
        "audio_url": {
          "title": "Audio Url",
          "type": "string",
          "description": "\nURL of the audio to use as the background music. Must be publicly accessible.\nLimit handling: If the audio duration exceeds the duration value (5 or 10 seconds),\nthe audio is truncated to the first 5 or 10 seconds, and the rest is discarded. If\nthe audio is shorter than the video, the remaining part of the video will be silent.\nFor example, if the audio is 3 seconds long and the video duration is 5 seconds, the\nfirst 3 seconds of the output video will have sound, and the last 2 seconds will be silent.\n- Format: WAV, MP3.\n- Duration: 3 to 30 s.\n- File size: Up to 15 MB.\n"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt rewriting using LLM. Improves results for short prompts but increases processing time.",
          "default": true
        },
        "negative_prompt": {
          "examples": [
            "low resolution, error, worst quality, low quality, defects"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt to describe content to avoid. Max 500 characters."
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        }
      },
      "description": "Input for text-to-video generation",
      "x-fal-order-properties": [
        "prompt",
        "audio_url",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "enable_prompt_expansion",
        "seed",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 5,
    "pricing_unit": "seconds"
  },
  {
    "id": "argil/avatars/text-to-video",
    "name": "Avatars Text to Video",
    "description": "High-quality avatar videos that feel real, generated from your text",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/zebra/9NGo8wnyQwuQTJQr4Cvht_27981df50e43459ea657ea36bee1b76b.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoRequest",
      "type": "object",
      "properties": {
        "text": {
          "examples": [
            "\nArgil is kinda crazy guys! You just turn a real person into \nan avatar that actually talks and moves and it's already reel-ready, \nfor TikTok, Shorts, whatever. No wasting hours editing, it still looks super pro.\n"
          ],
          "title": "Text",
          "type": "string"
        },
        "voice": {
          "enum": [
            "Rachel",
            "Clyde",
            "Roger",
            "Sarah",
            "Laura",
            "Thomas",
            "Charlie",
            "George",
            "Callum",
            "River",
            "Harry",
            "Liam",
            "Alice",
            "Matilda",
            "Will",
            "Jessica",
            "Lilly",
            "Bill",
            "Oxley",
            "Luna"
          ],
          "title": "Voice",
          "type": "string"
        },
        "remove_background": {
          "title": "Remove Background",
          "type": "boolean",
          "description": "Enabling the remove background feature will result in a 50% increase in the price.",
          "default": false
        },
        "avatar": {
          "enum": [
            "Mia outdoor (UGC)",
            "Lara (Masterclass)",
            "Ines (UGC)",
            "Maria (Masterclass)",
            "Emma (UGC)",
            "Sienna (Masterclass)",
            "Elena (UGC)",
            "Jasmine (Masterclass)",
            "Amara (Masterclass)",
            "Ryan podcast (UGC)",
            "Tyler (Masterclass)",
            "Jayse (Masterclass)",
            "Paul (Masterclass)",
            "Matteo (UGC)",
            "Daniel car (UGC)",
            "Dario (Masterclass)",
            "Viva (Masterclass)",
            "Chen (Masterclass)",
            "Alex (Masterclass)",
            "Vanessa (UGC)",
            "Laurent (UGC)",
            "Noemie car (UGC)",
            "Brandon (UGC)",
            "Byron (Masterclass)",
            "Calista (Masterclass)",
            "Milo (Masterclass)",
            "Fabien (Masterclass)",
            "Rose (UGC)"
          ],
          "title": "Avatar",
          "type": "string",
          "examples": [
            "Noemie car (UGC)"
          ]
        }
      },
      "x-fal-order-properties": [
        "avatar",
        "text",
        "voice",
        "remove_background"
      ],
      "required": [
        "avatar",
        "text",
        "voice"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/pixverse/v5/text-to-video",
    "name": "Pixverse",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v5",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/infinitalk/single-text",
    "name": "Infinitalk",
    "description": "Infinitalk model generates a talking avatar video from a text and audio file. The avatar lip-syncs to the provided audio with natural facial expressions.",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/tiger/no2x6NmiDH44hhb5uCRpF_7a1a914245a54424a4f70019bb757ea3.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "InfiniTalkSingleTextRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "An elderly man with a white beard and headphones records audio with a microphone. He appears engaged and expressive, suggesting a podcast or voiceover."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the video to generate. Must be either 480p or 720p.",
          "default": "480p"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular",
            "high"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "The acceleration level to use for generation.",
          "default": "regular"
        },
        "text_input": {
          "examples": [
            "Spend more time with people who make you feel alive, and less with things that drain your soul."
          ],
          "title": "Text Input",
          "type": "string",
          "description": "The text input to guide video generation."
        },
        "image_url": {
          "examples": [
            "https://v3.fal.media/files/panda/HuM21CXMf0q7OO2zbvwhV_c4533aada79a495b90e50e32dc9b83a8.png"
          ],
          "title": "Image URL",
          "type": "string",
          "description": "URL of the input image. If the input image does not match the chosen aspect ratio, it is resized and center cropped."
        },
        "voice": {
          "enum": [
            "Aria",
            "Roger",
            "Sarah",
            "Laura",
            "Charlie",
            "George",
            "Callum",
            "River",
            "Liam",
            "Charlotte",
            "Alice",
            "Matilda",
            "Will",
            "Jessica",
            "Eric",
            "Chris",
            "Brian",
            "Daniel",
            "Lily",
            "Bill"
          ],
          "title": "Voice",
          "type": "string",
          "examples": [
            "Bill"
          ],
          "description": "The voice to use for speech generation"
        },
        "num_frames": {
          "minimum": 41,
          "maximum": 721,
          "type": "integer",
          "title": "Number of Frames",
          "description": "Number of frames to generate. Must be between 41 to 721.",
          "default": 145
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen.",
          "default": 42
        }
      },
      "x-fal-order-properties": [
        "image_url",
        "text_input",
        "voice",
        "prompt",
        "num_frames",
        "resolution",
        "seed",
        "acceleration"
      ],
      "required": [
        "image_url",
        "text_input",
        "voice",
        "prompt"
      ]
    }
  },
  {
    "id": "moonvalley/marey/t2v",
    "name": "Marey Realism V1.5",
    "description": "Generate a video from a text prompt with Marey, a generative video model trained exclusively on fully licensed data.",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/zebra/XqLulT-Va4wv0SoknC72P_504081bd51c84280b787bc27906b490e.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MareyInputT2V",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Detailed Description: A small, white paper boat, with one corner engulfed in bright orange flames, drifts precariously across a dark puddle on wet asphalt. As raindrops fall, they create ever-expanding ripples on the water's surface, gently rocking the fragile vessel and causing the fiery reflection below to dance and shimmer. The flickering flame slowly consumes the paper, charring the edges black as the boat becomes waterlogged, beginning to sink in a poignant slow-motion battle between fire and water. Background: The background is softly blurred, suggesting an overcast day with out-of-focus foliage, enhancing the scene's intimate and melancholic mood. Middleground: Raindrops continuously strike the puddle's surface, creating concentric ripples that gently push the boat along its short, determined voyage. Foreground: The burning paper boat floats in sharp focus, its bright, flickering flame casting a warm, dramatic glow that reflects and distorts on the dark, wet surface of the asphalt."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate a video from"
        },
        "duration": {
          "enum": [
            "5s",
            "10s"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video.",
          "default": "5s"
        },
        "dimensions": {
          "enum": [
            "1920x1080",
            "1152x1152",
            "1536x1152",
            "1152x1536"
          ],
          "title": "Dimensions",
          "type": "string",
          "description": "The dimensions of the generated video in width x height format.",
          "default": "1920x1080"
        },
        "guidance_scale": {
          "anyOf": [
            {
              "type": "number"
            },
            {
              "type": "null"
            }
          ],
          "title": "Guidance Scale",
          "description": "Controls how strongly the generation is guided by the prompt (0-20). Higher values follow the prompt more closely."
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Seed for random number generation. Use -1 for random seed each run.",
          "default": -1
        },
        "negative_prompt": {
          "anyOf": [
            {
              "type": "string"
            },
            {
              "type": "null"
            }
          ],
          "title": "Negative Prompt",
          "description": "Negative prompt used to guide the model away from undesirable features.",
          "default": "<synthetic> <scene cut> low-poly, flat shader, bad rigging, stiff animation, uncanny eyes, low-quality textures, looping glitch, cheap effect, overbloom, bloom spam, default lighting, game asset, stiff face, ugly specular, AI artifacts"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "dimensions",
        "duration",
        "negative_prompt",
        "seed",
        "guidance_scale"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "5 seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/text-to-video/lora",
    "name": "Wan-2.2 Text-to-Video A14B with LoRAs",
    "description": "Wan-2.2 text-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. This endpoint supports LoRAs made for Wan 2.2.",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/lion/brSX2_cSumQ6aBMB-jTpi_ebd2e40e80d243e2a65f96daf3c961c7.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanLoRAT2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A close-up of a young woman smiling gently in the rain, raindrops glistening on her face and eyelashes. The video captures the delicate details of her expression and the water droplets, with soft light reflecting off her skin in the rainy atmosphere."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "shift": {
          "description": "Shift value for the video. Must be between 1.0 and 10.0.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            5
          ],
          "title": "Shift",
          "default": 5
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "examples": [
            "regular"
          ],
          "default": "regular"
        },
        "num_interpolated_frames": {
          "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
          "type": "integer",
          "minimum": 0,
          "maximum": 4,
          "examples": [
            1
          ],
          "title": "Number of Interpolated Frames",
          "default": 1
        },
        "reverse_video": {
          "title": "Reverse Video",
          "type": "boolean",
          "description": "If true, the video will be reversed.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "LoRA weights to be used in the inference.",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "frames_per_second": {
          "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
          "type": "integer",
          "minimum": 4,
          "maximum": 60,
          "title": "Frames per Second",
          "examples": [
            16
          ],
          "default": 16
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale (1st Stage)",
          "default": 3.5
        },
        "num_frames": {
          "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
          "type": "integer",
          "minimum": 17,
          "maximum": 161,
          "title": "Number of Frames",
          "examples": [
            81
          ],
          "default": 81
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
          "examples": [
            "balanced"
          ],
          "default": "balanced"
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p, 580p, or 720p).",
          "examples": [
            "720p"
          ],
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "examples": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "default": "16:9"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "guidance_scale_2": {
          "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            4
          ],
          "title": "Guidance Scale (2nd Stage)",
          "default": 4
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
          "examples": [
            "high"
          ],
          "default": "high"
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "interpolator_model": {
          "enum": [
            "none",
            "film",
            "rife"
          ],
          "title": "Interpolator Model",
          "type": "string",
          "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
          "examples": [
            "film"
          ],
          "default": "film"
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 40,
          "examples": [
            27
          ],
          "title": "Number of Inference Steps",
          "default": 27
        },
        "adjust_fps_for_interpolation": {
          "examples": [
            true
          ],
          "title": "Adjust FPS for Interpolation",
          "type": "boolean",
          "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_frames",
        "frames_per_second",
        "seed",
        "resolution",
        "aspect_ratio",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "guidance_scale",
        "guidance_scale_2",
        "shift",
        "interpolator_model",
        "num_interpolated_frames",
        "adjust_fps_for_interpolation",
        "video_quality",
        "video_write_mode",
        "loras",
        "reverse_video"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/wan/v2.2-5b/text-to-video/distill",
    "name": "Wan",
    "description": "Wan 2.2's 5B distill model produces up to 5 seconds of video 720p at 24FPS with fluid motion and powerful prompt understanding",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/kangaroo/40VOx0fdYnthcwT_S30u4_98d8b53ed1dd439db51e2ffa2d253427.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanDistillT2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A medium shot establishes a modern, minimalist office setting: clean lines, muted grey walls, and polished wood surfaces. The focus shifts to a close-up on a woman in sharp, navy blue business attire. Her crisp white blouse contrasts with the deep blue of her tailored suit jacket. The subtle texture of the fabric is visible\u2014a fine weave with a slight sheen. Her expression is serious, yet engaging, as she speaks to someone unseen just beyond the frame. Close-up on her eyes, showing the intensity of her gaze and the fine lines around them that hint at experience and focus. Her lips are slightly parted, as if mid-sentence. The light catches the subtle highlights in her auburn hair, meticulously styled. Note the slight catch of light on the silver band of her watch. High resolution 4k"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "shift": {
          "description": "Shift value for the video. Must be between 1.0 and 10.0.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            5
          ],
          "title": "Shift",
          "default": 5
        },
        "num_interpolated_frames": {
          "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
          "type": "integer",
          "minimum": 0,
          "maximum": 4,
          "examples": [
            0
          ],
          "title": "Number of Interpolated Frames",
          "default": 0
        },
        "frames_per_second": {
          "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
          "type": "integer",
          "minimum": 4,
          "maximum": 60,
          "title": "Frames per Second",
          "examples": [
            24
          ],
          "default": 24
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            1
          ],
          "title": "Guidance Scale (1st Stage)",
          "default": 1
        },
        "num_frames": {
          "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
          "type": "integer",
          "minimum": 17,
          "maximum": 161,
          "title": "Number of Frames",
          "examples": [
            81
          ],
          "default": 81
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
          "examples": [
            "balanced"
          ],
          "default": "balanced"
        },
        "resolution": {
          "enum": [
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (580p or 720p).",
          "examples": [
            "720p"
          ],
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "examples": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "default": "16:9"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
          "examples": [
            "high"
          ],
          "default": "high"
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "interpolator_model": {
          "enum": [
            "none",
            "film",
            "rife"
          ],
          "title": "Interpolator Model",
          "type": "string",
          "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
          "examples": [
            "film"
          ],
          "default": "film"
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 50,
          "examples": [
            40
          ],
          "title": "Number of Inference Steps",
          "default": 40
        },
        "adjust_fps_for_interpolation": {
          "examples": [
            true
          ],
          "title": "Adjust FPS for Interpolation",
          "type": "boolean",
          "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_frames",
        "frames_per_second",
        "seed",
        "resolution",
        "aspect_ratio",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "guidance_scale",
        "shift",
        "interpolator_model",
        "num_interpolated_frames",
        "adjust_fps_for_interpolation",
        "video_quality",
        "video_write_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 2,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/wan/v2.2-5b/text-to-video/fast-wan",
    "name": "Wan",
    "description": "Wan 2.2's 5B FastVideo model produces up to 5 seconds of video 720p at 24FPS with fluid motion and powerful prompt understanding",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/4c9sGLsb2lXhga0i89W2N_47ef03f9caa949ca901a2801a4d42e6a.jpg",
    "tags": [
      "text to video",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanSmallFastVideoT2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A medium shot establishes a modern, minimalist office setting: clean lines, muted grey walls, and polished wood surfaces. The focus shifts to a close-up on a woman in sharp, navy blue business attire. Her crisp white blouse contrasts with the deep blue of her tailored suit jacket. The subtle texture of the fabric is visible\u2014a fine weave with a slight sheen. Her expression is serious, yet engaging, as she speaks to someone unseen just beyond the frame. Close-up on her eyes, showing the intensity of her gaze and the fine lines around them that hint at experience and focus. Her lips are slightly parted, as if mid-sentence. The light catches the subtle highlights in her auburn hair, meticulously styled. Note the slight catch of light on the silver band of her watch. High resolution 4k"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "num_interpolated_frames": {
          "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
          "type": "integer",
          "minimum": 0,
          "maximum": 4,
          "examples": [
            0
          ],
          "title": "Number of Interpolated Frames",
          "default": 0
        },
        "frames_per_second": {
          "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
          "type": "integer",
          "minimum": 4,
          "maximum": 60,
          "title": "Frames per Second",
          "examples": [
            24
          ],
          "default": 24
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale",
          "default": 3.5
        },
        "num_frames": {
          "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
          "type": "integer",
          "minimum": 17,
          "maximum": 161,
          "title": "Number of Frames",
          "examples": [
            81
          ],
          "default": 81
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
          "examples": [
            "balanced"
          ],
          "default": "balanced"
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (580p or 720p).",
          "examples": [
            "720p"
          ],
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "examples": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "default": "16:9"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
          "examples": [
            "high"
          ],
          "default": "high"
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "interpolator_model": {
          "enum": [
            "none",
            "film",
            "rife"
          ],
          "title": "Interpolator Model",
          "type": "string",
          "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
          "examples": [
            "film"
          ],
          "default": "film"
        },
        "adjust_fps_for_interpolation": {
          "examples": [
            true
          ],
          "title": "Adjust FPS for Interpolation",
          "type": "boolean",
          "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_frames",
        "frames_per_second",
        "seed",
        "resolution",
        "aspect_ratio",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "guidance_scale",
        "interpolator_model",
        "num_interpolated_frames",
        "adjust_fps_for_interpolation",
        "video_quality",
        "video_write_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/text-to-video/turbo",
    "name": "Wan",
    "description": "Wan-2.2 turbo text-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. ",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-4.jpg",
    "tags": [
      "text to video",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanTurboT2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A medium shot establishes a modern, minimalist office setting: clean lines, muted grey walls, and polished wood surfaces. The focus shifts to a close-up on a woman in sharp, navy blue business attire. Her crisp white blouse contrasts with the deep blue of her tailored suit jacket. The subtle texture of the fabric is visible\u2014a fine weave with a slight sheen. Her expression is serious, yet engaging, as she speaks to someone unseen just beyond the frame. Close-up on her eyes, showing the intensity of her gaze and the fine lines around them that hint at experience and focus. Her lips are slightly parted, as if mid-sentence. The light catches the subtle highlights in her auburn hair, meticulously styled. Note the slight catch of light on the silver band of her watch. High resolution 4k"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p, 580p, or 720p).",
          "examples": [
            "720p"
          ],
          "default": "720p"
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "examples": [
            "regular"
          ],
          "default": "regular"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "examples": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "default": "16:9"
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
          "examples": [
            "balanced"
          ],
          "default": "balanced"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
          "examples": [
            "high"
          ],
          "default": "high"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "resolution",
        "aspect_ratio",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "video_quality",
        "video_write_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 2,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/wan/v2.2-5b/text-to-video",
    "name": "Wan v2.2 5B",
    "description": "Wan 2.2's 5B model produces up to 5 seconds of video 720p at 24FPS with fluid motion and powerful prompt understanding",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanSmallT2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A medium shot establishes a modern, minimalist office setting: clean lines, muted grey walls, and polished wood surfaces. The focus shifts to a close-up on a woman in sharp, navy blue business attire. Her crisp white blouse contrasts with the deep blue of her tailored suit jacket. The subtle texture of the fabric is visible\u2014a fine weave with a slight sheen. Her expression is serious, yet engaging, as she speaks to someone unseen just beyond the frame. Close-up on her eyes, showing the intensity of her gaze and the fine lines around them that hint at experience and focus. Her lips are slightly parted, as if mid-sentence. The light catches the subtle highlights in her auburn hair, meticulously styled. Note the slight catch of light on the silver band of her watch. High resolution 4k"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "shift": {
          "description": "Shift value for the video. Must be between 1.0 and 10.0.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            5
          ],
          "title": "Shift",
          "default": 5
        },
        "num_interpolated_frames": {
          "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
          "type": "integer",
          "minimum": 0,
          "maximum": 4,
          "examples": [
            0
          ],
          "title": "Number of Interpolated Frames",
          "default": 0
        },
        "frames_per_second": {
          "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
          "type": "integer",
          "minimum": 4,
          "maximum": 60,
          "title": "Frames per Second",
          "examples": [
            24
          ],
          "default": 24
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale",
          "default": 3.5
        },
        "num_frames": {
          "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
          "type": "integer",
          "minimum": 17,
          "maximum": 161,
          "title": "Number of Frames",
          "examples": [
            81
          ],
          "default": 81
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
          "examples": [
            "balanced"
          ],
          "default": "balanced"
        },
        "resolution": {
          "enum": [
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (580p or 720p).",
          "examples": [
            "720p"
          ],
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "examples": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "default": "16:9"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
          "examples": [
            "high"
          ],
          "default": "high"
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "interpolator_model": {
          "enum": [
            "none",
            "film",
            "rife"
          ],
          "title": "Interpolator Model",
          "type": "string",
          "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
          "examples": [
            "film"
          ],
          "default": "film"
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 50,
          "examples": [
            40
          ],
          "title": "Number of Inference Steps",
          "default": 40
        },
        "adjust_fps_for_interpolation": {
          "examples": [
            true
          ],
          "title": "Adjust FPS for Interpolation",
          "type": "boolean",
          "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_frames",
        "frames_per_second",
        "seed",
        "resolution",
        "aspect_ratio",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "guidance_scale",
        "shift",
        "interpolator_model",
        "num_interpolated_frames",
        "adjust_fps_for_interpolation",
        "video_quality",
        "video_write_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 3,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/wan/v2.2-a14b/text-to-video",
    "name": "Wan-2.2 Text-to-Video A14B",
    "description": "Wan-2.2 text-to-video is a video model that generates high-quality videos with high visual quality and motion diversity from text prompts. ",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-4.jpg",
    "tags": [
      "text to video",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanT2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A close-up of a young woman smiling gently in the rain, raindrops glistening on her face and eyelashes. The video captures the delicate details of her expression and the water droplets, with soft light reflecting off her skin in the rainy atmosphere."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "shift": {
          "description": "Shift value for the video. Must be between 1.0 and 10.0.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            5
          ],
          "title": "Shift",
          "default": 5
        },
        "acceleration": {
          "enum": [
            "none",
            "regular"
          ],
          "title": "Acceleration",
          "type": "string",
          "description": "Acceleration level to use. The more acceleration, the faster the generation, but with lower quality. The recommended value is 'regular'.",
          "examples": [
            "regular"
          ],
          "default": "regular"
        },
        "num_interpolated_frames": {
          "description": "Number of frames to interpolate between each pair of generated frames. Must be between 0 and 4.",
          "type": "integer",
          "minimum": 0,
          "maximum": 4,
          "examples": [
            1
          ],
          "title": "Number of Interpolated Frames",
          "default": 1
        },
        "frames_per_second": {
          "description": "Frames per second of the generated video. Must be between 4 to 60. When using interpolation and `adjust_fps_for_interpolation` is set to true (default true,) the final FPS will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If `adjust_fps_for_interpolation` is set to false, this value will be used as-is.",
          "type": "integer",
          "minimum": 4,
          "maximum": 60,
          "title": "Frames per Second",
          "examples": [
            16
          ],
          "default": 16
        },
        "guidance_scale": {
          "description": "Classifier-free guidance scale. Higher values give better adherence to the prompt but may decrease quality.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            3.5
          ],
          "title": "Guidance Scale (1st Stage)",
          "default": 3.5
        },
        "num_frames": {
          "description": "Number of frames to generate. Must be between 17 to 161 (inclusive).",
          "type": "integer",
          "minimum": 17,
          "maximum": 161,
          "title": "Number of Frames",
          "examples": [
            81
          ],
          "default": 81
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, input data will be checked for safety before processing.",
          "default": false
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": ""
        },
        "video_write_mode": {
          "enum": [
            "fast",
            "balanced",
            "small"
          ],
          "title": "Video Write Mode",
          "type": "string",
          "description": "The write mode of the output video. Faster write mode means faster results but larger file size, balanced write mode is a good compromise between speed and quality, and small write mode is the slowest but produces the smallest file size.",
          "examples": [
            "balanced"
          ],
          "default": "balanced"
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p, 580p, or 720p).",
          "examples": [
            "720p"
          ],
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "examples": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "default": "16:9"
        },
        "enable_output_safety_checker": {
          "examples": [
            false
          ],
          "title": "Enable Output Safety Checker",
          "type": "boolean",
          "description": "If set to true, output video will be checked for safety after generation.",
          "default": false
        },
        "guidance_scale_2": {
          "description": "Guidance scale for the second stage of the model. This is used to control the adherence to the prompt in the second stage of the model.",
          "type": "number",
          "minimum": 1,
          "maximum": 10,
          "examples": [
            4
          ],
          "title": "Guidance Scale (2nd Stage)",
          "default": 4
        },
        "video_quality": {
          "enum": [
            "low",
            "medium",
            "high",
            "maximum"
          ],
          "title": "Video Quality",
          "type": "string",
          "description": "The quality of the output video. Higher quality means better visual quality but larger file size.",
          "examples": [
            "high"
          ],
          "default": "high"
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion. This will use a large language model to expand the prompt with additional details while maintaining the original meaning.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "interpolator_model": {
          "enum": [
            "none",
            "film",
            "rife"
          ],
          "title": "Interpolator Model",
          "type": "string",
          "description": "The model to use for frame interpolation. If None, no interpolation is applied.",
          "examples": [
            "film"
          ],
          "default": "film"
        },
        "num_inference_steps": {
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "minimum": 2,
          "maximum": 40,
          "examples": [
            27
          ],
          "title": "Number of Inference Steps",
          "default": 27
        },
        "adjust_fps_for_interpolation": {
          "examples": [
            true
          ],
          "title": "Adjust FPS for Interpolation",
          "type": "boolean",
          "description": "If true, the number of frames per second will be multiplied by the number of interpolated frames plus one. For example, if the generated frames per second is 16 and the number of interpolated frames is 1, the final frames per second will be 32. If false, the passed frames per second will be used as-is.",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_frames",
        "frames_per_second",
        "seed",
        "resolution",
        "aspect_ratio",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_output_safety_checker",
        "enable_prompt_expansion",
        "acceleration",
        "guidance_scale",
        "guidance_scale_2",
        "shift",
        "interpolator_model",
        "num_interpolated_frames",
        "adjust_fps_for_interpolation",
        "video_quality",
        "video_write_mode"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 8,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/ltxv-13b-098-distilled",
    "name": "LTX-Video 13B 0.9.8 Distilled",
    "description": "Generate long videos from prompts using LTX Video-0.9.8 13B Distilled and custom LoRA",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "tags": [
      "video",
      "ltx-video",
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "description": "Distilled model input",
      "type": "object",
      "properties": {
        "second_pass_skip_initial_steps": {
          "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
          "type": "integer",
          "minimum": 1,
          "maximum": 11,
          "title": "Second Pass Skip Initial Steps",
          "examples": [
            5
          ],
          "default": 5
        },
        "first_pass_num_inference_steps": {
          "description": "Number of inference steps during the first pass.",
          "type": "integer",
          "minimum": 2,
          "maximum": 12,
          "title": "Number of Inference Steps",
          "examples": [
            8
          ],
          "default": 8
        },
        "frame_rate": {
          "description": "The frame rate of the video.",
          "type": "integer",
          "minimum": 1,
          "maximum": 60,
          "title": "Frame Rate",
          "examples": [
            24
          ],
          "default": 24
        },
        "reverse_video": {
          "examples": [
            false
          ],
          "title": "Reverse Video",
          "type": "boolean",
          "description": "Whether to reverse the video.",
          "default": false
        },
        "prompt": {
          "examples": [
            "A cinematic fast-tracking shot follows a vintage, teal camper van as it descends a winding mountain trail. The van, slightly weathered but well-maintained, is the central focus, its retro design emphasized by the motion blur. Medium shot reveals the dusty, ochre trail, edged with vibrant green pine trees. Close-up on the van's tires shows the gravel spraying, highlighting the speed and rugged terrain. Sunlight filters through the trees, casting dappled shadows on the van and the trail. The background is a hazy, majestic mountain range bathed in warm, golden light. The overall mood is adventurous and exhilarating. High resolution 4k movie scene."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide generation"
        },
        "expand_prompt": {
          "examples": [
            false
          ],
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using a language model.",
          "default": false
        },
        "temporal_adain_factor": {
          "description": "The factor for adaptive instance normalization (AdaIN) applied to generated video chunks after the first. This can help deal with a gradual increase in saturation/contrast in the generated video by normalizing the color distribution across the video. A high value will ensure the color distribution is more consistent across the video, while a low value will allow for more variation in color distribution.",
          "type": "number",
          "examples": [
            0.5
          ],
          "maximum": 1,
          "title": "Temporal AdaIN Factor",
          "minimum": 0,
          "multipleOf": 0.05,
          "default": 0.5
        },
        "loras": {
          "description": "LoRA weights to use for generation",
          "type": "array",
          "title": "Loras",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "num_frames": {
          "description": "The number of frames in the video.",
          "type": "integer",
          "minimum": 9,
          "maximum": 1441,
          "title": "Number of Frames",
          "examples": [
            121
          ],
          "default": 121
        },
        "second_pass_num_inference_steps": {
          "description": "Number of inference steps during the second pass.",
          "type": "integer",
          "minimum": 2,
          "maximum": 12,
          "title": "Second Pass Number of Inference Steps",
          "examples": [
            8
          ],
          "default": 8
        },
        "negative_prompt": {
          "description": "Negative prompt for generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
        },
        "enable_detail_pass": {
          "examples": [
            false
          ],
          "title": "Enable Detail Pass",
          "type": "boolean",
          "description": "Whether to use a detail pass. If True, the model will perform a second pass to refine the video and enhance details. This incurs a 2.0x cost multiplier on the base price.",
          "default": false
        },
        "resolution": {
          "examples": [
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video.",
          "enum": [
            "480p",
            "720p"
          ],
          "default": "720p"
        },
        "aspect_ratio": {
          "examples": [
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video.",
          "enum": [
            "9:16",
            "1:1",
            "16:9"
          ],
          "default": "16:9"
        },
        "tone_map_compression_ratio": {
          "description": "The compression ratio for tone mapping. This is used to compress the dynamic range of the video to improve visual quality. A value of 0.0 means no compression, while a value of 1.0 means maximum compression.",
          "type": "number",
          "examples": [
            0
          ],
          "maximum": 1,
          "title": "Tone Map Compression Ratio",
          "minimum": 0,
          "multipleOf": 0.05,
          "default": 0
        },
        "seed": {
          "description": "Random seed for generation",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "DistilledTextToVideoInput",
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "loras",
        "resolution",
        "aspect_ratio",
        "seed",
        "num_frames",
        "first_pass_num_inference_steps",
        "second_pass_num_inference_steps",
        "second_pass_skip_initial_steps",
        "frame_rate",
        "expand_prompt",
        "reverse_video",
        "enable_safety_checker",
        "enable_detail_pass",
        "temporal_adain_factor",
        "tone_map_compression_ratio"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/minimax/hailuo-02/pro/text-to-video",
    "name": "MiniMax Hailuo 02 [Pro] (Text to Video)",
    "description": "MiniMax Hailuo-02 Text To Video API (Pro, 1080p): Advanced video generation model with 1080p resolution",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "ProTextToVideoHailuo02Input",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "A Galactic Smuggler is a rogue figure with a cybernetic arm and a well-worn coat that hints at many dangerous escapades across the galaxy. Their ship is filled with rare and exotic treasures from distant planets, concealed in hidden compartments, showing their expertise in illicit trade. Their belt is adorned with energy-based weapons, ready to be drawn at any moment to protect themselves or escape from tight situations. This character thrives in the shadows of space, navigating between the law and chaos with stealth and wit, always seeking the next big score while evading bounty hunters and law enforcement. The rogue's ship, rugged yet efficient, serves as both a home and a tool for their dangerous lifestyle. The treasures they collect reflect the diverse and intriguing worlds they've encountered\u2014alien artifacts, rare minerals, and artifacts of unknown origin. Their reputation precedes them, with whispers of their dealings and the deadly encounters that often follow. A master of negotiation and deception, the Galactic Smuggler navigates the cosmos with an eye on the horizon, always one step ahead of those who pursue them."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000,
          "minLength": 1
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "prompt_optimizer"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 8,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/pro/text-to-video",
    "name": "Seedance 1.0 Pro",
    "description": "Seedance 1.0 Pro, a high quality video generation model developed by Bytedance.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "camera_fixed",
        "seed",
        "enable_safety_checker"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A bright blue race car speeds along a snowy racetrack. [Low-angle shot] Captures several cars speeding along the racetrack through a harsh snowstorm. [Overhead shot] The camera gradually pulls upward, revealing the full race scene illuminated by storm lights"
          ],
          "description": "The text prompt used to generate the video",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p",
            "1080p"
          ],
          "description": "Video resolution - 480p for faster generation, 720p for balance, 1080p for higher quality",
          "type": "string",
          "title": "Resolution",
          "default": "1080p"
        },
        "duration": {
          "enum": [
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
          ],
          "description": "Duration of the video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "camera_fixed": {
          "description": "Whether to fix the camera position",
          "type": "boolean",
          "title": "Camera Fixed",
          "default": false
        },
        "seed": {
          "description": "Random seed to control video generation. Use -1 for random.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "SeedanceProTextToVideoInput",
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/bytedance/seedance/v1/lite/text-to-video",
    "name": "Seedance 1.0 Lite",
    "description": "Seedance 1.0 Lite",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Sound-2.jpg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "camera_fixed",
        "seed",
        "enable_safety_checker"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A little dog is running in the sunshine. The camera follows the dog as it plays in a garden."
          ],
          "description": "The text prompt used to generate the video",
          "type": "string",
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "21:9",
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16",
            "9:21"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p",
            "1080p"
          ],
          "description": "Video resolution - 480p for faster generation, 720p for higher quality",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "duration": {
          "enum": [
            "2",
            "3",
            "4",
            "5",
            "6",
            "7",
            "8",
            "9",
            "10",
            "11",
            "12"
          ],
          "description": "Duration of the video in seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "description": "If set to true, the safety checker will be enabled.",
          "type": "boolean",
          "title": "Enable Safety Checker",
          "default": true
        },
        "camera_fixed": {
          "description": "Whether to fix the camera position",
          "type": "boolean",
          "title": "Camera Fixed",
          "default": false
        },
        "seed": {
          "description": "Random seed to control video generation. Use -1 for random.",
          "type": "integer",
          "title": "Seed"
        }
      },
      "title": "SeedanceTextToVideoInput",
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v2.1/master/text-to-video",
    "name": "Kling 2.1 Master",
    "description": "Kling 2.1 Master: The premium endpoint for Kling 2.1, designed for top-tier text-to-video generation with unparalleled motion fluidity, cinematic visuals, and exceptional prompt precision.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-5.jpeg",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoV21MasterRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Warm, earthy tones bathe the scene as the potter's hands, rough and calloused, coax a shapeless lump of clay into a vessel of elegant curves, the slow, deliberate movements highlighted by the subtle shifting light; the clay's cool, damp texture contrasts sharply with the warmth of the potter's touch, creating a captivating interplay between material and maker."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "duration",
        "aspect_ratio",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 28,
    "pricing_unit": "seconds"
  },
  {
    "id": "veed/avatars/text-to-video",
    "name": "Avatars",
    "description": "Generate high-quality videos with UGC-like avatars from text",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/veed_logo.webp",
    "tags": [
      "lipsync",
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Text2VideoInput",
      "type": "object",
      "properties": {
        "text": {
          "examples": [
            "\nEver wondered how to get that flawless glow? \nIntroducing our new skincare line, designed for real life. \nStep one: Cleanse with our gentle, nourishing formula. \nStep two: Apply our hydrating serum for that dewy look. \nStep three: Lock it in with our lightweight moisturizer. \nFeel the difference with every application. \nSee the glow? That's the magic of our skincare. \nUse code 'GLOW20' for an exclusive discount. \nJoin the skincare revolution today!\n"
          ],
          "title": "Text",
          "type": "string"
        },
        "avatar_id": {
          "enum": [
            "emily_vertical_primary",
            "emily_vertical_secondary",
            "marcus_vertical_primary",
            "marcus_vertical_secondary",
            "mira_vertical_primary",
            "mira_vertical_secondary",
            "jasmine_vertical_primary",
            "jasmine_vertical_secondary",
            "jasmine_vertical_walking",
            "aisha_vertical_walking",
            "elena_vertical_primary",
            "elena_vertical_secondary",
            "any_male_vertical_primary",
            "any_female_vertical_primary",
            "any_male_vertical_secondary",
            "any_female_vertical_secondary",
            "any_female_vertical_walking",
            "emily_primary",
            "emily_side",
            "marcus_primary",
            "marcus_side",
            "aisha_walking",
            "elena_primary",
            "elena_side",
            "any_male_primary",
            "any_female_primary",
            "any_male_side",
            "any_female_side"
          ],
          "description": "The avatar to use for the video",
          "type": "string",
          "title": "Avatar Id"
        }
      },
      "x-fal-order-properties": [
        "avatar_id",
        "text"
      ],
      "required": [
        "avatar_id",
        "text"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/ltx-video-13b-dev",
    "name": "LTX Video-0.9.7 13B",
    "description": "Generate videos from prompts using LTX Video-0.9.7 13B and custom LoRA",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "tags": [
      "video",
      "ltx-video",
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "loras",
        "resolution",
        "aspect_ratio",
        "seed",
        "num_frames",
        "first_pass_num_inference_steps",
        "first_pass_skip_final_steps",
        "second_pass_num_inference_steps",
        "second_pass_skip_initial_steps",
        "frame_rate",
        "expand_prompt",
        "reverse_video",
        "enable_safety_checker"
      ],
      "type": "object",
      "properties": {
        "second_pass_skip_initial_steps": {
          "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
          "type": "integer",
          "minimum": 1,
          "maximum": 50,
          "title": "Second Pass Skip Initial Steps",
          "examples": [
            17
          ],
          "default": 17
        },
        "first_pass_num_inference_steps": {
          "description": "Number of inference steps during the first pass.",
          "type": "integer",
          "minimum": 2,
          "maximum": 50,
          "title": "First Pass Num Inference Steps",
          "examples": [
            30
          ],
          "default": 30
        },
        "frame_rate": {
          "description": "The frame rate of the video.",
          "type": "integer",
          "minimum": 1,
          "maximum": 60,
          "title": "Frame Rate",
          "examples": [
            30
          ],
          "default": 30
        },
        "prompt": {
          "examples": [
            "A cinematic fast-tracking shot follows a vintage, teal camper van as it descends a winding mountain trail. The van, slightly weathered but well-maintained, is the central focus, its retro design emphasized by the motion blur. Medium shot reveals the dusty, ochre trail, edged with vibrant green pine trees. Close-up on the van's tires shows the gravel spraying, highlighting the speed and rugged terrain. Sunlight filters through the trees, casting dappled shadows on the van and the trail. The background is a hazy, majestic mountain range bathed in warm, golden light. The overall mood is adventurous and exhilarating. High resolution 4k movie scene."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide generation"
        },
        "reverse_video": {
          "examples": [
            false
          ],
          "title": "Reverse Video",
          "type": "boolean",
          "description": "Whether to reverse the video.",
          "default": false
        },
        "expand_prompt": {
          "examples": [
            false
          ],
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using a language model.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "LoRA weights to use for generation",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "second_pass_num_inference_steps": {
          "description": "Number of inference steps during the second pass.",
          "type": "integer",
          "minimum": 2,
          "maximum": 50,
          "title": "Second Pass Num Inference Steps",
          "examples": [
            30
          ],
          "default": 30
        },
        "num_frames": {
          "description": "The number of frames in the video.",
          "type": "integer",
          "minimum": 9,
          "maximum": 161,
          "title": "Num Frames",
          "examples": [
            121
          ],
          "default": 121
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for generation",
          "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "examples": [
            "720p"
          ],
          "description": "Resolution of the generated video (480p or 720p).",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "1:1",
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "examples": [
            "16:9"
          ],
          "description": "Aspect ratio of the generated video (16:9, 1:1 or 9:16).",
          "default": "16:9"
        },
        "first_pass_skip_final_steps": {
          "minimum": 0,
          "maximum": 50,
          "type": "integer",
          "title": "First Pass Skip Final Steps",
          "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
          "default": 3
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        }
      },
      "title": "TextToVideoInput",
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/ltx-video-13b-distilled",
    "name": "LTX Video-0.9.7 13B Distilled",
    "description": "Generate videos from prompts using LTX Video-0.9.7 13B Distilled and custom LoRA",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "tags": [
      "video",
      "ltx-video",
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "DistilledTextToVideoInput",
      "type": "object",
      "properties": {
        "second_pass_skip_initial_steps": {
          "description": "The number of inference steps to skip in the initial steps of the second pass. By skipping some steps at the beginning, the second pass can focus on smaller details instead of larger changes.",
          "type": "integer",
          "minimum": 1,
          "title": "Second Pass Skip Initial Steps",
          "examples": [
            5
          ],
          "maximum": 20,
          "default": 5
        },
        "first_pass_num_inference_steps": {
          "description": "Number of inference steps during the first pass.",
          "type": "integer",
          "minimum": 2,
          "title": "First Pass Num Inference Steps",
          "examples": [
            8
          ],
          "maximum": 20,
          "default": 8
        },
        "frame_rate": {
          "description": "The frame rate of the video.",
          "type": "integer",
          "minimum": 1,
          "title": "Frame Rate",
          "examples": [
            30
          ],
          "maximum": 60,
          "default": 30
        },
        "reverse_video": {
          "examples": [
            false
          ],
          "title": "Reverse Video",
          "type": "boolean",
          "description": "Whether to reverse the video.",
          "default": false
        },
        "prompt": {
          "examples": [
            "A cinematic fast-tracking shot follows a vintage, teal camper van as it descends a winding mountain trail. The van, slightly weathered but well-maintained, is the central focus, its retro design emphasized by the motion blur. Medium shot reveals the dusty, ochre trail, edged with vibrant green pine trees. Close-up on the van's tires shows the gravel spraying, highlighting the speed and rugged terrain. Sunlight filters through the trees, casting dappled shadows on the van and the trail. The background is a hazy, majestic mountain range bathed in warm, golden light. The overall mood is adventurous and exhilarating. High resolution 4k movie scene."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide generation"
        },
        "expand_prompt": {
          "examples": [
            false
          ],
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using a language model.",
          "default": false
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "LoRA weights to use for generation",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "num_frames": {
          "description": "The number of frames in the video.",
          "type": "integer",
          "minimum": 9,
          "title": "Num Frames",
          "examples": [
            121
          ],
          "maximum": 161,
          "default": 121
        },
        "second_pass_num_inference_steps": {
          "description": "Number of inference steps during the second pass.",
          "type": "integer",
          "minimum": 2,
          "title": "Second Pass Num Inference Steps",
          "examples": [
            8
          ],
          "maximum": 20,
          "default": 8
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for generation",
          "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "examples": [
            "720p"
          ],
          "description": "Resolution of the generated video (480p or 720p).",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "1:1",
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "examples": [
            "16:9"
          ],
          "description": "Aspect ratio of the generated video (16:9, 1:1 or 9:16).",
          "default": "16:9"
        },
        "first_pass_skip_final_steps": {
          "minimum": 0,
          "title": "First Pass Skip Final Steps",
          "type": "integer",
          "maximum": 20,
          "description": "Number of inference steps to skip in the final steps of the first pass. By skipping some steps at the end, the first pass can focus on larger changes instead of smaller details.",
          "default": 1
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "loras",
        "resolution",
        "aspect_ratio",
        "seed",
        "num_frames",
        "first_pass_num_inference_steps",
        "first_pass_skip_final_steps",
        "second_pass_num_inference_steps",
        "second_pass_skip_initial_steps",
        "frame_rate",
        "expand_prompt",
        "reverse_video",
        "enable_safety_checker"
      ],
      "description": "Distilled model input",
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/ltx-video-lora",
    "name": "LTX Video-0.9.7 LoRA",
    "description": "Deprecated.\nUse fal-ai/ltx-video-13b-dev or fal-ai/ltx-video-13b-distilled instead.\n",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-4.jpg",
    "tags": [
      "video",
      "ltx-video",
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoInput",
      "type": "object",
      "properties": {
        "number_of_steps": {
          "description": "The number of inference steps to use.",
          "type": "integer",
          "minimum": 1,
          "title": "Number Of Steps",
          "examples": [
            30
          ],
          "maximum": 50,
          "default": 30
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "examples": [
            "720p"
          ],
          "description": "The resolution of the video.",
          "default": "720p"
        },
        "reverse_video": {
          "examples": [
            false
          ],
          "title": "Reverse Video",
          "type": "boolean",
          "description": "Whether to reverse the video.",
          "default": false
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "1:1",
            "9:16"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "examples": [
            "16:9"
          ],
          "description": "The aspect ratio of the video.",
          "default": "16:9"
        },
        "frame_rate": {
          "description": "The frame rate of the video.",
          "type": "integer",
          "minimum": 1,
          "title": "Frame Rate",
          "examples": [
            25
          ],
          "maximum": 60,
          "default": 25
        },
        "expand_prompt": {
          "examples": [
            false
          ],
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using the LLM.",
          "default": false
        },
        "number_of_frames": {
          "description": "The number of frames in the video.",
          "type": "integer",
          "minimum": 9,
          "title": "Number Of Frames",
          "examples": [
            89
          ],
          "maximum": 161,
          "default": 89
        },
        "prompt": {
          "examples": [
            "A close-up reveals a fluffy ginger tabby cat, its fur a vibrant mix of orange, cream, and black, walking delicately along a sun-drenched sidewalk. Medium shot shows the cat's paws stepping lightly on the warm grey concrete, each pad a soft, almost imperceptible pink. The sidewalk's texture is rough, with small pebbles embedded in the cement. A slight shadow stretches from the cat, indicating a high sun angle. The surrounding environment blurs subtly, suggesting a quiet residential street with hints of green foliage in the background. The overall mood is peaceful and serene, bathed in the warm glow of late afternoon sun. The cat's amber eyes gleam with curiosity. High resolution 4k"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "loras": {
          "title": "Loras",
          "type": "array",
          "description": "The LoRA weights to use for generation.",
          "items": {
            "$ref": "#/components/schemas/LoRAWeight"
          },
          "default": []
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for generation."
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use.",
          "default": "blurry, low quality, low resolution, inconsistent motion, jittery, distorted"
        }
      },
      "description": "Request model for text-to-video generation.",
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "loras",
        "resolution",
        "aspect_ratio",
        "number_of_frames",
        "number_of_steps",
        "frame_rate",
        "seed",
        "expand_prompt",
        "reverse_video",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/pixverse/v4.5/text-to-video/fast",
    "name": "Pixverse",
    "description": "Generate high quality and fast video clips from text and image prompts using PixVerse v4.5 fast",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastTextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "negative_prompt",
        "style",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 2,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/pixverse/v4.5/text-to-video",
    "name": "Pixverse",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v4.5",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/vidu/q1/text-to-video",
    "name": "Vidu Text to Video",
    "description": "Vidu Q1 Text to Video generates high-quality 1080p videos with exceptional visual quality and motion diversity",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Upscale-1.jpeg",
    "tags": [
      "stylized",
      "transform"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Q1TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "In an ultra-realistic fashion photography style featuring light blue and pale amber tones, an astronaut in a spacesuit walks through the fog. The background consists of enchanting white and golden lights, creating a minimalist still life and an impressive panoramic scene."
          ],
          "maxLength": 1500,
          "type": "string",
          "title": "Prompt",
          "description": "Text prompt for video generation, max 1500 characters"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the output video",
          "default": "16:9"
        },
        "style": {
          "enum": [
            "general",
            "anime"
          ],
          "title": "Style",
          "type": "string",
          "description": "The style of output video",
          "default": "general"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Seed for the random number generator"
        },
        "movement_amplitude": {
          "enum": [
            "auto",
            "small",
            "medium",
            "large"
          ],
          "title": "Movement Amplitude",
          "type": "string",
          "description": "The movement amplitude of objects in the frame",
          "default": "auto"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "style",
        "seed",
        "aspect_ratio",
        "movement_amplitude"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/ltx-video-v097",
    "name": "LTX Video-0.9.7",
    "description": "Deprecated.\nUse fal-ai/ltx-video-13b-dev or fal-ai/ltx-video-13b-distilled instead.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/Training-3.jpg",
    "tags": [
      "video",
      "text-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cute cat walking on a sidewalk"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide generation"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p or 720p).",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "default": "16:9"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using the model's own capabilities.",
          "default": true
        },
        "num_inference_steps": {
          "minimum": 2,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "Number of inference steps",
          "default": 40
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for generation",
          "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "resolution",
        "aspect_ratio",
        "seed",
        "num_inference_steps",
        "expand_prompt"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/magi",
    "name": "MAGI-1",
    "description": "MAGI-1 is a video generation model with exceptional understanding of physical interactions and cinematic prompts",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "tags": [
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MagiTextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Close-up shot: the old sea captain stares intently, pipe in mouth, wisps of smoke curling around his weathered face. The camera begins a slow clockwise orbit, pulling back. Finally, the camera rises high above, revealing the entire wooden sailing ship cutting through the waves, the captain unmoved, gazing toward the distant horizon."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "enum": [
            4,
            8,
            16,
            32,
            64
          ],
          "title": "Num Inference Steps",
          "type": "integer",
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "default": 16
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "num_frames": {
          "minimum": 96,
          "title": "Num Frames",
          "type": "integer",
          "maximum": 192,
          "description": "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
          "default": 96
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_frames",
        "seed",
        "resolution",
        "num_inference_steps",
        "enable_safety_checker",
        "aspect_ratio"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/magi-distilled",
    "name": "MAGI-1 (Distilled)",
    "description": "MAGI-1 distilled is a faster video generation model with exceptional understanding of physical interactions and cinematic prompts",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/fal/for%20videos-1.jpg",
    "tags": [
      "text-to-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MagiTextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Close-up shot: the old sea captain stares intently, pipe in mouth, wisps of smoke curling around his weathered face. The camera begins a slow clockwise orbit, pulling back. Finally, the camera rises high above, revealing the entire wooden sailing ship cutting through the waves, the captain unmoved, gazing toward the distant horizon."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p or 720p). 480p is 0.5 billing units, and 720p is 1 billing unit.",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "auto",
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video. If 'auto', the aspect ratio will be determined automatically based on the input image.",
          "default": "auto"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": true
        },
        "num_inference_steps": {
          "enum": [
            4,
            8,
            16,
            32
          ],
          "title": "Num Inference Steps",
          "type": "integer",
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "default": 16
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "num_frames": {
          "minimum": 96,
          "title": "Num Frames",
          "type": "integer",
          "maximum": 192,
          "description": "Number of frames to generate. Must be between 96 and 192 (inclusive). Each additional 24 frames beyond 96 incurs an additional billing unit.",
          "default": 96
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_frames",
        "seed",
        "resolution",
        "num_inference_steps",
        "enable_safety_checker",
        "aspect_ratio"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/pixverse/v4/text-to-video",
    "name": "PixVerse v4: Text to Video",
    "description": "Generate high quality video clips from text and image prompts using PixVerse v4",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/pixverse/v4/text-to-video/fast",
    "name": "PixVerse v4: Text to Video Fast",
    "description": "Generate high quality and fast video clips from text and image prompts using PixVerse v4 fast",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastTextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "negative_prompt",
        "style",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 2,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/kling-video/lipsync/audio-to-video",
    "name": "Kling LipSync Audio-to-Video",
    "description": "Kling LipSync is an audio-to-video model that generates realistic lip movements from audio input.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/elephant/njNipNC0TkA9fJguiS1NB_c75b090e2ebb4d9581d21d66cfc4a0d3.jpg",
    "tags": [
      "audio to video",
      "lipsync"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LipsyncA2VRequest",
      "type": "object",
      "properties": {
        "video_url": {
          "examples": [
            "https://fal.media/files/koala/8teUPbRRMtAUTORDvqy0l.mp4"
          ],
          "description": "The URL of the video to generate the lip sync for. Supports .mp4/.mov, \u2264100MB, 2\u201310s, 720p/1080p only, width/height 720\u20131920px.",
          "type": "string",
          "title": "Video Url"
        },
        "audio_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/kling/kling-audio.mp3"
          ],
          "description": "The URL of the audio to generate the lip sync for. Minimum duration is 2s and maximum duration is 60s. Maximum file size is 5MB.",
          "type": "string",
          "title": "Audio Url"
        }
      },
      "x-fal-order-properties": [
        "video_url",
        "audio_url"
      ],
      "required": [
        "video_url",
        "audio_url"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/lipsync/text-to-video",
    "name": "Kling LipSync Text-to-Video",
    "description": "Kling LipSync is a text-to-video model that generates realistic lip movements from text input.",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/GoSnDOnX0Tea08N7iI7oM.jpeg",
    "tags": [
      "text to video",
      "lipsync"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "LipsyncT2VRequest",
      "type": "object",
      "properties": {
        "text": {
          "examples": [
            "Mental health is as important as physical health, shaping our emotions, thoughts, and daily interactions."
          ],
          "maxLength": 120,
          "type": "string",
          "title": "Text",
          "description": "Text content for lip-sync video generation. Max 120 characters."
        },
        "video_url": {
          "examples": [
            "https://fal.media/files/koala/8teUPbRRMtAUTORDvqy0l.mp4"
          ],
          "description": "The URL of the video to generate the lip sync for. Supports .mp4/.mov, \u2264100MB, 2-60s, 720p/1080p only, width/height 720\u20131920px. If validation fails, an error is returned.",
          "type": "string",
          "title": "Video Url"
        },
        "voice_id": {
          "enum": [
            "genshin_vindi2",
            "zhinen_xuesheng",
            "AOT",
            "ai_shatang",
            "genshin_klee2",
            "genshin_kirara",
            "ai_kaiya",
            "oversea_male1",
            "ai_chenjiahao_712",
            "girlfriend_4_speech02",
            "chat1_female_new-3",
            "chat_0407_5-1",
            "cartoon-boy-07",
            "uk_boy1",
            "cartoon-girl-01",
            "PeppaPig_platform",
            "ai_huangzhong_712",
            "ai_huangyaoshi_712",
            "ai_laoguowang_712",
            "chengshu_jiejie",
            "you_pingjing",
            "calm_story1",
            "uk_man2",
            "laopopo_speech02",
            "heainainai_speech02",
            "reader_en_m-v1",
            "commercial_lady_en_f-v1",
            "tiyuxi_xuedi",
            "tiexin_nanyou",
            "girlfriend_1_speech02",
            "girlfriend_2_speech02",
            "zhuxi_speech02",
            "uk_oldman3",
            "dongbeilaotie_speech02",
            "chongqingxiaohuo_speech02",
            "chuanmeizi_speech02",
            "chaoshandashu_speech02",
            "ai_taiwan_man2_speech02",
            "xianzhanggui_speech02",
            "tianjinjiejie_speech02",
            "diyinnansang_DB_CN_M_04-v2",
            "yizhipiannan-v1",
            "guanxiaofang-v2",
            "tianmeixuemei-v1",
            "daopianyansang-v1",
            "mengwa-v1"
          ],
          "description": "Voice ID to use for speech synthesis",
          "type": "string",
          "title": "Voice Id",
          "examples": [
            "genshin_klee2"
          ]
        },
        "voice_language": {
          "enum": [
            "zh",
            "en"
          ],
          "title": "Voice Language",
          "type": "string",
          "description": "The voice language corresponding to the Voice ID",
          "default": "en"
        },
        "voice_speed": {
          "minimum": 0.8,
          "description": "Speech rate for Text to Video generation",
          "type": "number",
          "title": "Voice Speed",
          "maximum": 2,
          "default": 1
        }
      },
      "x-fal-order-properties": [
        "video_url",
        "text",
        "voice_id",
        "voice_language",
        "voice_speed"
      ],
      "required": [
        "video_url",
        "text",
        "voice_id"
      ]
    },
    "credits": 1,
    "pricing_unit": "units"
  },
  {
    "id": "fal-ai/wan-t2v-lora",
    "name": "Wan-2.1 Text-to-Video with LoRAs",
    "description": "Add custom LoRAs to Wan-2.1 is a text-to-video model that generates high-quality videos with high visual quality and motion diversity from images",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/wan-i2v-lora.webp",
    "tags": [
      "\"text to video\"",
      "\"motion\"",
      "\"lora\""
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_frames",
        "frames_per_second",
        "seed",
        "resolution",
        "aspect_ratio",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_prompt_expansion",
        "turbo_mode",
        "loras",
        "reverse_video"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "description": "The text prompt to guide video generation.",
          "type": "string",
          "title": "Prompt"
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p,580p, or 720p).",
          "default": "480p"
        },
        "reverse_video": {
          "title": "Reverse Video",
          "type": "boolean",
          "description": "If true, the video will be reversed.",
          "default": false
        },
        "seed": {
          "description": "Random seed for reproducibility. If None, a random seed is chosen.",
          "type": "integer",
          "title": "Seed"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "loras": {
          "description": "LoRA weights to be used in the inference.",
          "type": "array",
          "title": "Loras",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "default": []
        },
        "frames_per_second": {
          "minimum": 5,
          "description": "Frames per second of the generated video. Must be between 5 to 24.",
          "type": "integer",
          "maximum": 24,
          "title": "Frames Per Second",
          "default": 16
        },
        "turbo_mode": {
          "description": "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
          "type": "boolean",
          "title": "Turbo Mode",
          "default": true
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 2,
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "type": "integer",
          "maximum": 40,
          "title": "Num Inference Steps",
          "default": 30
        },
        "num_frames": {
          "minimum": 81,
          "description": "Number of frames to generate. Must be between 81 to 100 (inclusive).",
          "type": "integer",
          "maximum": 100,
          "title": "Num Frames",
          "default": 81
        },
        "negative_prompt": {
          "examples": [
            "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for video generation.",
          "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        },
        "enable_prompt_expansion": {
          "examples": [
            true
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        }
      },
      "title": "WanLoRARequest",
      "required": [
        "prompt"
      ]
    },
    "credits": 15,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2-flash",
    "name": "Luma Ray 2 Flash",
    "description": "Ray2 Flash is a fast video generative model capable of creating realistic visuals with natural, coherent motion.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Ray2TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A herd of wild horses galloping across a dusty desert plain under a blazing midday sun, their manes flying in the wind; filmed in a wide tracking shot with dynamic motion, warm natural lighting, and an epic."
          ],
          "maxLength": 5000,
          "type": "string",
          "minLength": 3,
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "21:9",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "540p",
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
          "default": "540p"
        },
        "loop": {
          "title": "Loop",
          "type": "boolean",
          "description": "Whether the video should loop (end of video is blended with the beginning)",
          "default": false
        },
        "duration": {
          "enum": [
            "5s",
            "9s"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video (9s costs 2x more)",
          "default": "5s"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "loop",
        "resolution",
        "duration"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/pika/v2.2/text-to-video",
    "name": "Pika Text to Video (v2.2)",
    "description": "Pika 2.2 is an advanced text-to-video generation model that transforms written prompts into high-quality, dynamic video clips. It supports realistic motion, smooth camera transitions, and detailed scene composition, allowing creators to generate cinematic visuals directly from text. Version 2.2 introduces improved temporal consistency, enhanced lighting and texture rendering, and faster generation speeds",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/panda/d7bGY17P07W2dKiNoWXfQ_fb8e23d259a44c5a893f04ae7a710b95.jpg",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "negative_prompt",
        "aspect_ratio",
        "resolution",
        "duration"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A lone astronaut walks across a cracked lunar surface. [Low-angle shot] Footprints trail behind in the silver dust. [Wide shot] The camera drifts upward to reveal Earth glowing on the horizon."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "duration": {
          "enum": [
            5,
            10
          ],
          "title": "Duration",
          "type": "integer",
          "description": "The duration of the generated video in seconds",
          "default": 5
        },
        "resolution": {
          "enum": [
            "1080p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "examples": [
            "1080p",
            "720p"
          ],
          "description": "The resolution of the generated video",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1",
            "4:5",
            "5:4",
            "3:2",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "A negative prompt to guide the model",
          "default": "ugly, bad, terrible"
        }
      },
      "title": "Pika22TextToVideoRequest",
      "description": "Request model for Pika 2.2 text-to-video generation",
      "required": [
        "prompt"
      ]
    },
    "credits": 4,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/pika/v2.1/text-to-video",
    "name": "Pika Text to Video (v2.1)",
    "description": "Pika v2.1 creates videos from a text prompt with high quality output.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/penguin/CUxIh-EAd_N4npYGWlEqA_d08d3d9739e947e9814d7d2f2a1c998d.jpg",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "negative_prompt",
        "aspect_ratio",
        "resolution",
        "duration"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A young woman in a pale blue corset and denim, her vibrant blue bob framed against a dusky desert landscape, walks slowly, her gaze unwavering and enigmatic as the camera remains fixed on her deliberate pace.  The warm glow of a stucco house contrasts with the cool desert air, hinting at both refuge and isolation, while a blurred figure retreating inside adds a layer of unspoken narrative to her solitary journey."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "duration": {
          "title": "Duration",
          "type": "integer",
          "description": "The duration of the generated video in seconds",
          "default": 5
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated video",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1",
            "4:5",
            "5:4",
            "3:2",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "A negative prompt to guide the model",
          "default": ""
        }
      },
      "title": "TextToVideoRequest",
      "description": "Base request for text-to-video generation",
      "required": [
        "prompt"
      ]
    },
    "credits": 8,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/pika/v2/turbo/text-to-video",
    "name": "Pika Text to Video Turbo (v2)",
    "description": "Pika v2 Turbo creates videos from a text prompt with high quality output.",
    "category": "text-to-video",
    "thumbnail_url": "https://v3b.fal.media/files/b/kangaroo/D6kbQkNiBrPL9m05gdWnE_48bca5e513bd42a6b777dfb9b08e0ca9.jpg",
    "tags": [
      "editing",
      "effects",
      "animation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "negative_prompt",
        "aspect_ratio",
        "resolution",
        "duration"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A young woman in a pale blue corset and denim, her vibrant blue bob framed against a dusky desert landscape, walks slowly, her gaze unwavering and enigmatic as the camera remains fixed on her deliberate pace.  The warm glow of a stucco house contrasts with the cool desert air, hinting at both refuge and isolation, while a blurred figure retreating inside adds a layer of unspoken narrative to her solitary journey."
          ],
          "title": "Prompt",
          "type": "string"
        },
        "duration": {
          "title": "Duration",
          "type": "integer",
          "description": "The duration of the generated video in seconds",
          "default": 5
        },
        "resolution": {
          "enum": [
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated video",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1",
            "4:5",
            "5:4",
            "3:2",
            "2:3"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed for the random number generator"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "A negative prompt to guide the model",
          "default": ""
        }
      },
      "title": "TextToVideoRequest",
      "description": "Base request for text-to-video generation",
      "required": [
        "prompt"
      ]
    },
    "credits": 4,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/wan-pro/text-to-video",
    "name": "Wan-2.1 Pro Text-to-Video",
    "description": "Wan-2.1 Pro is a premium text-to-video model that generates high-quality 1080p videos at 30fps with up to 6 seconds duration, delivering exceptional visual quality and motion diversity from text prompts",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_02.jpg",
    "tags": [
      "text to video",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "WanProT2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A lone astronaut in a detailed NASA spacesuit performs an exuberant dance on the lunar surface, arms outstretched in joyful abandon against the stark moonscape. The Earth hangs dramatically in the black sky, appearing to streak past due to the motion of the dance, creating a sense of dynamic movement. The scene captures extreme contrasts between the brilliant white of the spacesuit reflecting harsh sunlight and the deep shadows of the lunar craters. Every detail is rendered with photorealistic precision: the texture of the regolith disturbed by the astronaut's boots, the reflections on the helmet visor."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video"
        },
        "enable_safety_checker": {
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "Whether to enable the safety checker",
          "default": true
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "5 seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/kling-video/v1.5/pro/effects",
    "name": "Kling 1.5",
    "description": "Generate video clips from your prompts using Kling 1.5 (pro)",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "VideoEffectsRequest",
      "type": "object",
      "properties": {
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "input_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/juggernaut_examples/VHXMavzPyI27zi6JseyL4.png",
              "https://storage.googleapis.com/falserverless/juggernaut_examples/QEW5VrzccxGva7mPfEXjf.png"
            ]
          ],
          "description": "URL of images to be used for hug, kiss or heart_gesture video.",
          "type": "array",
          "title": "Input Image Urls",
          "items": {
            "type": "string"
          }
        },
        "effect_scene": {
          "enum": [
            "hug",
            "kiss",
            "heart_gesture",
            "squish",
            "expansion",
            "fuzzyfuzzy",
            "bloombloom",
            "dizzydizzy",
            "jelly_press",
            "jelly_slice",
            "jelly_squish",
            "jelly_jiggle",
            "pixelpixel",
            "yearbook",
            "instant_film",
            "anime_figure",
            "rocketrocket"
          ],
          "description": "The effect scene to use for the video generation",
          "type": "string",
          "title": "Effect Scene",
          "examples": [
            "hug"
          ]
        }
      },
      "x-fal-order-properties": [
        "input_image_urls",
        "effect_scene",
        "duration"
      ],
      "required": [
        "effect_scene"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/pro/effects",
    "name": "Kling 1.6",
    "description": "Generate video clips from your prompts using Kling 1.6 (pro)",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "VideoEffectsRequest",
      "type": "object",
      "properties": {
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "input_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/juggernaut_examples/VHXMavzPyI27zi6JseyL4.png",
              "https://storage.googleapis.com/falserverless/juggernaut_examples/QEW5VrzccxGva7mPfEXjf.png"
            ]
          ],
          "description": "URL of images to be used for hug, kiss or heart_gesture video.",
          "type": "array",
          "title": "Input Image Urls",
          "items": {
            "type": "string"
          }
        },
        "effect_scene": {
          "enum": [
            "hug",
            "kiss",
            "heart_gesture",
            "squish",
            "expansion",
            "fuzzyfuzzy",
            "bloombloom",
            "dizzydizzy",
            "jelly_press",
            "jelly_slice",
            "jelly_squish",
            "jelly_jiggle",
            "pixelpixel",
            "yearbook",
            "instant_film",
            "anime_figure",
            "rocketrocket"
          ],
          "description": "The effect scene to use for the video generation",
          "type": "string",
          "title": "Effect Scene",
          "examples": [
            "hug"
          ]
        }
      },
      "x-fal-order-properties": [
        "input_image_urls",
        "effect_scene",
        "duration"
      ],
      "required": [
        "effect_scene"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1/standard/effects",
    "name": "Kling 1.0",
    "description": "Generate video clips from your prompts using Kling 1.0",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/GoSnDOnX0Tea08N7iI7oM.jpeg",
    "tags": [
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "VideoEffectsRequest",
      "type": "object",
      "properties": {
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "input_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/juggernaut_examples/VHXMavzPyI27zi6JseyL4.png",
              "https://storage.googleapis.com/falserverless/juggernaut_examples/QEW5VrzccxGva7mPfEXjf.png"
            ]
          ],
          "description": "URL of images to be used for hug, kiss or heart_gesture video.",
          "type": "array",
          "title": "Input Image Urls",
          "items": {
            "type": "string"
          }
        },
        "effect_scene": {
          "enum": [
            "hug",
            "kiss",
            "heart_gesture",
            "squish",
            "expansion",
            "fuzzyfuzzy",
            "bloombloom",
            "dizzydizzy",
            "jelly_press",
            "jelly_slice",
            "jelly_squish",
            "jelly_jiggle",
            "pixelpixel",
            "yearbook",
            "instant_film",
            "anime_figure",
            "rocketrocket"
          ],
          "description": "The effect scene to use for the video generation",
          "type": "string",
          "title": "Effect Scene",
          "examples": [
            "hug"
          ]
        }
      },
      "x-fal-order-properties": [
        "input_image_urls",
        "effect_scene",
        "duration"
      ],
      "required": [
        "effect_scene"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/standard/effects",
    "name": "Kling 1.6",
    "description": "Generate video clips from your prompts using Kling 1.6 (std)",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "VideoEffectsRequest",
      "type": "object",
      "properties": {
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "input_image_urls": {
          "examples": [
            [
              "https://storage.googleapis.com/falserverless/juggernaut_examples/VHXMavzPyI27zi6JseyL4.png",
              "https://storage.googleapis.com/falserverless/juggernaut_examples/QEW5VrzccxGva7mPfEXjf.png"
            ]
          ],
          "description": "URL of images to be used for hug, kiss or heart_gesture video.",
          "type": "array",
          "title": "Input Image Urls",
          "items": {
            "type": "string"
          }
        },
        "effect_scene": {
          "enum": [
            "hug",
            "kiss",
            "heart_gesture",
            "squish",
            "expansion",
            "fuzzyfuzzy",
            "bloombloom",
            "dizzydizzy",
            "jelly_press",
            "jelly_slice",
            "jelly_squish",
            "jelly_jiggle",
            "pixelpixel",
            "yearbook",
            "instant_film",
            "anime_figure",
            "rocketrocket"
          ],
          "description": "The effect scene to use for the video generation",
          "type": "string",
          "title": "Effect Scene",
          "examples": [
            "hug"
          ]
        }
      },
      "x-fal-order-properties": [
        "input_image_urls",
        "effect_scene",
        "duration"
      ],
      "required": [
        "effect_scene"
      ]
    }
  },
  {
    "id": "fal-ai/ltx-video-v095",
    "name": "LTX Video-0.9.5",
    "description": "Generate videos from prompts using LTX Video-0.9.5",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/ltx-0.9.5.webp",
    "tags": [
      "video",
      "text-video"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cute cat walking on a sidewalk"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "Text prompt to guide generation"
        },
        "resolution": {
          "enum": [
            "480p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "Resolution of the generated video (480p or 720p).",
          "default": "720p"
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "default": "16:9"
        },
        "expand_prompt": {
          "title": "Expand Prompt",
          "type": "boolean",
          "description": "Whether to expand the prompt using the model's own capabilities.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for generation"
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "Number of inference steps",
          "default": 40
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "Negative prompt for generation",
          "default": "worst quality, inconsistent motion, blurry, jittery, distorted"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "resolution",
        "aspect_ratio",
        "seed",
        "num_inference_steps",
        "expand_prompt"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/pro/text-to-video",
    "name": "Kling 1.6",
    "description": "Generate video clips from your prompts using Kling 1.6 (pro)",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "duration",
        "aspect_ratio",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/wan/v2.1/1.3b/text-to-video",
    "name": "Wan-2.1 1.3B Text-to-Video",
    "description": "Wan-2.1 1.3B is a text-to-video model that generates high-quality videos with high visual quality and motion diversity from text promptsat faster speeds.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_02.jpg",
    "tags": [
      "text to video",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": null,
    "credits": 4,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/wan-t2v",
    "name": "Wan-2.1 Text-to-Video",
    "description": "Wan-2.1 is a text-to-video model that generates high-quality videos with high visual quality and motion diversity from text prompts",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_02.jpg",
    "tags": [
      "text to video",
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_frames",
        "frames_per_second",
        "seed",
        "resolution",
        "aspect_ratio",
        "num_inference_steps",
        "enable_safety_checker",
        "enable_prompt_expansion",
        "turbo_mode"
      ],
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt to guide video generation."
        },
        "aspect_ratio": {
          "enum": [
            "9:16",
            "16:9"
          ],
          "description": "Aspect ratio of the generated video (16:9 or 9:16).",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "description": "Resolution of the generated video (480p, 580p, or 720p).",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "Random seed for reproducibility. If None, a random seed is chosen."
        },
        "turbo_mode": {
          "description": "If true, the video will be generated faster with no noticeable degradation in the visual quality.",
          "type": "boolean",
          "title": "Turbo Mode",
          "default": false
        },
        "frames_per_second": {
          "minimum": 5,
          "maximum": 24,
          "type": "integer",
          "description": "Frames per second of the generated video. Must be between 5 to 24.",
          "title": "Frames Per Second",
          "default": 16
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "num_frames": {
          "minimum": 81,
          "title": "Num Frames",
          "type": "integer",
          "maximum": 100,
          "description": "Number of frames to generate. Must be between 81 to 100 (inclusive).",
          "default": 81
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 40,
          "type": "integer",
          "description": "Number of inference steps for sampling. Higher values give better quality but take longer.",
          "title": "Num Inference Steps",
          "default": 30
        },
        "negative_prompt": {
          "examples": [
            "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
          ],
          "description": "Negative prompt for video generation.",
          "type": "string",
          "title": "Negative Prompt",
          "default": "bright colors, overexposed, static, blurred details, subtitles, style, artwork, painting, picture, still, overall gray, worst quality, low quality, JPEG compression residue, ugly, incomplete, extra fingers, poorly drawn hands, poorly drawn faces, deformed, disfigured, malformed limbs, fused fingers, still picture, cluttered background, three legs, many people in the background, walking backwards"
        },
        "enable_prompt_expansion": {
          "examples": [
            false
          ],
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": false
        }
      },
      "title": "WanT2VRequest",
      "required": [
        "prompt"
      ]
    },
    "credits": 8,
    "pricing_unit": "videos"
  },
  {
    "id": "fal-ai/veo2",
    "name": "Veo 2",
    "description": "Veo 2 creates videos with realistic motion and high quality output. Explore different styles and find your own with extensive camera controls.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/web-examples/veo2/veo2.webp",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "The camera floats gently through rows of pastel-painted wooden beehives, buzzing honeybees gliding in and out of frame. The motion settles on the refined farmer standing at the center, his pristine white beekeeping suit gleaming in the golden afternoon light. He lifts a jar of honey, tilting it slightly to catch the light. Behind him, tall sunflowers sway rhythmically in the breeze, their petals glowing in the warm sunlight. The camera tilts upward to reveal a retro farmhouse with mint-green shutters, its walls dappled with shadows from swaying trees. Shot with a 35mm lens on Kodak Portra 400 film, the golden light creates rich textures on the farmer's gloves, marmalade jar, and weathered wood of the beehives."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The text prompt describing the video you want to generate",
          "minLength": 1
        },
        "duration": {
          "enum": [
            "5s",
            "6s",
            "7s",
            "8s"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5s"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "A seed to use for the video generation"
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "A negative prompt to guide the video generation"
        },
        "enhance_prompt": {
          "title": "Enhance Prompt",
          "type": "boolean",
          "description": "Whether to enhance the video generation",
          "default": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "duration",
        "negative_prompt",
        "enhance_prompt",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/minimax/video-01-director",
    "name": "MiniMax (Hailuo AI) Video 01 Director",
    "description": "Generate video clips more accurately with respect to natural language descriptions and using camera movement instructions for shot control.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/red_clouds.jpg",
    "tags": [
      "motion",
      "transformation",
      "camera-controls"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoDirectorRequest",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "[Push in]Close up of a tense woman looks to the left, startled by a sound, in a darkened kitchen, Pots and pans hang ominously, the window in the kitchen is open and the wind softly blows the pans and creates an ominous mood. [Shake]the woman's shock turns to fear. Black-and-white film noir shot dimly lit, 1950s-style, with dramatic, high-contrast shadows. The overall atmosphere is reminiscent of Alfred Hitchcock's suspenseful storytelling, evoking a looming sense of dread with stark chiaroscuro lighting and a slight film-grain texture."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000,
          "description": "Text prompt for video generation. Camera movement instructions can be added using square brackets (e.g. [Pan left] or [Zoom in]). You can use up to 3 combined movements per prompt. Supported movements: Truck left/right, Pan left/right, Push in/Pull out, Pedestal up/down, Tilt up/down, Zoom in/out, Shake, Tracking shot, Static shot. For example: [Truck left, Pan right, Zoom in]. For a more detailed guide, refer https://sixth-switch-2ac.notion.site/T2V-01-Director-Model-Tutorial-with-camera-movement-1886c20a98eb80f395b8e05291ad8645"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "prompt_optimizer"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/pixverse/v3.5/text-to-video",
    "name": "PixVerse v3.5",
    "description": "Generate high quality video clips from text prompts using PixVerse v3.5",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "duration": {
          "enum": [
            "5",
            "8"
          ],
          "description": "The duration of the generated video in seconds. 8s videos cost double. 1080p videos are limited to 5 seconds",
          "type": "string",
          "title": "Duration",
          "default": "5"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p",
            "1080p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "duration",
        "negative_prompt",
        "style",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 1,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/pixverse/v3.5/text-to-video/fast",
    "name": "PixVerse v3.5 Fast",
    "description": "Generate high quality video clips quickly from text prompts using PixVerse v3.5 Fast",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/pixverse-v3.5.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastTextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Epic low-cut camera capture of a girl clad in ultraviolet threads, Peter Max art style depiction, luminous diamond skin glistening under a vast moon's radiance, embodied in a superhuman flight among mystical ruins, symbolizing a deity's ritual ascent, hyper-detailed"
          ],
          "title": "Prompt",
          "type": "string"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "4:3",
            "1:1",
            "3:4",
            "9:16"
          ],
          "description": "The aspect ratio of the generated video",
          "type": "string",
          "title": "Aspect Ratio",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "360p",
            "540p",
            "720p"
          ],
          "description": "The resolution of the generated video",
          "type": "string",
          "title": "Resolution",
          "default": "720p"
        },
        "style": {
          "enum": [
            "anime",
            "3d_animation",
            "clay",
            "comic",
            "cyberpunk"
          ],
          "description": "The style of the generated video",
          "type": "string",
          "title": "Style"
        },
        "seed": {
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        ",
          "type": "integer",
          "title": "Seed"
        },
        "negative_prompt": {
          "examples": [
            "blurry, low quality, low resolution, pixelated, noisy, grainy, out of focus, poorly lit, poorly exposed, poorly composed, poorly framed, poorly cropped, poorly color corrected, poorly color graded"
          ],
          "description": "Negative prompt to be used for the generation",
          "type": "string",
          "title": "Negative Prompt",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "resolution",
        "negative_prompt",
        "style",
        "seed"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits": 2,
    "pricing_unit": "video segments"
  },
  {
    "id": "fal-ai/luma-dream-machine/ray-2",
    "name": "Luma Ray 2",
    "description": "Ray2 is a large-scale video generative model capable of creating realistic visuals with natural, coherent motion.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/luma-dream-machine-ray-2.webp",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Ray2TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A herd of wild horses galloping across a dusty desert plain under a blazing midday sun, their manes flying in the wind; filmed in a wide tracking shot with dynamic motion, warm natural lighting, and an epic."
          ],
          "maxLength": 5000,
          "type": "string",
          "minLength": 3,
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "21:9",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "540p",
            "720p",
            "1080p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the generated video (720p costs 2x more, 1080p costs 4x more)",
          "default": "540p"
        },
        "loop": {
          "title": "Loop",
          "type": "boolean",
          "description": "Whether the video should loop (end of video is blended with the beginning)",
          "default": false
        },
        "duration": {
          "enum": [
            "5s",
            "9s"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video (9s costs 2x more)",
          "default": "5s"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "loop",
        "resolution",
        "duration"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/hunyuan-video-lora",
    "name": "Hunyuan Video LoRA Inference",
    "description": "Hunyuan Video is an Open video generation model with high visual quality, motion diversity, text-video alignment, and generation stability",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video.webp?v=1",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "HunyuanT2VRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio (W:H)",
          "type": "string",
          "description": "The aspect ratio of the video to generate.",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the video to generate.",
          "default": "720p"
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. You can use any number of LoRAs\n            and they will be merged together to generate the final image.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for generating the video."
        },
        "num_frames": {
          "enum": [
            "129",
            "85"
          ],
          "title": "Number of Frames",
          "type": "string",
          "description": "The number of frames to generate.",
          "default": 129
        },
        "pro_mode": {
          "title": "Pro Mode",
          "type": "boolean",
          "description": "By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "pro_mode",
        "aspect_ratio",
        "resolution",
        "num_frames",
        "enable_safety_checker",
        "loras"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/transpixar",
    "name": "TransPixar V1",
    "description": "Transform text into stunning videos with TransPixar - an AI model that generates both RGB footage and alpha channels, enabling seamless compositing and creative video effects.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/transpixar.webp",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A cloud of dust erupting and dispersing like an explosion."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 20,
          "type": "number",
          "title": "Guidance scale (CFG)",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
          "default": 7
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to perform.",
          "default": 24
        },
        "export_fps": {
          "minimum": 4,
          "maximum": 32,
          "type": "integer",
          "title": "Export Fps",
          "description": "The target FPS of the video",
          "default": 8
        },
        "negative_prompt": {
          "examples": [
            "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to generate video from",
          "default": ""
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "export_fps"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/cogvideox-5b",
    "name": "CogVideoX-5B",
    "description": "Generate videos from prompts using CogVideoX-5B",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/model_tests/cogvideox/panda.gif.gif",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "BaseInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A garden comes to life as a kaleidoscope of butterflies flutters amidst the blossoms, their delicate wings casting shadows on the petals below. In the background, a grand fountain cascades water with a gentle splendor, its rhythmic sound providing a soothing backdrop. Beneath the cool shade of a mature tree, a solitary wooden chair invites solitude and reflection, its smooth surface worn by the touch of countless visitors seeking a moment of tranquility in nature's embrace."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "use_rife": {
          "title": "Use Rife",
          "type": "boolean",
          "description": "Use RIFE for video interpolation",
          "default": true
        },
        "loras": {
          "description": "\n            The LoRAs to use for the image generation. We currently support one lora.\n        ",
          "type": "array",
          "items": {
            "$ref": "#/components/schemas/LoraWeight"
          },
          "examples": [],
          "title": "Loras",
          "default": []
        },
        "video_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Video Size",
          "description": "The size of the generated video.",
          "default": {
            "height": 480,
            "width": 720
          }
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related video to show you.\n        ",
          "maximum": 20,
          "default": 7
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of the model\n            will output the same video every time.\n        "
        },
        "export_fps": {
          "minimum": 4,
          "title": "Export Fps",
          "type": "integer",
          "description": "The target FPS of the video",
          "maximum": 32,
          "default": 16
        },
        "negative_prompt": {
          "examples": [
            "Distorted, discontinuous, Ugly, blurry, low resolution, motionless, static, disfigured, disconnected limbs, Ugly faces, incomplete arms"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to generate video from",
          "default": ""
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "description": "The number of inference steps to perform.",
          "maximum": 50,
          "default": 50
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "video_size",
        "negative_prompt",
        "loras",
        "num_inference_steps",
        "seed",
        "guidance_scale",
        "use_rife",
        "export_fps"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1.6/standard/text-to-video",
    "name": "Kling 1.6",
    "description": "Generate video clips from your prompts using Kling 1.6 (std)",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "duration",
        "aspect_ratio",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 5,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/minimax/video-01-live",
    "name": "MiniMax (Hailuo AI) Video 01 Live",
    "description": "Generate video clips from your prompts using MiniMax model",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/fal_cdn/Fal_Visuals_V1_016.jpg",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoLiveRequest",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "A rugged middle-aged man with wheat-colored skin and a full beard streaked with gray stands in the harsh sunlight of a desert outpost. His curly hair is windswept, and sweat drips down the bridge of his slightly crooked nose. His faded utility jacket and weathered boots are caked in dust, while his sharp, watchful eyes scan the horizon."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "prompt_optimizer"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/luma-dream-machine",
    "name": "Luma Dream Machine",
    "description": "Generate video clips from your prompts using Luma Dream Machine v1.5",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/JtiRw34MZ1GkgxRnH52Cs.png",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A teddy bear in sunglasses playing electric guitar and dancing"
          ],
          "maxLength": 5000,
          "type": "string",
          "minLength": 3,
          "title": "Prompt"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "4:3",
            "3:4",
            "21:9",
            "9:21"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video",
          "default": "16:9"
        },
        "loop": {
          "title": "Loop",
          "type": "boolean",
          "description": "Whether the video should loop (end of video is blended with the beginning)",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "aspect_ratio",
        "loop"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1/standard/text-to-video",
    "name": "Kling 1.0",
    "description": "Generate video clips from your prompts using Kling 1.0",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/GoSnDOnX0Tea08N7iI7oM.jpeg",
    "tags": [
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "V1TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "advanced_camera_control": {
          "description": "Advanced Camera control parameters",
          "title": "Advanced Camera Control",
          "allOf": [
            {
              "$ref": "#/components/schemas/CameraControl"
            }
          ]
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "camera_control": {
          "enum": [
            "down_back",
            "forward_up",
            "right_turn_forward",
            "left_turn_forward"
          ],
          "description": "Camera control parameters",
          "type": "string",
          "title": "Camera Control"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "duration",
        "aspect_ratio",
        "negative_prompt",
        "cfg_scale",
        "camera_control",
        "advanced_camera_control"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 5,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/kling-video/v1.5/pro/text-to-video",
    "name": "Kling 1.5",
    "description": "Generate video clips from your prompts using Kling 1.5 (pro)",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/elephant/28-vTrv3W2BT-u8_cy7mt.png",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "maxLength": 2500,
          "type": "string",
          "title": "Prompt"
        },
        "duration": {
          "enum": [
            "5",
            "10"
          ],
          "title": "Duration",
          "type": "string",
          "description": "The duration of the generated video in seconds",
          "default": "5"
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16",
            "1:1"
          ],
          "title": "Aspect Ratio",
          "type": "string",
          "description": "The aspect ratio of the generated video frame",
          "default": "16:9"
        },
        "negative_prompt": {
          "maxLength": 2500,
          "type": "string",
          "title": "Negative Prompt",
          "default": "blur, distort, and low quality"
        },
        "cfg_scale": {
          "minimum": 0,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt.\n        ",
          "type": "number",
          "title": "Cfg Scale",
          "maximum": 1,
          "default": 0.5
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "duration",
        "aspect_ratio",
        "negative_prompt",
        "cfg_scale"
      ],
      "required": [
        "prompt"
      ]
    },
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/mochi-v1",
    "name": "Mochi 1",
    "description": "Mochi 1 preview is an open state-of-the-art video generation model with high-fidelity motion and strong prompt adherence in preliminary evaluation.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/mochi-v1.webp?v=1",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "MochiT2VInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A dog running in a field."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate a video from."
        },
        "enable_prompt_expansion": {
          "title": "Enable Prompt Expansion",
          "type": "boolean",
          "description": "Whether to enable prompt expansion.",
          "default": true
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for generating the video."
        },
        "negative_prompt": {
          "examples": [
            "Blurry, shaky footage"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt for the video.",
          "default": ""
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "seed",
        "enable_prompt_expansion"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/hunyuan-video",
    "name": "Hunyuan Video",
    "description": "Hunyuan Video is an Open video generation model with high visual quality, motion diversity, text-video alignment, and generation stability. This endpoint generates videos from text descriptions.",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/hunyuan-video.webp?v=1",
    "tags": [
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "HunyuanVideoRequest",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "aspect_ratio": {
          "enum": [
            "16:9",
            "9:16"
          ],
          "title": "Aspect Ratio (W:H)",
          "type": "string",
          "description": "The aspect ratio of the video to generate.",
          "default": "16:9"
        },
        "resolution": {
          "enum": [
            "480p",
            "580p",
            "720p"
          ],
          "title": "Resolution",
          "type": "string",
          "description": "The resolution of the video to generate.",
          "default": "720p"
        },
        "enable_safety_checker": {
          "examples": [
            true
          ],
          "title": "Enable Safety Checker",
          "type": "boolean",
          "description": "If set to true, the safety checker will be enabled.",
          "default": false
        },
        "num_inference_steps": {
          "minimum": 2,
          "maximum": 30,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of inference steps to run. Lower gets faster results, higher gets better results.",
          "default": 30
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "The seed to use for generating the video."
        },
        "num_frames": {
          "enum": [
            "129",
            "85"
          ],
          "title": "Number of Frames",
          "type": "string",
          "description": "The number of frames to generate.",
          "default": 129
        },
        "pro_mode": {
          "title": "Pro Mode",
          "type": "boolean",
          "description": "By default, generations are done with 35 steps. Pro mode does 55 steps which results in higher quality videos but will take more time and cost 2x more billing units.",
          "default": false
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "num_inference_steps",
        "seed",
        "pro_mode",
        "aspect_ratio",
        "resolution",
        "num_frames",
        "enable_safety_checker"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/kling-video/v1/pro/text-to-video",
    "name": "Kling 1.0",
    "description": "Generate video clips from your prompts using Kling 1.0 (pro)",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/GoSnDOnX0Tea08N7iI7oM.jpeg",
    "tags": [
      "motion"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": null,
    "credits_per_5sec": 10,
    "pricing_unit": "seconds"
  },
  {
    "id": "fal-ai/ltx-video",
    "name": "LTX Video (preview)",
    "description": "Generate videos from prompts using LTX Video",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/model_tests/cogvideox/panda.gif.gif",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A man stands waist-deep in a crystal-clear mountain pool, his back turned to a massive, thundering waterfall that cascades down jagged cliffs behind him. He wears a dark blue swimming shorts and his muscular back glistens with water droplets. The camera moves in a dynamic circular motion around him, starting from his right side and sweeping left, maintaining a slightly low angle that emphasizes the towering height of the waterfall. As the camera moves, the man slowly turns his head to follow its movement, his expression one of awe as he gazes up at the natural wonder. The waterfall creates a misty atmosphere, with sunlight filtering through the spray to create rainbow refractions. The water churns and ripples around him, reflecting the dramatic landscape. The handheld camera movement adds a subtle shake that enhances the raw, untamed energy of the scene. The lighting is natural and bright, with the sun positioned behind the waterfall, creating a backlit effect that silhouettes the falling water and illuminates the mist."
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate the video from."
        },
        "guidance_scale": {
          "maximum": 10,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The guidance scale to use.",
          "exclusiveMinimum": 1,
          "default": 3
        },
        "seed": {
          "anyOf": [
            {
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "The seed to use for random number generation."
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 50,
          "type": "integer",
          "title": "Number of Inference Steps",
          "description": "The number of inference steps to take.",
          "default": 30
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to generate the video from.",
          "default": "low quality, worst quality, deformed, distorted, disfigured, motion smear, motion artifacts, fused fingers, bad anatomy, weird hand, ugly"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "seed",
        "num_inference_steps",
        "guidance_scale"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/fast-svd/text-to-video",
    "name": "Stable Video Diffusion",
    "description": "Generate short video clips from your prompts using SVD v1.1",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/svd_rocket.gif",
    "tags": [],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastSVDTextInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A rocket flying that is about to take off"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use as a starting point for the generation."
        },
        "cond_aug": {
          "minimum": 0,
          "maximum": 10,
          "type": "number",
          "title": "Cond Aug",
          "description": "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
          "default": 0.02
        },
        "deep_cache": {
          "enum": [
            "none",
            "minimum",
            "medium",
            "high"
          ],
          "title": "Deep Cache",
          "type": "string",
          "description": "\n            Enabling [DeepCache](https://github.com/horseee/DeepCache) will make the execution\n            faster, but might sometimes degrade overall quality. The higher the setting, the\n            faster the execution will be, but the more quality might be lost.\n        ",
          "default": "none"
        },
        "fps": {
          "minimum": 1,
          "maximum": 25,
          "type": "integer",
          "title": "Fps",
          "description": "\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ",
          "default": 10
        },
        "motion_bucket_id": {
          "minimum": 1,
          "maximum": 255,
          "type": "integer",
          "title": "Motion Bucket Id",
          "description": "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
          "default": 127
        },
        "video_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Video Size",
          "description": "The size of the generated video.",
          "default": "landscape_16_9"
        },
        "steps": {
          "minimum": 1,
          "maximum": 100,
          "type": "integer",
          "title": "Steps",
          "description": "\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ",
          "default": 20
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "The negative prompt to use as a starting point for the generation.",
          "default": "unrealistic, saturated, high contrast, big nose, painting, drawing, sketch, cartoon, anime, manga, render, CG, 3d, watermark, signature, label"
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "motion_bucket_id",
        "cond_aug",
        "seed",
        "steps",
        "deep_cache",
        "fps",
        "negative_prompt",
        "video_size"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/fast-svd-lcm/text-to-video",
    "name": "Stable Video Diffusion Turbo",
    "description": "Generate short video clips from your images using SVD v1.1 at Lightning Speed",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/fast-svd-turbo.gif",
    "tags": [
      "lcm",
      "diffusion",
      "turbo"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "FastSVDTextInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "A rocket flying that is about to take off"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use as a starting point for the generation."
        },
        "cond_aug": {
          "minimum": 0,
          "maximum": 10,
          "type": "number",
          "title": "Cond Aug",
          "description": "\n            The conditoning augmentation determines the amount of noise that will be\n            added to the conditioning frame. The higher the number, the more noise\n            there will be, and the less the video will look like the initial image.\n            Increase it for more motion.\n        ",
          "default": 0.02
        },
        "fps": {
          "minimum": 1,
          "maximum": 25,
          "type": "integer",
          "title": "Fps",
          "description": "\n            The FPS of the generated video. The higher the number, the faster the video will\n            play. Total video length is 25 frames.\n        ",
          "default": 10
        },
        "motion_bucket_id": {
          "minimum": 1,
          "maximum": 255,
          "type": "integer",
          "title": "Motion Bucket Id",
          "description": "\n            The motion bucket id determines the motion of the generated video. The\n            higher the number, the more motion there will be.\n        ",
          "default": 127
        },
        "video_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Video Size",
          "description": "The size of the generated video.",
          "default": "landscape_16_9"
        },
        "steps": {
          "minimum": 1,
          "maximum": 20,
          "type": "integer",
          "title": "Steps",
          "description": "\n            The number of steps to run the model for. The higher the number the better\n            the quality and longer it will take to generate.\n        ",
          "default": 4
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "motion_bucket_id",
        "cond_aug",
        "seed",
        "steps",
        "fps",
        "video_size"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/t2v-turbo",
    "name": "T2V Turbo - Video Crafter",
    "description": "Generate short video clips from your prompts",
    "category": "text-to-video",
    "thumbnail_url": "https://fal.media/files/monkey/yirvhUzF8h7DVpCoDGsdU.png",
    "tags": [
      "turbo"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "Input",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "a dog wearing vr goggles on a boat"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to generate images from"
        },
        "guidance_scale": {
          "minimum": 0.1,
          "maximum": 30,
          "type": "number",
          "title": "Guidance Scale",
          "description": "The guidance scale",
          "default": 7.5
        },
        "seed": {
          "anyOf": [
            {
              "minimum": 0,
              "maximum": 203279,
              "type": "integer"
            },
            {
              "type": "null"
            }
          ],
          "title": "Seed",
          "description": "The seed to use for the random number generator"
        },
        "export_fps": {
          "minimum": 1,
          "maximum": 24,
          "type": "integer",
          "title": "Export Fps",
          "description": "The FPS of the exported video",
          "default": 8
        },
        "num_frames": {
          "minimum": 16,
          "maximum": 32,
          "type": "integer",
          "title": "Num Frames",
          "description": "The number of frames to generate",
          "default": 16
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 12,
          "type": "integer",
          "title": "Num Inference Steps",
          "description": "The number of steps to sample",
          "default": 4
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "seed",
        "num_inference_steps",
        "guidance_scale",
        "num_frames",
        "export_fps"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/fast-animatediff/text-to-video",
    "name": "AnimateDiff",
    "description": "Animate your ideas!",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/fast-animatediff-t2v.webp",
    "tags": [
      "animation",
      "stylized"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AnimateDiffT2VInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "masterpiece, best quality, 1girl, solo, cherry blossoms, hanami, pink flower, white flower, spring season, wisteria, petals, flower, plum blossoms, outdoors, falling petals, white hair, black eyes",
            "panda playing a guitar, on a boat, in the ocean, high quality, high quality, ultra HD, realistic"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the video. Be as descriptive as possible for best results."
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "fps": {
          "minimum": 1,
          "title": "Fps",
          "type": "integer",
          "maximum": 16,
          "description": "Number of frames per second to extract from the video.",
          "default": 8
        },
        "video_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Video Size",
          "description": "The size of the video to generate.",
          "default": "square"
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance scale (CFG)",
          "type": "number",
          "maximum": 20,
          "description": "\n            The CFG (Classifier Free Guidance) scale is a measure of how close you want\n            the model to stick to your prompt when looking for a related image to show you.\n        ",
          "default": 7.5
        },
        "num_frames": {
          "minimum": 1,
          "title": "Num Frames",
          "type": "integer",
          "maximum": 32,
          "description": "The number of frames to generate for the video.",
          "default": 16
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 50,
          "description": "The number of inference steps to perform.",
          "default": 25
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": "(bad quality, worst quality:1.2), ugly faces, bad anime"
        },
        "motions": {
          "title": "Motions",
          "type": "array",
          "description": "The motions to apply to the video.",
          "uniqueItems": true,
          "items": {
            "enum": [
              "zoom-out",
              "zoom-in",
              "pan-left",
              "pan-right",
              "tilt-up",
              "tilt-down"
            ],
            "type": "string"
          }
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_frames",
        "num_inference_steps",
        "guidance_scale",
        "seed",
        "fps",
        "motions",
        "video_size"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/fast-animatediff/turbo/text-to-video",
    "name": "AnimateDiff Turbo",
    "description": "Animate your ideas in lightning speed!",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/fast-animatediff-t2v-turbo.webp",
    "tags": [
      "animation",
      "stylized",
      "turbo"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AnimateDiffT2VTurboInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "masterpiece, best quality, 1girl, solo, cherry blossoms, hanami, pink flower, white flower, spring season, wisteria, petals, flower, plum blossoms, outdoors, falling petals, white hair, black eyes",
            "panda playing a guitar, on a boat, in the ocean, high quality, high quality, ultra HD, realistic"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the video. Be as descriptive as possible for best results."
        },
        "seed": {
          "title": "Seed",
          "type": "integer",
          "description": "\n            The same seed and the same prompt given to the same version of Stable Diffusion\n            will output the same image every time.\n        "
        },
        "fps": {
          "minimum": 1,
          "title": "Fps",
          "type": "integer",
          "maximum": 16,
          "description": "Number of frames per second to extract from the video.",
          "default": 8
        },
        "video_size": {
          "anyOf": [
            {
              "$ref": "#/components/schemas/ImageSize"
            },
            {
              "enum": [
                "square_hd",
                "square",
                "portrait_4_3",
                "portrait_16_9",
                "landscape_4_3",
                "landscape_16_9"
              ],
              "type": "string"
            }
          ],
          "title": "Video Size",
          "description": "The size of the video to generate.",
          "default": "square"
        },
        "guidance_scale": {
          "minimum": 0,
          "title": "Guidance Scale",
          "type": "number",
          "maximum": 20,
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "default": 1
        },
        "num_frames": {
          "minimum": 1,
          "title": "Num Frames",
          "type": "integer",
          "maximum": 64,
          "description": "The number of frames to generate for the video.",
          "default": 16
        },
        "num_inference_steps": {
          "minimum": 1,
          "title": "Num Inference Steps",
          "type": "integer",
          "maximum": 8,
          "description": "The number of inference steps to perform. 4-12 is recommended for turbo mode.",
          "default": 4
        },
        "negative_prompt": {
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to address details that you don't want\n            in the image. This could be colors, objects, scenery and even the small details\n            (e.g. moustache, blurry, low resolution).\n        ",
          "default": "(bad quality, worst quality:1.2), ugly faces, bad anime"
        },
        "motions": {
          "title": "Motions",
          "type": "array",
          "description": "The motions to apply to the video.",
          "uniqueItems": true,
          "items": {
            "enum": [
              "zoom-out",
              "zoom-in",
              "pan-left",
              "pan-right",
              "tilt-up",
              "tilt-down"
            ],
            "type": "string"
          }
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "num_frames",
        "num_inference_steps",
        "guidance_scale",
        "seed",
        "fps",
        "motions",
        "video_size"
      ],
      "required": [
        "prompt"
      ]
    },
    "pricing_unit": "compute seconds",
    "pricing_type": "variable"
  },
  {
    "id": "fal-ai/minimax/video-01",
    "name": "MiniMax (Hailuo AI) Video 01",
    "description": "Generate video clips from your prompts using MiniMax model",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/red_clouds.jpg",
    "tags": [
      "motion",
      "transformation"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "TextToVideoRequest",
      "type": "object",
      "properties": {
        "prompt_optimizer": {
          "title": "Prompt Optimizer",
          "type": "boolean",
          "description": "Whether to use the model's prompt optimizer",
          "default": true
        },
        "prompt": {
          "examples": [
            "A stylish woman walks down a Tokyo street filled with warm glowing neon and animated city signage. She wears a black leather jacket, a long red dress, and black boots, and carries a black purse."
          ],
          "title": "Prompt",
          "type": "string",
          "maxLength": 2000
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "prompt_optimizer"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "fal-ai/animatediff-sparsectrl-lcm",
    "name": "Animatediff SparseCtrl LCM",
    "description": "Animate Your Drawings with Latent Consistency Models!",
    "category": "text-to-video",
    "thumbnail_url": "https://storage.googleapis.com/falserverless/gallery/ad-sparsectrl-lcm.png",
    "tags": [
      "lcm",
      "animation",
      "stylized"
    ],
    "highlighted": false,
    "pinned": false,
    "input_schema": {
      "title": "AnimatediffLCMInput",
      "type": "object",
      "properties": {
        "prompt": {
          "examples": [
            "Drone footage, futuristic city at night, synthwave, vaporware, neon lights, highly detailed, masterpeice, high quality"
          ],
          "title": "Prompt",
          "type": "string",
          "description": "The prompt to use for generating the image. Be as descriptive as possible for best results."
        },
        "seed": {
          "examples": [
            42
          ],
          "title": "Seed",
          "type": "integer",
          "description": "\n        The same seed and the same prompt given to the same version of Stable\n        Diffusion will output the same image every time.\n        "
        },
        "controlnet_type": {
          "enum": [
            "scribble",
            "rgb"
          ],
          "title": "Controlnet Type",
          "type": "string",
          "description": "The type of controlnet to use for generating the video. The controlnet determines how the video will be animated.",
          "default": "scribble"
        },
        "keyframe_2_index": {
          "examples": [
            15
          ],
          "title": "Keyframe 2 Index",
          "type": "integer",
          "description": "The frame index of the third keyframe to use for the generation.",
          "nullable": false,
          "default": 0
        },
        "keyframe_0_index": {
          "examples": [
            0
          ],
          "title": "Keyframe 0 Index",
          "type": "integer",
          "description": "The frame index of the first keyframe to use for the generation.",
          "nullable": false,
          "default": 0
        },
        "keyframe_1_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/scribble2/scribble_2_2.png"
          ],
          "title": "Keyframe 1 Image Url",
          "type": "string",
          "description": "The URL of the second keyframe to use for the generation.",
          "nullable": true
        },
        "keyframe_1_index": {
          "examples": [
            8
          ],
          "title": "Keyframe 1 Index",
          "type": "integer",
          "description": "The frame index of the second keyframe to use for the generation.",
          "nullable": false,
          "default": 0
        },
        "guidance_scale": {
          "minimum": 0,
          "maximum": 2,
          "type": "integer",
          "title": "Classifier-Free Guidance scale (CFG)",
          "description": "The CFG (Classifier Free Guidance) scale is a measure of how close you want the model to stick to your prompt when looking for a related image to show you.",
          "default": 1
        },
        "num_inference_steps": {
          "minimum": 1,
          "maximum": 12,
          "type": "integer",
          "title": "Number of inference steps",
          "description": "Increasing the amount of steps tells Stable Diffusion that it should take more steps to generate your final result which can increase the amount of detail in your image.",
          "default": 4
        },
        "keyframe_2_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/scribble2/scribble_2_3.png"
          ],
          "title": "Keyframe 2 Image Url",
          "type": "string",
          "description": "The URL of the third keyframe to use for the generation.",
          "nullable": true
        },
        "negative_prompt": {
          "examples": [
            "blurry, low resolution, bad, ugly, low quality, pixelated, interpolated, compression artifacts, noisey, grainy"
          ],
          "title": "Negative Prompt",
          "type": "string",
          "description": "\n            The negative prompt to use. Use it to specify what you don't want.\n        ",
          "default": ""
        },
        "keyframe_0_image_url": {
          "examples": [
            "https://storage.googleapis.com/falserverless/scribble2/scribble_2_1.png"
          ],
          "title": "Keyframe 0 Image Url",
          "type": "string",
          "description": "The URL of the first keyframe to use for the generation.",
          "nullable": true
        }
      },
      "x-fal-order-properties": [
        "prompt",
        "negative_prompt",
        "controlnet_type",
        "num_inference_steps",
        "guidance_scale",
        "seed",
        "keyframe_0_image_url",
        "keyframe_0_index",
        "keyframe_1_image_url",
        "keyframe_1_index",
        "keyframe_2_image_url",
        "keyframe_2_index"
      ],
      "required": [
        "prompt"
      ]
    }
  },
  {
    "id": "workflows/nicholaswallace/legomaker",
    "name": "Lego Maker",
    "description": "Transform images into Lego-style artwork",
    "category": "effects",
    "thumbnail_url": "/video-thumbnails/wan-effects-thumb.mp4",
    "tags": [
      "lego",
      "effects",
      "stylize"
    ],
    "highlighted": true,
    "pinned": true
  }
]